<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Tom Leverstone - Blog</title><link href="/" rel="alternate"></link><link href="https://leverstone.me/blog/atom.xml" rel="self"></link><id>/</id><updated>2025-04-21T19:00:00+00:00</updated><entry><title>Frontend Gems #2: 'Load More' with htmx</title><link href="/blog/frontend-gems-2-load-more-with-htmx" rel="alternate"></link><published>2025-04-21T19:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2025-04-21:/blog/frontend-gems-2-load-more-with-htmx</id><summary type="html">&lt;p&gt;Until recently, this blog displayed 10 entries at a time, using &lt;strong&gt;OLDER&lt;/strong&gt; and &lt;strong&gt;NEWER&lt;/strong&gt; buttons for pagination:&lt;/p&gt;
&lt;p&gt;&lt;video
    controls
    src="/images/blog/pagination_traditional.webm"
/&gt;
&lt;/p&gt;
&lt;p&gt;There's nothing fancy here. The &lt;strong&gt;OLDER&lt;/strong&gt; button is an anchor element linking to the next blog index page …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Until recently, this blog displayed 10 entries at a time, using &lt;strong&gt;OLDER&lt;/strong&gt; and &lt;strong&gt;NEWER&lt;/strong&gt; buttons for pagination:&lt;/p&gt;
&lt;p&gt;&lt;video
    controls
    src="/images/blog/pagination_traditional.webm"
/&gt;
&lt;/p&gt;
&lt;p&gt;There's nothing fancy here. The &lt;strong&gt;OLDER&lt;/strong&gt; button is an anchor element linking to the next blog index page (&lt;code&gt;index2.html&lt;/code&gt;, &lt;code&gt;index3.html&lt;/code&gt; etc.). You can see how the URL changes in the video. The &lt;strong&gt;NEWER&lt;/strong&gt; button works in a similar way. &lt;a href="https://github.com/Nagasaki45/leverstone.me/blob/b399d620c862194e224834ea8545abe8b1811cfd/theme/templates/partials/pagination.html"&gt;Here's the code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Wouldn't it be nice if there was just a &lt;strong&gt;Load More&lt;/strong&gt; button that loads the next page in place, without a full page load? 🤔&lt;/p&gt;
&lt;p&gt;This website is a static site, with very minimal JavaScript. In an effort to keep things simple, I looked into &lt;a href="https://htmx.org/"&gt;htmx&lt;/a&gt;. The solution is now live on the blog. Here's how it looks:&lt;/p&gt;
&lt;p&gt;&lt;video
    controls
    src="/images/blog/pagination_load_more.webm"
/&gt;
&lt;/p&gt;
&lt;p&gt;Now, dear reader, how complex do you think the solution is? How many lines of code were added, and removed, to support this? Intuitively I thought it would take a lot of fiddling, but to my surprise it was super easy! Here's the crux of it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;{% if articles_page.has_next() %}
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;button&lt;/span&gt;
  &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;btn btn-primary load-more&amp;quot;&lt;/span&gt;
  &lt;span class="na"&gt;hx-get&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;{{ page_name }}/index{{ articles_page.next_page_number() }}.html&amp;quot;&lt;/span&gt;
  &lt;span class="na"&gt;hx-select&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;.item, .load-more&amp;quot;&lt;/span&gt;
  &lt;span class="na"&gt;hx-swap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;outerHTML&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  Load more
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;button&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
{% endif %}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;So, what do we have here? If there are more articles to load, we render a &lt;strong&gt;Load More&lt;/strong&gt; button with some htmx attributes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;hx-get&lt;/code&gt;: Specifies the URL to GET when the button is clicked. This is the same URL the previous &lt;strong&gt;OLDER&lt;/strong&gt; button used.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hx-select&lt;/code&gt;: Selects the blog entries (&lt;code&gt;.item&lt;/code&gt;) and the next &lt;strong&gt;Load More&lt;/strong&gt; button (if any) from the HTML response received from the &lt;code&gt;hx-get&lt;/code&gt; request.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hx-swap="outerHTML"&lt;/code&gt;: Instructs htmx to replace the &lt;em&gt;current&lt;/em&gt; button (the one that was clicked) entirely with the content selected by &lt;code&gt;hx-select&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/Nagasaki45/leverstone.me/commit/4df289df2322cc7ba66844768f3917eb1998013f"&gt;Here's the change&lt;/a&gt;. Yes! That's all of it. And the stats? 3 files changed: the new button implementation replaced the old pagination buttons, minor CSS changes, and adding the htmx library; +14 -19 lines changed. Yes, more lines were removed than added. This is a win in my book 🙌&lt;/p&gt;
&lt;p&gt;I stopped here, but it should be equally simple to implement infinite scroll. Just change the trigger from clicking a button to triggering the load when a specific element (like one near the bottom) enters the viewport. Note, however, it's not needed for my site as I want the footer reachable.&lt;/p&gt;
&lt;p&gt;This was my first attempt to use htmx and it was much smoother than expected! When reading about htmx I always thought of it as a complement to a backend service. Here I have a statically generated site, but it provided a super simple solution for my use case. What's more, any existing links online pointing to the old &lt;code&gt;indexX.html&lt;/code&gt; pages will still work perfectly; they'll simply load the specific page, which now includes the &lt;strong&gt;Load More&lt;/strong&gt; button at the bottom. Not breaking existing links is a massive bonus!&lt;/p&gt;
&lt;p&gt;In line with my &lt;a href="/blog/frontend-gems-1-pagefind"&gt;previous blog post in this series&lt;/a&gt; I think there's much to gain from using simple technologies like static sites, htmx, and the like. Not everything needs to be a full-blown Single Page App using a JS framework (React, I'm looking at you). Give simplicity a shot!&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Frontend Gems #1: Pagefind</title><link href="/blog/frontend-gems-1-pagefind" rel="alternate"></link><published>2025-04-15T23:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2025-04-15:/blog/frontend-gems-1-pagefind</id><summary type="html">&lt;p&gt;&lt;img alt="Pagefind logo" src="/images/blog/pagefind_logo.webp"&gt;&lt;/p&gt;
&lt;p&gt;First in this series focusing on frontend technologies or techniques that I find interesting is &lt;a href="https://pagefind.app/"&gt;Pagefind&lt;/a&gt;. From their website:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Pagefind is a fully static search library that aims to perform well on large sites, while …&lt;/p&gt;&lt;/blockquote&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="Pagefind logo" src="/images/blog/pagefind_logo.webp"&gt;&lt;/p&gt;
&lt;p&gt;First in this series focusing on frontend technologies or techniques that I find interesting is &lt;a href="https://pagefind.app/"&gt;Pagefind&lt;/a&gt;. From their website:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Pagefind is a fully static search library that aims to perform well on large sites, while using as little of your users’ bandwidth as possible, and without hosting any infrastructure.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I was looking for a search solution for this very blog, a statically generated website built with &lt;a href="https://getpelican.com/"&gt;Pelican&lt;/a&gt; (&lt;a href="https://github.com/Nagasaki45/leverstone.me"&gt;source code here&lt;/a&gt;). I wanted to keep the site simple and entirely under my control. This meant avoiding developing and maintaining a backend, or using a third-party search-as-a-service solution like &lt;a href="https://www.algolia.com/"&gt;Algolia&lt;/a&gt; (nothing against them, of course). Some Googling led me to Pagefind, and I'm very happy I discovered this project! Integrating it into the site was a breeze.&lt;/p&gt;
&lt;p&gt;Pleased with the result, I showed it to a few colleagues who raised the question of scalability. While this isn't a concern for this website (with nearly 90 pages at the time of writing), could Pagefind perform well in production settings with much larger datasets? Surprisingly, I suspect the answer might be 'yes'. The project's website features impressive demos, including a search implementation across the entire MDN documentation repository – quite a feat.&lt;/p&gt;
&lt;p&gt;I won't pretend to understand all the intricacies of how Pagefind works, but here are some general observations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A script processes your build output folder, containing the static HTML files.&lt;/li&gt;
&lt;li&gt;The search engine runs in WebAssembly, so it is quite performant.&lt;/li&gt;
&lt;li&gt;It retrieves binary index files as needed. Observing the network tab, it appears to transfer very little data during a search – typically only a few tens of kilobytes at most.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;On second thought, the efficiency shouldn't be entirely surprising. The script creates an index from your content beforehand. Conceptually, it's similar to running Solr or ElasticSearch, where an index is built to optimize search performance. The main difference here is that the pre-built index files are fetched over the network instead of being read directly from a server's disk. The index is still an index though, with a single purpose, to avoid scanning large amounts of data at search time.&lt;/p&gt;
&lt;p&gt;On a more general note, this experience reinforces my conviction that a much larger portion of the web could function perfectly well as statically generated sites. Requiring a performant search feature is not an excuse!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Written with the help of gemini-2.5-pro-exp-03-25.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>The definition of vibe coding - A tribute to Todepond</title><link href="/blog/the-definition-of-vibe-coding-a-tribute-to-todepond" rel="alternate"></link><published>2025-03-26T01:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2025-03-26:/blog/the-definition-of-vibe-coding-a-tribute-to-todepond</id><summary type="html">&lt;p&gt;If you're not following &lt;a href="https://www.todepond.com/"&gt;Lu Wilson, a.k.a Todepond&lt;/a&gt;, &lt;strong&gt;you really should!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;They published a blog post titled &lt;a href="https://www.todepond.com/sky/definition-of-live-coding/"&gt;Definition of "live coding"&lt;/a&gt; about a week ago. My initial reaction:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Chart of the quality of the definition of live coding over the past 10 years" src="/images/blog/the-definition-of-live-coding-from-iclc.webp"&gt;&lt;/p&gt;
&lt;p&gt;Many things went wrong during …&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you're not following &lt;a href="https://www.todepond.com/"&gt;Lu Wilson, a.k.a Todepond&lt;/a&gt;, &lt;strong&gt;you really should!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;They published a blog post titled &lt;a href="https://www.todepond.com/sky/definition-of-live-coding/"&gt;Definition of "live coding"&lt;/a&gt; about a week ago. My initial reaction:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Chart of the quality of the definition of live coding over the past 10 years" src="/images/blog/the-definition-of-live-coding-from-iclc.webp"&gt;&lt;/p&gt;
&lt;p&gt;Many things went wrong during COVID. Apparently, the definition of live coding is one of them. I wanted to plot this 👆 and share somewhere, but what's the point? It's probably a waste of time. I moved on.&lt;/p&gt;
&lt;p&gt;Then, this appeared on my RSS feed: &lt;a href="https://www.todepond.com/sky/okay-fine-ill-define-live-coding/"&gt;Okay fine I’ll define live coding&lt;/a&gt;. What a beautifully written thought provoking piece! Seriously.&lt;/p&gt;
&lt;p&gt;So the plot has to be updated. Should I spend 5 minutes just doing the plot in any existing tool? Nahhhhh. Let's just &lt;a href="https://www.youtube.com/watch?v=JjHD5f058qw"&gt;sketch-it-and-let-the-AI-figure-it-out&lt;/a&gt;. Or, even better, create an interface to do just that, &lt;a href="https://github.com/tldraw/draw-fast"&gt;draw-fast&lt;/a&gt; style.&lt;/p&gt;
&lt;p&gt;Presenting to you 🥁... &lt;a href="https://plot-fast.leverstone.me/"&gt;&lt;strong&gt;Plot Fast&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;video
  controls
  src="/images/blog/the-definition-of-live-coding-plot-fast.mp4"
/&gt;
&lt;/p&gt;
&lt;p&gt;Did you see how fast it was?!? And the legend? 😵 Perfect!&lt;/p&gt;
&lt;h1 id="a-note-about-api-keys"&gt;A note about API keys&lt;/h1&gt;
&lt;p&gt;When you click the button to convert the sketch to an XKCD chart you'll be asked for a Gemini API key. It will be stored in local storage from now on. You can trust me that this is not leaked anywhere &lt;strong&gt;but you probably shouldn't!&lt;/strong&gt; You can read the source to make sure I'm not doing anything nasty with the key. Or at least make sure you don't use a key that is attached to a payment method.&lt;/p&gt;
&lt;h1 id="vibe-coding"&gt;Vibe coding&lt;/h1&gt;
&lt;p&gt;This was an exercise in &lt;a href="https://x.com/karpathy/status/1886192184808149383"&gt;vibe coding&lt;/a&gt; - asking LLMs to write code and accepting their suggestions without reviewing. Don't do it in your production code kids! Anyway, it went surprisingly smooth. I used a mix of &lt;code&gt;gemini-2.5-pro-exp-03-25&lt;/code&gt; and &lt;code&gt;claude-3.7-sonnet&lt;/code&gt;. Why? I'm not sure. I really like Gemini for writing and I initially thought I will ask for a plan, and then drop to Sonnet for the implementation. I ended up one-shotting the implementation and then iterating on it.&lt;/p&gt;
&lt;p&gt;I'm not using any code writing AI tool here, just the trustworthy &lt;a href="https://llm.datasette.io/en/stable/"&gt;&lt;code&gt;llm&lt;/code&gt; command line tool from Simon Willison&lt;/a&gt;. The entire thing is one file, so I'm just feeding the file to a model, copy-pasting any errors I see in the web console. Dealing with other requests (e.g. layout changes) is similar. For every new topic (e.g. fixing a bug, changing the layout) I started a new conversation.&lt;/p&gt;
&lt;p&gt;I tried to guide the LLM with clear instructions:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Project brief: A digital canvas to draw diagrams by hand - ms paint style. One button to convert the diagram to a nicely plotted one, potentially in XKCD or cartoonish style. Implementation details: use canvas, upon button press convert the canvas to an image and send it to an LLM (gemini-2.0-flash) to return a JSON for the chart spec. This is then loaded in chart.xkcd. It should all be done in a single HTML page. When the user clicks the button for the first time they are asked for an API key which is then stored in local memory.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Generating the system prompt was interesting. I used &lt;a href="https://shot-scraper.datasette.io/en/stable/index.html"&gt;&lt;code&gt;shot-scraper&lt;/code&gt;&lt;/a&gt;, another tool from Simon Willison, to take a screenshot of &lt;a href="https://timqian.com/chart.xkcd/"&gt;the chart.xkcd docs&lt;/a&gt;, then fed it to the LLM with the following prompt:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I want an LLM to take an image of a hand made chart in MS Paint and produce a JSON object that can be passed to chart.xkcd for rendering. Create a system prompt with documentation for how to use chart.xkcd. Include examples. Make sure that when the LLM receives an image it will output only a valid JSON containing the data to pass to chart.xkcd. At the top level of the JSON there should be two keys: chartType, and spec. The chart type is 'line', 'xy', 'bar', etc. The spec is the object to pass to the library.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That's pretty much it! Thanks for reading. And thanks Lu again for the inspiration!&lt;/p&gt;
&lt;p&gt;Happy vibe-plotting 📈&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Script for Checking TLS Certificate Expiry Dates</title><link href="/blog/script-for-checking-tls-certificate-expiry-dates" rel="alternate"></link><published>2025-03-10T23:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2025-03-10:/blog/script-for-checking-tls-certificate-expiry-dates</id><summary type="html">&lt;p&gt;I have multiple projects on subdomains of leverstone.me. What's the expiration date of the TLS certificates on these subdomains? I have no idea 🤷&lt;/p&gt;
&lt;p&gt;Wouldn't it be nice if there was a CLI tool that …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have multiple projects on subdomains of leverstone.me. What's the expiration date of the TLS certificates on these subdomains? I have no idea 🤷&lt;/p&gt;
&lt;p&gt;Wouldn't it be nice if there was a CLI tool that, given a domain, lists the expiry dates of its subdomains? I couldn't find one so asked perplexity and Claude 3.7 Sonnet to help me write it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;$#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-ne&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Usage: &lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;basename&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$0&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt; &amp;lt;domain&amp;gt;&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;exit&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="nv"&gt;DOMAIN&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;

&lt;span class="c1"&gt;# Combine main domain with subdomains from subfinder and process each&lt;/span&gt;
&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$DOMAIN&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;subfinder&lt;span class="w"&gt; &lt;/span&gt;-d&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$DOMAIN&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-silent&lt;span class="o"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;read&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-r&lt;span class="w"&gt; &lt;/span&gt;subdomain&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;do&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;# Get expiry date from certificate&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;expiry_date&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;openssl&lt;span class="w"&gt; &lt;/span&gt;s_client&lt;span class="w"&gt; &lt;/span&gt;-servername&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$subdomain&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-connect&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$subdomain&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;:443&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&amp;gt;/dev/null&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;openssl&lt;span class="w"&gt; &lt;/span&gt;x509&lt;span class="w"&gt; &lt;/span&gt;-enddate&lt;span class="w"&gt; &lt;/span&gt;-noout&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&amp;gt;/dev/null&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;sed&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;s/notAfter=//&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-n&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$expiry_date&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="c1"&gt;# Convert to ISO 8601&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nv"&gt;iso_date&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;date&lt;span class="w"&gt; &lt;/span&gt;-d&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$expiry_date&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;+%Y-%m-%dT%H:%M:%SZ&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&amp;gt;/dev/null&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;$?&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-eq&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$subdomain&lt;/span&gt;&lt;span class="s2"&gt;: &lt;/span&gt;&lt;span class="nv"&gt;$iso_date&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;
&lt;span class="w"&gt;            &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$subdomain&lt;/span&gt;&lt;span class="s2"&gt;: &lt;/span&gt;&lt;span class="nv"&gt;$expiry_date&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$subdomain&lt;/span&gt;&lt;span class="s2"&gt;: No SSL certificate found&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Drop this in, for example, &lt;code&gt;~/.local/bin/certcheck&lt;/code&gt; (assuming &lt;code&gt;~/.local/bin&lt;/code&gt; is in your path already), &lt;code&gt;chmod +x ~/.local/bin/certcheck&lt;/code&gt;, and you are ready to go!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;➜ certcheck leverstone.me
leverstone.me: 2025-05-09T06:01:06Z
proker.leverstone.me: 2025-06-06T23:19:25Z
xteams.leverstone.me: 2025-06-06T23:18:28Z
web-audio.leverstone.me: 2025-06-06T23:16:14Z
grab-a-coffee.leverstone.me: 2025-06-06T23:21:17Z
cardigan.leverstone.me: 2025-06-06T23:20:16Z
miniflux.leverstone.me: 2025-05-22T00:02:03Z
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Looks good!&lt;/p&gt;
&lt;h1 id="notes"&gt;Notes&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/projectdiscovery/subfinder"&gt;&lt;code&gt;subfinder&lt;/code&gt;&lt;/a&gt; is an open source 'Fast passive subdomain enumeration tool' for penetration testers and bug bounty hunters. You'll have to install it. On arch linux &lt;code&gt;yay -S subfinder&lt;/code&gt; was enough. Perplexity suggested it when I asked for ways to find subdomain of a domain from the command line.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/openssl/openssl"&gt;OpenSSL&lt;/a&gt; is used to fetch the certificate and extract the expiry time. The command &lt;code&gt;echo | openssl s_client -servername "$subdomain" -connect "$subdomain":443 2&amp;gt;/dev/null | openssl x509 -enddate -noout&lt;/code&gt; was suggested by Claude 3.7 Sonnet when asked for ways to get the expiry time of a certificate of a domain.&lt;/li&gt;
&lt;li&gt;The rest of the script was created by iterating on some basic prompts with Claude.&lt;/li&gt;
&lt;/ul&gt;</content><category term="Blog"></category></entry><entry><title>Custom shell aliases per project</title><link href="/blog/custom-shell-aliases-per-project" rel="alternate"></link><published>2025-02-28T23:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2025-02-28:/blog/custom-shell-aliases-per-project</id><summary type="html">&lt;p&gt;I've been playing with &lt;a href="https://aider.chat/"&gt;aider&lt;/a&gt; recently. I's an "AI pair programming in your terminal". Think GitHub Copilot, Cursor, etc. but for the command line. This blog post is not about that. It's about making it …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been playing with &lt;a href="https://aider.chat/"&gt;aider&lt;/a&gt; recently. I's an "AI pair programming in your terminal". Think GitHub Copilot, Cursor, etc. but for the command line. This blog post is not about that. It's about making it easier to run aider in my projects.&lt;/p&gt;
&lt;p&gt;Confused? Let's see...&lt;/p&gt;
&lt;p&gt;In one of my projects I run aider like this&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;aider&lt;span class="w"&gt; &lt;/span&gt;--architect&lt;span class="w"&gt; &lt;/span&gt;--test-cmd&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;uv run python -m pytest&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;--lint-cmd&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;make format&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In another I run it like this&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;aider&lt;span class="w"&gt; &lt;/span&gt;--architect&lt;span class="w"&gt; &lt;/span&gt;--model&lt;span class="w"&gt; &lt;/span&gt;o3-mini&lt;span class="w"&gt; &lt;/span&gt;--editor-model&lt;span class="w"&gt; &lt;/span&gt;sonnet&lt;span class="w"&gt; &lt;/span&gt;--test-cmd&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;docker run --rm -v .:/ app my-app pytest&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;--lint-cmd&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;make docker/format&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The point is, this is a long command line to type every time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Wouldn't it be nice if I had custom aliases, per project, so I can just run &lt;code&gt;aider&lt;/code&gt; within the repo and it will run the full command for me? 🤔&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I googled and asked some LLMs but couldn't find a simple existing solution. Having something custom sounded easy, so I tried to get something done with the help of ChatGPT, and it worked surprisingly well!&lt;/p&gt;
&lt;h1 id="trusted-source"&gt;&lt;code&gt;trusted-source&lt;/code&gt;&lt;/h1&gt;
&lt;p&gt;This custom &lt;a href="https://ohmyz.sh/"&gt;oh-my-zsh&lt;/a&gt; plugin looks for &lt;code&gt;.trusted-source&lt;/code&gt; files in the current directory, ask the user to confirm they are trusted, and if so, sources them.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Function to source trusted `.trusted-source` files in the current directory.&lt;/span&gt;
&lt;span class="k"&gt;function&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;load_trusted_source&lt;span class="o"&gt;()&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nb"&gt;local&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;file_to_source&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$PWD&lt;/span&gt;&lt;span class="s2"&gt;/.trusted-source&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nb"&gt;local&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;trust_file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$HOME&lt;/span&gt;&lt;span class="s2"&gt;/.trusted-sources&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;# File to store trusted hashes.&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nb"&gt;local&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;file_hash

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-f&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$file_to_source&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;# Compute a checksum&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;file_hash&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;shasum&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$file_to_source&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;awk&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;{print $1}&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="c1"&gt;# Retrieve the last trusted hash for this directory.&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nb"&gt;local&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;saved_hash
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;saved_hash&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;grep&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;^&lt;/span&gt;&lt;span class="nv"&gt;$PWD&lt;/span&gt;&lt;span class="s2"&gt; &amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$trust_file&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&amp;gt;/dev/null&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;tail&lt;span class="w"&gt; &lt;/span&gt;-n&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;awk&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;{print $2}&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$saved_hash&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;!&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$file_hash&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;New or changed .trusted-source file detected in &lt;/span&gt;&lt;span class="nv"&gt;$PWD&lt;/span&gt;&lt;span class="s2"&gt;.&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nb"&gt;read&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-q&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;REPLY?Do you trust and want to source it? [y/N] &amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[[&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$REPLY&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;~&lt;span class="w"&gt; &lt;/span&gt;^&lt;span class="o"&gt;[&lt;/span&gt;Yy&lt;span class="o"&gt;]&lt;/span&gt;$&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;]]&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;then&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="c1"&gt;# Append the new trusted hash to the trust file.&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$PWD&lt;/span&gt;&lt;span class="s2"&gt; &lt;/span&gt;&lt;span class="nv"&gt;$file_hash&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&amp;gt;&amp;gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$trust_file&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$file_to_source&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="c1"&gt;# The file is trusted; load it silently.&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$file_to_source&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;fi&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# Hook the function into zsh&amp;#39;s directory-change mechanism.&lt;/span&gt;
&lt;span class="nv"&gt;chpwd_functions&lt;/span&gt;&lt;span class="o"&gt;+=(&lt;/span&gt;load_trusted_source&lt;span class="o"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Optionally, run it once on shell startup.&lt;/span&gt;
load_trusted_source
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To use it, copy it to &lt;code&gt;~/.oh-my-zsh/custom/plugins/trusted-source/trusted-source.plugin.zsh&lt;/code&gt;. And add &lt;code&gt;trusted-source&lt;/code&gt; to the list of plugins in your &lt;code&gt;~/.zshrc&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;With this set up I have this &lt;code&gt;.trusted-source&lt;/code&gt; in the root of my project:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nb"&gt;alias&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;aider&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;aider&lt;span class="w"&gt; &lt;/span&gt;--architect&lt;span class="w"&gt; &lt;/span&gt;--test-cmd&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;uv run python -m pytest&amp;#39;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;--lint-cmd&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;make format&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;and to run aider I can just run &lt;code&gt;aider&lt;/code&gt; 🙌&lt;/p&gt;
&lt;p&gt;This is just one use case of course. I can use this for env vars (replacing &lt;a href="https://github.com/direnv/direnv"&gt;direnv&lt;/a&gt;), source my Python virtual environment (something I rarely do now that I mostly use uv / poetry), etc. This plugin is for zsh and oh-my-zsh, but the idea should be very much transferable to other shells. I'm documenting it here for my future self, but maybe someone will also find it interesting.&lt;/p&gt;
&lt;p&gt;And what about aider, you ask? I'm still struggling with all of this AI for writing code idea. For writing prose? Definitely! For exploring technical ideas? Of course! For translating what's in my head to an easy to read and maintainable python code? I'm not yet there, but I'm trying. We will see how it goes...&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Quoting Sam Altman</title><link href="/blog/quoting-sam-altman" rel="alternate"></link><published>2025-02-16T00:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2025-02-16:/blog/quoting-sam-altman</id><summary type="html">&lt;p&gt;A few days ago Sam Altman shared &lt;a href="https://x.com/sama/status/1889755723078443244"&gt;an update about OpenAI's roadmap on twitter&lt;/a&gt;. Here's what I'm reading between the lines:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We hate the model picker as much as you do and want to return …&lt;/p&gt;&lt;/blockquote&gt;</summary><content type="html">&lt;p&gt;A few days ago Sam Altman shared &lt;a href="https://x.com/sama/status/1889755723078443244"&gt;an update about OpenAI's roadmap on twitter&lt;/a&gt;. Here's what I'm reading between the lines:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We hate the model picker as much as you do and want to return to magic unified intelligence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;He's talking about ChatGPT, not the API. Is this where the focus is?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We will next ship GPT-4.5, the model we called Orion internally, as our last non-chain-of-thought model.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As I understand it there's a lot of value in "small" models like 4o-mini, Gemini flash, etc. These are generally faster and cheaper than their larger siblings, and perfectly adequate for many tasks. I think this is also reflected in the wide range of sizes of open weights models. The point here suggests that OpenAI are confident they can compete in the space of "small" models with only chain-of-thought models. This is interesting because there's always a performance penalty for this type of models as they "burn" tokens on thinking before answering.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;After that, a top goal for us is to unify o-series models and GPT-series models by creating systems that can use all our tools, know when to think for a long time or not, and generally be useful for a very wide range of tasks.&lt;/p&gt;
&lt;p&gt;In both ChatGPT and our API, we will release GPT-5 as a system that integrates a lot of our technology, including o3. We will no longer ship o3 as a standalone model.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There's a lot to unpack here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The future of OpenAI is an intelligent software system that does a lot behind the scene. This is different to what we are used to now (especially when using the API). At the moment we interact with a model. In the future we will interact with a more complex software system. One can say the differentiation is pointless, because the models themselves are black boxes, but I tend to disagree. First, models have relatively clear performance behaviour - I know the time to first token and tokens per second and can consider these when developing an application around LLMs. If my application changes its time to first token from 1 second to a few 10s of seconds because of user input that's a problem. Second, we match the model we use to the problem we are trying to solve. We don't always need more intelligence. If this is something that can be triggered by user input that might also be a problem.&lt;/li&gt;
&lt;li&gt;If GPT 5 is not going to be a new kind of intelligence we didn't see before, what does it say about OpenAI's AGI mission?&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;The free tier of ChatGPT will get unlimited chat access to GPT-5 at the standard intelligence setting (!!), subject to abuse thresholds.&lt;/p&gt;
&lt;p&gt;Plus subscribers will be able to run GPT-5 at a higher level of intelligence, and Pro subscribers will be able to run GPT-5 at an even higher level of intelligence. These models will incorporate voice, canvas, search, deep research, and more.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;So, in the future there's just one model, or rather a software system orchestrating multiple models, to which the only parameter is the intelligence level. This sounds potentially simpler than picking a model, but might also mean less opportunity to tune the system to someone's needs.&lt;/li&gt;
&lt;li&gt;The only monetisation is the level of intelligence, not features. That's a bold move! As someone that works on an AI driven application we often struggle with this question. The downside is that free tier users are not going to get a good picture of what AI is capable of. Essentially it's like going back to the days of free GPT 3.5, when non-paying users say AI is crap, while paying users are getting much more out of 4o. I don't think it worked well for OpenAI. otherwise they wouldn't have changed this.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;Overall, to me, it all sounds great for serving ChatGPT users. It doesn't sound very appealing for builders of applications on top of OpenAI's APIs. On the other hand I think it's great that OpenAI keeps innovating. I don't think the future of AI is necessarily about the best intelligence. There's a lot to be gained from better software systems that wrap models. Even if OpenAI ends up being consumer focused there's enough players that can push the enterprise use case forwards and overall the field will benefit from the diversity.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Quoting Chip Huyen</title><link href="/blog/quoting-chip-huyen" rel="alternate"></link><published>2025-02-08T23:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2025-02-08:/blog/quoting-chip-huyen</id><summary type="html">&lt;p&gt;The best explanation I've seen for why AI is not going to replace software engineers:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I think it goes back to the question of what software engineering is. So maybe I can use an analogy …&lt;/p&gt;&lt;/blockquote&gt;</summary><content type="html">&lt;p&gt;The best explanation I've seen for why AI is not going to replace software engineers:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I think it goes back to the question of what software engineering is. So maybe I can use an analogy to help explain it better.&lt;/p&gt;
&lt;p&gt;Take writing, for example. We tend to confuse the most salient activity of something with the job itself. In the past, writing meant the physical act of putting words onto paper. Back then, people thought of writing as that physical act and took pride in their calligraphy. People would say, "Oh, I have beautiful handwriting; you must be smart, you must be intelligent."&lt;/p&gt;
&lt;p&gt;But then we had computers, and now writing doesn't refer to that act anymore. Writing refers to the process of arranging ideas into a readable format.&lt;/p&gt;
&lt;p&gt;And I think it's the same with coding. Now, people think of software engineering as a physical act: putting code into VS Code, Vim, or whatever editor they use. But that's not what software engineering is.&lt;/p&gt;
&lt;p&gt;Software engineering is about solving problems. Consider a problem: How do I come up with executable programs to solve it? Coding itself is just a physical act.&lt;/p&gt;
&lt;p&gt;&lt;cite&gt;From &lt;a href="https://newsletter.pragmaticengineer.com/p/ai-engineering-with-chip-huyen"&gt;The Pragmatic Engineer Podcast&lt;/a&gt;&lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;19.4.2025 UPDATE:&lt;/strong&gt; When I first published this post I used an LLM to extract the quote from the MP3 that I downloaded from the link above. I don't remember the prompt but it was something along the lines of "Give me the verbatim where the interviewee compares software engineering to writing". Given the publishing date I believe I used Gemini 1.5 Flash. The LLM response captured the essence of the argument but butchered the ending. &lt;a href="https://github.com/Nagasaki45/leverstone.me/commit/c6727fc4da5c32ec74a9390be6c9ff6384710764"&gt;Here's the old version&lt;/a&gt;. I knew it was wrong, but still published it. It annoyed me since, so today I've updated the post with a new verbatim. I used a similar prompt with the same audio file against the new Gemini 2.5 Flash:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;Here&amp;#39;s a modified quote from this podcast:

[OLD POST QUOTE]

Find the verbatim quote from the podcast.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I then passed the results through another call with the prompt:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="nv"&gt;Convert&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;this&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;transcription&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;spoken&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;text&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;into&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;what&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;it&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;would&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;look&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;like&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;was&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;written&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;text&lt;/span&gt;.&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;It&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;should&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;be&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;ready&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;post&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;social&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;media&lt;/span&gt;.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I didn't double checked it against the podcast but it's more in line with what I remember so here we go.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Performance Profiling in Python: Tools, Techniques, and an Unexpected Culprit</title><link href="/blog/performance-profiling-in-python-tools-techniques-and-an-unexpected-culprit" rel="alternate"></link><published>2025-01-31T13:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2025-01-31:/blog/performance-profiling-in-python-tools-techniques-and-an-unexpected-culprit</id><summary type="html">&lt;p&gt;Recently, my team encountered a performance issue with our Python service that uses FastAPI, gunicorn, uvicorn, and the OpenAI API. The service works fine in development, but when we load-tested it in our staging environment …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Recently, my team encountered a performance issue with our Python service that uses FastAPI, gunicorn, uvicorn, and the OpenAI API. The service works fine in development, but when we load-tested it in our staging environment, the response time skyrocketed, and the throughput became embarrassingly low. Luckily, it was us stressing the service.&lt;/p&gt;
&lt;p&gt;In this post, I'll walk through how we diagnosed and fixed this performance bottleneck. While the specific issue we found might not match your next performance problem, the debugging process and tools we used should be helpful for any Python developer dealing with similar challenges.&lt;/p&gt;
&lt;p&gt;I've created a &lt;a href="https://github.com/Nagasaki45/OTEL-OpenAI-performance-investigation"&gt;minimal reproducible example&lt;/a&gt; that demonstrates the exact same issue we encountered. Let's dive in.&lt;/p&gt;
&lt;h1 id="recognizing-the-symptoms"&gt;Recognizing the Symptoms&lt;/h1&gt;
&lt;p&gt;We noticed that as we scaled up concurrent users, response times became significantly worse. We load-tested the service to understand its behaviour under pressure. Using &lt;a href="https://httpd.apache.org/docs/2.4/programs/ab.html"&gt;Apache Benchmark (ab)&lt;/a&gt;, a handy tool for simulating user load, we were able to quantify the problem.&lt;/p&gt;
&lt;p&gt;We can run it as follows to simulate a single user hitting the service:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ab&lt;span class="w"&gt; &lt;/span&gt;-l&lt;span class="w"&gt; &lt;/span&gt;-c&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-n&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;http://localhost:9000/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The median response time in this case is 1545 milliseconds, and the throughput is 0.58 requests per second (RPS).&lt;/p&gt;
&lt;p&gt;Based on this, in an ideal world, 75 concurrent users should receive the same response time, and the throughput should increase 75-fold to about 43 RPS. Let's try:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ab&lt;span class="w"&gt; &lt;/span&gt;-l&lt;span class="w"&gt; &lt;/span&gt;-c&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;75&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-n&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;200&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;http://localhost:9000/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Results:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Median response time: 35306ms&lt;/li&gt;
&lt;li&gt;RPS: 1.95&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Huston, we have a problem! But where to begin?&lt;/p&gt;
&lt;h1 id="suspects"&gt;Suspects&lt;/h1&gt;
&lt;p&gt;The application relies on AsyncIO, so our initial hunch was that there might be a blocking call somewhere causing multiple requests to wait for each other. We enabled the &lt;a href="https://docs.python.org/3/library/asyncio-dev.html"&gt;debug mode for AsyncIO&lt;/a&gt; but couldn't find coroutines with unexpectedly long execution times. That wasn't the issue.&lt;/p&gt;
&lt;p&gt;Next was the DB. We use &lt;a href="https://opentelemetry.io/"&gt;OpenTelemetry&lt;/a&gt; to collect traces from our apps, including traces for DB queries. A quick look at our traces showed that the DB queries were very efficient, taking only a few milliseconds each, and there were only a few of them per request. Even if DB queries blocked the event loop, they couldn't cause the performance issue we were observing.&lt;/p&gt;
&lt;p&gt;Lastly, we checked the CPU utilisation while load-testing the service. It was clearly at 100%. We were on to something!&lt;/p&gt;
&lt;h1 id="investigating-inefficient-code"&gt;Investigating Inefficient Code&lt;/h1&gt;
&lt;p&gt;The code is inefficient? Here comes the profiler! It allowed us to examine the time spent in each function, the number of times each function is called, and the relationships between function calls.&lt;/p&gt;
&lt;p&gt;While Python's built-in cProfile is a common choice, we opted for &lt;a href="https://github.com/sumerc/yappi"&gt;Yappi&lt;/a&gt; instead. Why? Because our service heavily relies on asynchronous code (coroutines), and &lt;a href="https://github.com/sumerc/yappi/blob/master/doc/coroutine-profiling.md"&gt;Yappi handles them better than cProfile&lt;/a&gt;. A rule of thumb: if you use AsyncIO, just use Yappi. We tried cProfile, and it didn't help us much in this case.&lt;/p&gt;
&lt;h2 id="setting-up-yappi"&gt;Setting up Yappi&lt;/h2&gt;
&lt;p&gt;Integrating Yappi into our FastAPI application was straightforward:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;contextlib&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;yappi&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;fastapi&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;FastAPI&lt;/span&gt;

&lt;span class="nd"&gt;@contextlib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;asynccontextmanager&lt;/span&gt;
&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;lifespan&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;app&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FastAPI&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;yappi&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;yield&lt;/span&gt;
    &lt;span class="k"&gt;finally&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;yappi&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;ps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;yappi&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;convert2pstats&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stats&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
        &lt;span class="c1"&gt;# TIME is total time spent within function excluding callees&lt;/span&gt;
        &lt;span class="n"&gt;ps&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ps&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sort_stats&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pstats&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SortKey&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TIME&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;ps&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dump_stats&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;profile.stats&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Dump profiling info to profile.stats&lt;/span&gt;
        &lt;span class="n"&gt;ps&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;print_stats&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Printing the top 20 calls&lt;/span&gt;

&lt;span class="n"&gt;app&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;FastAPI&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;lifespan&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;lifespan&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;With this setup, whenever the service stopped, Yappi would dump the profiling data, sorted by total time in descending order. We initially tried cumulative time but this resulted in a report of the top-level functions (like the endpoint handler), not the most inefficient ones.&lt;/p&gt;
&lt;p&gt;It is time to gather some evidence!&lt;/p&gt;
&lt;h2 id="profiling-under-load"&gt;Profiling under Load&lt;/h2&gt;
&lt;p&gt;We ran the same load test again, with Yappi enabled:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;ab&lt;span class="w"&gt; &lt;/span&gt;-l&lt;span class="w"&gt; &lt;/span&gt;-c&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;75&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-n&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="m"&gt;200&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;http://localhost:9000/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;At the top of the profiling data, we found this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
    43450   16.802    0.000   73.513    0.002 /home/tgurion/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/email/feedparser.py:216(FeedParser._parsegen)
  5497700   15.427    0.000   22.207    0.000 /home/tgurion/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/email/feedparser.py:77(BufferedSubFile.readline)
  5497700   14.446    0.000   36.653    0.000 /home/tgurion/.local/share/uv/python/cpython-3.12.6-linux-x86_64-gnu/lib/python3.12/email/feedparser.py:127(BufferedSubFile.__next__)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A significant amount of time was spent in &lt;code&gt;email/feedparser.py&lt;/code&gt;! This was unexpected, as our service didn't directly use email parsing. Where does this call come from?&lt;/p&gt;
&lt;h2 id="visualising-the-call-relationships"&gt;Visualising the Call Relationships&lt;/h2&gt;
&lt;p&gt;To visualise the call relationships, we used &lt;a href="https://github.com/jrfonseca/gprof2dot"&gt;gprof2dot&lt;/a&gt; - a tool to convert the profiling output into a &lt;a href="https://graphviz.org/docs/layouts/dot/"&gt;Graphviz &lt;code&gt;.dot&lt;/code&gt; file&lt;/a&gt;, which is a common file format for graph diagrams. We then used &lt;a href="https://graphviz.org/docs/attr-types/xdot/"&gt;xdot&lt;/a&gt; to view the diagram. There's also an option to use dot directly to convert the file to &lt;code&gt;png&lt;/code&gt;. More specifically:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# Convert the profiling output to a .dot file&lt;/span&gt;
gprof2dot&lt;span class="w"&gt; &lt;/span&gt;-f&lt;span class="w"&gt; &lt;/span&gt;pstats&lt;span class="w"&gt; &lt;/span&gt;profile.stats&lt;span class="w"&gt; &lt;/span&gt;&amp;gt;&lt;span class="w"&gt; &lt;/span&gt;profile.dot
&lt;span class="c1"&gt;# Convert the .dot file to png&lt;/span&gt;
dot&lt;span class="w"&gt; &lt;/span&gt;-Tpng&lt;span class="w"&gt; &lt;/span&gt;profile.dot&lt;span class="w"&gt; &lt;/span&gt;-o&lt;span class="w"&gt; &lt;/span&gt;profile.png
&lt;span class="c1"&gt;# Open the .dot file in an interactive viewer&lt;/span&gt;
xdot&lt;span class="w"&gt; &lt;/span&gt;profile.dot
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Here are the profiling results. It shows the call graph of the service. Each node represents a function, and the edges represent calls between functions. More on the meaning of the stats on nodes and edges can be found &lt;a href="https://github.com/jrfonseca/gprof2dot?tab=readme-ov-file#output"&gt;in the gprof2dot docs&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Annotated dot representation of the profiling output. The red area is feedparser.py. The blue area is opentelemetry-instrumentation-openai" src="/images/blog/dot_representation_of_performance_investigation_profile.avif"&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: I wish I could have dropped an xdot-like interactive experience here, but that's hard to do, so you've got a manually annotated image instead. You can enlarge it; it's high-res.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;feedparser.py&lt;/code&gt; functions are annotated in red. Almost all of the calls to it are coming from a single source, annotated in blue. This is the &lt;a href="https://pypi.org/project/opentelemetry-instrumentation-openai/"&gt;opentelemetry-instrumentation-openai&lt;/a&gt; library 😱&lt;/p&gt;
&lt;h2 id="the-culprit-opentelemetry-openai-instrumentation"&gt;The Culprit: OpenTelemetry OpenAI Instrumentation&lt;/h2&gt;
&lt;p&gt;The OpenTelemetry OpenAI instrumentation helps us understand our calls to OpenAI. While convenient, it appeared to be a major performance bottleneck. But before we pronounce the defendant guilty, one last test.&lt;/p&gt;
&lt;p&gt;We removed the opentelemetry-instrumentation-openai library and reran the load test. Here are the results before and after the change:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Metric&lt;/th&gt;
&lt;th style="text-align: right;"&gt;Before&lt;/th&gt;
&lt;th style="text-align: right;"&gt;After&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Median response time (ms)&lt;/td&gt;
&lt;td style="text-align: right;"&gt;35306&lt;/td&gt;
&lt;td style="text-align: right;"&gt;15161&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Requests per second&lt;/td&gt;
&lt;td style="text-align: right;"&gt;1.95&lt;/td&gt;
&lt;td style="text-align: right;"&gt;4.76&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;That's more than double the throughput with less than half the response time!&lt;/p&gt;
&lt;p&gt;At this point, we removed the instrumentation library. But let's not finish our story on a negative note. Back to the &lt;code&gt;.dot&lt;/code&gt; file!&lt;/p&gt;
&lt;h1 id="the-fix"&gt;The Fix&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;.dot&lt;/code&gt; call graph suggested that &lt;a href="https://importlib-metadata.readthedocs.io/en/latest/api.html#importlib_metadata.version"&gt;&lt;code&gt;importlib_meta.version&lt;/code&gt;&lt;/a&gt; might be the bottleneck. This function takes a distribution (something you might install with pip) and returns the version currently installed. It was called 8604 times, and it is responsible for the calls to &lt;code&gt;feedparser.py&lt;/code&gt;, which accounts for almost 84% of the total execution time of the service. Checking the opentelemetry-instrumentation-openai source, I found &lt;a href="https://github.com/traceloop/openllmetry/blob/3539e34026a06d4cccdc1b73fd26d3f6b97fee02/packages/opentelemetry-instrumentation-openai/opentelemetry/instrumentation/openai/utils.py#L14"&gt;two&lt;/a&gt; &lt;a href="https://github.com/traceloop/openllmetry/blob/3539e34026a06d4cccdc1b73fd26d3f6b97fee02/packages/opentelemetry-instrumentation-openai/opentelemetry/instrumentation/openai/shared/__init__.py#L238"&gt;calls&lt;/a&gt; to this function. I was very happy to find that this is the bottleneck as, although computationally intensive, it is: (a) completely deterministic, and (b) called only with 2 literal values: &lt;code&gt;version("openai")&lt;/code&gt; and &lt;code&gt;version("pydantic")&lt;/code&gt;. &lt;a href="https://github.com/traceloop/openllmetry/pull/2577"&gt;Moving these to happen at import time was a simple fix&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;At the time of writing, the maintainers of the library have not yet merged the PR. We are waiting for that and will then add the instrumentation library back to our service.&lt;/p&gt;
&lt;h1 id="sharing-the-findings"&gt;Sharing the Findings&lt;/h1&gt;
&lt;p&gt;I've documented this entire investigation in &lt;a href="https://github.com/Nagasaki45/OTEL-OpenAI-performance-investigation"&gt;this GitHub repository&lt;/a&gt;, including the code, instructions for reproducing the issue, and the profiling results. I've also raised an issue on the &lt;a href="https://github.com/traceloop/openllmetry/issues/2547"&gt;OpenTelemetry instrumentation library's repository&lt;/a&gt; to inform the maintainers of the performance problem and &lt;a href="https://github.com/traceloop/openllmetry/pull/2577"&gt;submitted a PR with a fix&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="lessons-learned"&gt;Lessons Learned&lt;/h1&gt;
&lt;p&gt;This investigation taught us valuable lessons about debugging performance issues:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Load testing is crucial&lt;/strong&gt;. We regularly load test our staging environment, which is configured very similarly to our production environment. When we notice issues, we usually manage to replicate them quite easily in local development. In this case, the minimal reproducible repo (from which all of the examples in this post are drawn) was enough to reproduce the problem, find the culprit, and come up with a fix.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Having the right tools is essential&lt;/strong&gt;. AsyncIO debug mode showed us immediately that the issue was not related to blocking calls from coroutines. Traces from the DB queries confirmed it wasn't a DB issue either. &lt;code&gt;htop&lt;/code&gt; hinted at the issue when we saw 100% CPU utilisation during load tests, as up to that point we assumed the service is IO bound, not CPU bound. Yappi immediately sent us in the right direction. Visualising the profiling output helped us quickly understand what was going on and come up with the fix.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Validate your changes&lt;/strong&gt;. Once you've made a change, re-run your load tests to confirm that it has resolved the issue.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Continuous learning is important&lt;/strong&gt;. The techniques described above worked for me in this case. They might not work in a different investigation. There are certainly other ways to profile services, understand the call graph, and so on. I'm keen to learn about them! This post serves as a reminder for myself of what I've done, should I encounter similar problems in the future, and as a guide for anyone interested in learning some techniques to do the same.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The AI stack is still evolving&lt;/strong&gt;. On a broader level, we learned that much of the rapidly moving AI stack is not as robust and performant as one would expect. This is not the first time our team has encountered performance issues with popular libraries, raising the question of how these things even run in production. It seems that a lot of current development work focuses on delivering prototypes without much emphasis on performance. There might be another blog post dedicated to this topic coming soon 😉&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;This blog post was made with the help of Gemini Experimental 1206 and Claude 3.5 Sonnet.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Automating Groundedness Evaluation in RAG Applications</title><link href="/blog/automating-groundedness-evaluation-in-rag-applications" rel="alternate"></link><published>2025-01-21T00:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2025-01-21:/blog/automating-groundedness-evaluation-in-rag-applications</id><summary type="html">&lt;p&gt;As a software engineer working on a Retrieval-Augmented Generation (RAG) application, one of my primary concerns is the accuracy and reliability of the answers it provides. A RAG application works by first searching for content …&lt;/p&gt;</summary><content type="html">&lt;p&gt;As a software engineer working on a Retrieval-Augmented Generation (RAG) application, one of my primary concerns is the accuracy and reliability of the answers it provides. A RAG application works by first searching for content that matches a user's query and then passing the results and the query to a Large Language Model (LLM) to generate an answer. While this approach leverages the strengths of both search and generative AI, it is not immune to issues like hallucinations, misinterpretation of sources, and failure to properly cite them. These issues can be grouped under the umbrella term "groundedness." While groundedness is not the only quality of a RAG application response (other important qualities include relevance and style), it is a key metric for evaluating its reliability.&lt;/p&gt;
&lt;h1 id="the-challenge"&gt;The Challenge&lt;/h1&gt;
&lt;p&gt;Initially, my team evaluated the groundedness of our RAG application's answers manually. This involved running a set of test queries through the system, examining the answers and the sources, and determining if the answers were well-supported by the sources. We would run each query multiple times because LLM outputs are not deterministic and can vary slightly between runs. This manual process was time-consuming, taking approximately one developer-day to evaluate just one question.&lt;/p&gt;
&lt;h1 id="example"&gt;Example&lt;/h1&gt;
&lt;p&gt;Let's look at a made-up example. Consider this query:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;What are the health benefits of eating apples?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And this answer:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Eating apples has various benefits for your health:&lt;/p&gt;
&lt;p&gt;...&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cardiovascular Benefits&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Eating apples can reduce blood pressure [1].&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;...&lt;/p&gt;
&lt;p&gt;In conclusion, eating apples is a great choice for maintaining a healthy and happy life.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The '[1]' in the answer indicates that the LLM draws this argument from the first source passed to it in its context window.&lt;/p&gt;
&lt;p&gt;When we evaluate an answer manually, we have to look at the sources. Let's consider the following first source:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A 2019 clinical study found that regular apple consumption was associated with lower LDL cholesterol levels.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From this, we conclude that the argument is not well-grounded by the source because the source doesn't mention anything about the effect of eating apples on blood pressure. It mentions an association with cholesterol levels. In this example, the AI makes a leap from the cholesterol argument in the source to talking about blood pressure.&lt;/p&gt;
&lt;h1 id="goals"&gt;Goals&lt;/h1&gt;
&lt;p&gt;We set out to create an automated system for evaluating the groundedness of our RAG application's answers. Our goals for this system were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It should provide a quick and automated way to score the groundedness of an answer given the sources.&lt;/li&gt;
&lt;li&gt;The results should be consistent over multiple runs.&lt;/li&gt;
&lt;li&gt;The results should indicate the positive or negative effect of code, model, or prompt changes on groundedness.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Essentially, we needed a system that could provide a reliable signal-to-noise ratio, allowing us to confidently assess the impact of changes to our application.&lt;/p&gt;
&lt;p&gt;When these goals are achieved, we have a metric that allows us to measure the performance before and after a change and ensure we are moving in the right direction.&lt;/p&gt;
&lt;h1 id="off-the-shelf-solution"&gt;Off-the-Shelf Solution&lt;/h1&gt;
&lt;p&gt;Our first attempt at automating groundedness evaluation involved using an off-the-shelf solution called &lt;a href="https://docs.ragas.io/en/stable/"&gt;Ragas&lt;/a&gt;. The Ragas library implements an &lt;a href="https://docs.ragas.io/en/latest/concepts/metrics/available_metrics/faithfulness/"&gt;automatic groundedness metric&lt;/a&gt;. They call it faithfulness, but it's essentially the same thing. It works roughly like this: The library calls an LLM to break down the answer into individual statements. Then, multiple LLM calls fact-check each statement against the entire context (all the sources). The groundedness score is the percentage of statements that are fact-checked as true.&lt;/p&gt;
&lt;p&gt;While this seemed like a promising solution, it didn't work well in practice. We encountered issues with high variance between runs, and the scores didn't change significantly when we made changes to our code, prompts, or models. This meant the signal-to-noise ratio was too low to be useful.&lt;/p&gt;
&lt;h1 id="improved-solution"&gt;Improved Solution&lt;/h1&gt;
&lt;p&gt;We went back to the drawing board to figure out a better metric based on our manual evaluation process. The key insight was that instead of fact-checking each statement against all the sources, we could fact-check segments of the answer against the specific sources they referenced. Here's how it works:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The answer is broken down into paragraphs, with headers dropped (i.e., there's no point in fact-checking the header 'Cardiovascular Benefits').&lt;/li&gt;
&lt;li&gt;Paragraphs are further broken down into segments based on references. This is done without using an LLM, as we know where the references are in our answers.&lt;/li&gt;
&lt;li&gt;Each answer segment with references is fact-checked against its own references using an LLM.&lt;/li&gt;
&lt;li&gt;Answer segments without references are fact-checked in a second round against answer segments that were fact-checked as true in the first round.&lt;/li&gt;
&lt;li&gt;The final groundedness score is the percentage of segments that are fact-checked as true.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This approach more closely mirrors how a human would evaluate groundedness by focusing on the specific sources cited for each part of the answer. The LLM we use for fact-checking is prompted to provide an explanation for its decision before giving a true/false assessment. This can be thought of as a simple variant of the "chain-of-thought" technique. We used the explanation only for debugging. All groundedness calculations are done only with the final true/false assessment.&lt;/p&gt;
&lt;p&gt;Let's look at how this works with our example. When we break down the answer, we get one segment with a reference. It looks like this to the fact-checker LLM:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;text&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;1. Eating apples can reduce blood pressure&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;fact&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;A 2019 clinical study found that regular apple consumption was associated with lower LDL cholesterol levels.&amp;quot;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;An example response from the LLM in this case looks somewhat like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;explanation&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;The fact provided discusses the association between apple consumption and lower LDL cholesterol levels, not blood pressure. There is no information in the fact about apples reducing blood pressure, so the claim in the text cannot be verified based on the given fact.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;correct&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;false&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Note step #4 in the algorithm above. It is designed primarily to capture ungrounded arguments in introductions and conclusions that often don't have references. These rely on the body of the answer and theoretically shouldn't introduce new arguments. In our example, consider the conclusion:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In conclusion, eating apples is a great choice for maintaining a healthy and happy life.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I included only a partial made-up example, but let's assume the answer includes grounded statements about health benefits but nothing about happiness. In this case, the concluding statement would be fact-checked as false because the happiness claim cannot be supported by any of the positively fact-checked segments from step #3.&lt;/p&gt;
&lt;p&gt;The key to this solution is the understanding that we don't need to do anything fancy. We have the references in the response already, and it's easy to break down the response by the references. The off-the-shelf solutions are generic. They don't know the structure of your references, so they cannot parse them. Instead, they come up with a fancy LLM solution that we found to be suboptimal.&lt;/p&gt;
&lt;h1 id="the-details"&gt;The Details&lt;/h1&gt;
&lt;p&gt;The fact-checker LLM model we use is gpt-4o, set to 0 temperature. We also rely on &lt;a href="https://openai.com/index/introducing-structured-outputs-in-the-api/"&gt;structured output&lt;/a&gt;. We had good experience using this model for LLM-as-a-judge tasks in the past, so we ended up using it without trying different models or parameters.&lt;/p&gt;
&lt;p&gt;The system prompt is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You are a fact-checker that marks a text as correct or incorrect based on a provided fact. A text is correct only if all of the claims in it can be backed up by the fact. First, provide your explanation for your decision, then a correctness assessment that is either 'true' if the text is correct according to the facts or 'false' otherwise.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id="results-and-experiments"&gt;Results and Experiments&lt;/h1&gt;
&lt;p&gt;Using this custom algorithm, we achieved an average answer groundedness of 90% on our test set of 78 representative queries. We manually investigated about 30 fact-check LLM calls from the test set to conclude that the LLM-as-a-judge works well on this task (very unscientific, I know).&lt;/p&gt;
&lt;p&gt;Calculating the metric for the entire test set takes about 1 minute. This is a significant improvement over manual evaluation, which took about 1 day per query.&lt;/p&gt;
&lt;p&gt;One of the goals for the metric was to keep the variance small between runs. The results from 5 runs ranged between 88% and 92%. Is this too much? We tried to explore this in a series of small experiments to see how the metric performs when we change the prompt or model of the RAG application.&lt;/p&gt;
&lt;p&gt;In our RAG application, the system prompt for the LLM includes instructions for only using the provided sources when answering. We tried to make the instructions stricter, telling the LLM to only output sentences that could be supported by a reference. The resulting groundedness score remained 90%. This suggests we may be hitting a ceiling in terms of what can be achieved with prompt changes alone. Note that this is just an assumption. We didn't fully validate this.&lt;/p&gt;
&lt;p&gt;When we relaxed the instructions, telling the application to use its world knowledge whenever possible and only use sources when it couldn't support an argument from world knowledge, the groundedness score dropped to 82%. This indicates that our evaluation system is sensitive to changes that affect the reliance on sources.&lt;/p&gt;
&lt;p&gt;We also tested different models for generating the answers in our RAG application. An older model, gpt-3.5-turbo, scored 75%, while a newer but cheaper model, gpt-4o-mini, scored 77%. The model we launched our product with about a year ago, gpt-4-turbo, scored 87%. These results demonstrate that our evaluation system can detect differences in groundedness between different models.&lt;/p&gt;
&lt;h1 id="limitations-and-future-work"&gt;Limitations and Future Work&lt;/h1&gt;
&lt;p&gt;While our automated groundedness evaluation system is a major improvement over manual evaluation, it does have some limitations. It is a very strict measurement and penalizes answers that attempt to extrapolate or predict from the sources. This may not always be desirable, especially if the goal is to provide more forward-looking insights.&lt;/p&gt;
&lt;p&gt;There is also still some variance between runs, with scores shifting around 3-4 percentage points. However, this seems to be within an acceptable range, as the differences we observed from changing prompts and models were larger than this variance.&lt;/p&gt;
&lt;p&gt;Achieving 90% groundedness on our first measurement is a positive result in my book! It's also a bit tricky to sell because RAG is often sold as a solution to LLM hallucinations. If you've played with RAG systems, you know they are not immune to these problems. Telling leadership that 10% of the stuff the application produces is not well-grounded is problematic, but at least now we can measure it and potentially improve on that metric. Whether further improvements are necessary or even noticeable to users is an open question that we will continue to explore.&lt;/p&gt;
&lt;p&gt;I would like to stress again that LLM-as-a-judge is a really powerful tool. We have good experience with LLM-based metrics for information retrieval relevance, answer relevance, and now groundedness, all performing very well for our needs.&lt;/p&gt;
&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;We have developed a robust and efficient way to measure the groundedness of answers from our RAG application. This automated solution produces results comparable in quality to manual evaluation but in a fraction of the time. This tool allows us to confidently investigate new models, prompt changes, and other techniques for improving the groundedness of answers in our RAG application. While there's always room for improvement, this system represents a significant step forward in our ability to evaluate and enhance the reliability of our application.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This blog post was made with the help of Gemini Experimental 1206.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>GenAI App: To Stream or Not to Stream?</title><link href="/blog/genai-app-to-stream-or-not-to-stream" rel="alternate"></link><published>2025-01-03T16:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2025-01-03:/blog/genai-app-to-stream-or-not-to-stream</id><summary type="html">&lt;p&gt;Generative AI applications, particularly those with LLM-powered chat interfaces like ChatGPT, stream responses. We type our query, and the answer gradually generates, word by word. This streaming approach has become so commonplace that it's almost …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Generative AI applications, particularly those with LLM-powered chat interfaces like ChatGPT, stream responses. We type our query, and the answer gradually generates, word by word. This streaming approach has become so commonplace that it's almost expected. But is it always the best approach?&lt;/p&gt;
&lt;h1 id="the-cost-of-streaming"&gt;The cost of streaming&lt;/h1&gt;
&lt;p&gt;As you might know, I work on a Retrieval-Augmented Generation (RAG) application. This application currently streams responses, providing a familiar user interface. This comes at a cost. In my experience it's much harder to develop a streaming application, here's why.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Incremental processing:&lt;/strong&gt; With streaming, we often need to process the token stream incrementally. This adds complexity when dealing with various markups the LLM is instructed to use. For example, we tell the LLM to refer to the sources provided, so it might output something like &lt;code&gt;Grass is green [1]&lt;/code&gt;, where &lt;code&gt;1&lt;/code&gt; refers to the first source provided. Behind the scenes we replace the &lt;code&gt;[1]&lt;/code&gt; markup with a nicely rendered reference component. Another example is the instruction to the LLM to respond &lt;code&gt;&amp;lt;no-answer&amp;gt;Explain why you failed to answer here.&amp;lt;/no-answer&amp;gt;&lt;/code&gt; when it fails to answer with the provided sources. This is parsed and logged, and is used to change the logic of the execution slightly. There are a few other examples of markups the LLM is instructed to use, but you get the idea. Handling these markups is significantly easier when the entire response is available.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Rendering a reference component in the middle of an answer" src="/images/blog/leap_reference.webp"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;API response:&lt;/strong&gt; Managing the communication between the backend and frontend is more intricate with streaming. We utilize &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events"&gt;Server-Sent Events (SSE)&lt;/a&gt;, which, while effective, is less straightforward than simply responding with a JSON object.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Frontend Handling:&lt;/strong&gt; The frontend must handle the incoming stream of tokens, requiring more complex logic than simply displaying a complete response. For example, the response uses markdown, which is not trivial to process incrementally. In addition, the custom components we inject into this markdown for references and the like make it even harder.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Storage and Retrieval:&lt;/strong&gt; Streaming introduces complexities when it comes to storing and retrieving complete answers. For analytics purposes and to enable features like saving or sharing conversations, we need to store the full, generated response. This means that even if we stream the answer to the user, we have to simultaneously assemble the full response in the background for storage. When users later access their saved conversations, we have a non-streaming response to deal with. This creates duplication in our system: a streaming path for initial answer generation and a non-streaming path for displaying stored answers, increasing the overall system complexity. Essentially, we have to develop a way to convert a stream into a full answer for storage, and then present it to the user in its complete form later on.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We are a small team of three developers. This significantly amplifies the impact of the complexities above.&lt;/p&gt;
&lt;p&gt;Now, you should say: these are just technical complexities that are required for this type of product. Live with them! That's what your company is paying you for. Isn't it?&lt;/p&gt;
&lt;h1 id="llms-are-getting-faster"&gt;LLMs are getting faster&lt;/h1&gt;
&lt;p&gt;When we first launched this system at the beginning of 2024, generating a full answer took around 30 seconds. In such a scenario, streaming was a necessity. Without it, users would be staring at a blank screen for what seems like an eternity in web standards. Streaming allowed the user to start reading the response after just a few seconds, providing a much better user experience.&lt;/p&gt;
&lt;p&gt;Since the launch, the time required for preprocessing a query before we start answering has at least doubled. We introduced LLM-based translation stage, which improves the performance of the system for non-English queries. Another preparation stage that takes the query and the chat history and produces a search phrase. Without this stage, questions like 'more info please' could not work in conversational settings. There's also a reranking stage now, after fetching search results. All of these changes improved the quality of the answers significantly, or allowed completely new modes of interaction (in the case of the search phrase stage) at the expense of longer time until the answer starts to stream.&lt;/p&gt;
&lt;p&gt;Despite the increased preprocessing time, the actual answer generation now streams in at around 10 seconds on average. This is only due to the improved speed of newer LLM models. So while the preprocessing time doubled, the answer generation shrank to about a third of the initial duration. Overall, the ratio of time spent in answer generation is decreasing.&lt;/p&gt;
&lt;p&gt;You could argue that streaming remains preferable, as it provides users with initial content sooner. But consider that: when we launched, the ratio of time spent in answer generation was about 90% of the response time. These days it's closing to 50%. We're moving towards a scenario where the majority of time is spent preparing to answer, and less time actually generating the answer.&lt;/p&gt;
&lt;p&gt;Check out the impressive speed offered by Cerebras. &lt;a href="https://cerebras.ai/blog/llama-405b-inference"&gt;They can stream from Llama 3.1 405B - a GPT-4 class model - at 969 tokens per second&lt;/a&gt;. The answers by our system are about 400 words. This translates to roughly 533 tokens, according to &lt;a href="https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them"&gt;OpenAI's estimation of 3/4 words per token&lt;/a&gt;. This means that they can generate an answer in much less than 1 second.&lt;/p&gt;
&lt;p&gt;If such performance becomes commonplace, the time spent on answer generation will be dwarfed by the preprocessing steps within the RAG pipeline. Given these factors, there's a strong case for transitioning from a streaming to a non-streaming model. It's simpler and cheaper to develop and maintain, and in the long run, may not have any disadvantage to its streaming counterpart.&lt;/p&gt;
&lt;h1 id="a-reason-to-stream"&gt;A reason to stream&lt;/h1&gt;
&lt;p&gt;There's still one very compelling reason to retain streaming: user expectations. In the rapidly evolving world of GenAI, streaming has become the established standard, particularly for chat-based applications. Users are now used to this interactive style of response delivery, largely thanks to the influence of prominent products like ChatGPT. Diverging from this norm, even with a technically sound rationale, carries a significant risk. A non-streaming response might be perceived as 'broken', 'slow', or 'inferior' simply because it deviates from the established user experience. This presents a difficult product dilemma: how do we balance the internal benefits of increased team efficiency and reduced development overhead against the potential negative perception of users accustomed to the streaming standard?&lt;/p&gt;
&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;These days, streaming is undoubtedly the de-facto standard for GenAI applications, particularly in chat interfaces. The influence of leading products has firmly established this pattern in users' minds. Personally, I believe that with the ongoing acceleration of LLM generation speeds, we will see a gradual decline in the prevalence of streaming. The benefits of instantaneous, full responses will start to outweigh the perceived advantages of a token-by-token reveal. However, as a developer working on a GenAI application, it's a challenge to even consider moving away from streaming, especially when your application already streams responses. The established user expectation is a powerful force. Yet, the efficiency gains that could be realized by making the change are worth thinking about. We could streamline development, simplify our architecture, and potentially deliver a more robust and feature-rich experience in the long run.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This blog post was made with the help of Gemini Experimental 1206.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Thoughts on Personalising Retrieval-Augmented Generation</title><link href="/blog/thoughts-on-personalising-retrieval-augmented-generation" rel="alternate"></link><published>2024-12-23T23:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2024-12-23:/blog/thoughts-on-personalising-retrieval-augmented-generation</id><summary type="html">&lt;p&gt;I've been thinking about personalising Retrieval-Augmented Generation (RAG) lately. This is partly because my team is now building a chatbot that answers questions using a RAG setup. It's a continuation of my work with a …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I've been thinking about personalising Retrieval-Augmented Generation (RAG) lately. This is partly because my team is now building a chatbot that answers questions using a RAG setup. It's a continuation of my work with a previous team, where we developed a search system for market research content. Both products rely on the same underlying data, but the chatbot offers a modern, AI-driven, user experience.&lt;/p&gt;
&lt;p&gt;In the search system, personalisation usually meant boosting documents based on signals like the categories of the users' most-visited documents. Now, with the chatbot, we're revisiting personalisation in a slightly different context, and it's got me reflecting on how it can work effectively. These are just some initial ideas, and I'm not claiming to have all the answers—but I thought it'd be worth putting them out there.&lt;/p&gt;
&lt;h1 id="what-are-we-trying-to-achieve-with-personalisation"&gt;What Are We Trying to Achieve with Personalisation?&lt;/h1&gt;
&lt;p&gt;Let's start with a classic example: a user types "cheese" into our RAG system. What do they actually want? They could be interested in recent marketing campaigns for cheese, looking for consumer preferences, or focused on specific markets like the UK or US. The query is so vague that it's hard to produce a useful answer.&lt;/p&gt;
&lt;p&gt;Contrast this with a much more specific query: "What are the latest trends in cheddar consumption in the UK?" That's clear, and it gives the system a much better shot at providing a meaningful answer.&lt;/p&gt;
&lt;p&gt;So, where does personalisation fit in? If the query is already specific, I don't think personalisation adds much value. A well-designed RAG system—both the search and the answer generation—should handle specific queries effectively by retrieving the most relevant documents and using them to produce a coherent, accurate answer. But for vague queries like "cheese," personalisation can step in to improve the process.&lt;/p&gt;
&lt;h1 id="a-personalisation-proposal"&gt;A Personalisation Proposal&lt;/h1&gt;
&lt;p&gt;Here's the main idea: use personalisation to help expand under-specified queries.&lt;/p&gt;
&lt;p&gt;Imagine this: the query and previous messages in the conversation are passed through a personalisation step. This step evaluates the query to see if it's specific enough. If the query is under-specified, the step enriches it with context about the user (e.g., their preference for UK-specific data).&lt;/p&gt;
&lt;p&gt;From there, the personalised query is sent to the search engine, which retrieves the most relevant documents. These documents, along with the personalised query, are then passed to the language model to generate a final response.&lt;/p&gt;
&lt;h1 id="what-about-collecting-preferences"&gt;What About Collecting Preferences?&lt;/h1&gt;
&lt;p&gt;I haven't said much about how we'd gather user preferences—partly because I think it's a separate problem. In the past, we've kept track of things like the categories users visit most often, and I imagine something similar could work here.&lt;/p&gt;
&lt;p&gt;Alternatively, we could ask users directly about their context. For example, when they register, we could prompt them to choose a focus area or specify regions they're interested in. Either way, the real challenge is figuring out how to use this information effectively, not just how to collect it.&lt;/p&gt;
&lt;h1 id="final-thoughts"&gt;Final Thoughts&lt;/h1&gt;
&lt;p&gt;Personalising RAG systems isn't about fixing things that already work. If the user provides a clear, detailed query, the system doesn't need much help. But when faced with vague queries, personalisation could help by guiding the system in the right direction.&lt;/p&gt;
&lt;p&gt;These ideas aren't revolutionary, and they might not even work in practice, but they feel like a promising starting point. What do you think? Does this approach make sense, or are there better ways to think about personalisation in RAG? Let me know—I'd love to hear your thoughts.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This blog post was made with the help of Gemini Experimental 1206.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Mentoring toolkit</title><link href="/blog/mentoring-toolkit" rel="alternate"></link><published>2024-12-04T00:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2024-12-04:/blog/mentoring-toolkit</id><summary type="html">&lt;p&gt;I had the privilege of mentoring two junior software engineers over the past year. It was my first time doing something like this, so there was a lot to learn! To be honest, I don't …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I had the privilege of mentoring two junior software engineers over the past year. It was my first time doing something like this, so there was a lot to learn! To be honest, I don't think I got it quite right: many of the discussions meandered randomly around different topics, leaving an impression (on me, at least) that they didn't provide much value to the mentees. Having said that, I've learned a few tricks. These are pragmatic, simple tactics that helped me steer conversations in a direction that I think provides value to the mentee.&lt;/p&gt;
&lt;h1 id="build-trust-and-personal-connection"&gt;Build trust and personal connection&lt;/h1&gt;
&lt;p&gt;I'm lucky that I developed good personal connections with my mentees quite early on. I think none of the tactics below can work without that. I talk with my mentees about their hobbies, families, and activities outside of work. This all helps and makes the conversations much more engaging and interesting to both me and them.&lt;/p&gt;
&lt;h1 id="stay-independent-from-company-interests"&gt;Stay independent from company interests&lt;/h1&gt;
&lt;p&gt;Mentoring sessions should be a safe space. It means that my priority is the mentee, their growth, their feelings, etc., not the company. I try to make it very clear that they can speak freely about anything, even if it clashes with what the company expects from them. This is mostly done by building trust. There's no much point saying "you can talk about anything here". Make sure they can trust you, but if needed, make it clear that you are not a company representative in these mentoring sessions.&lt;/p&gt;
&lt;h1 id="do-not-shy-away-from-discussing-the-purpose-of-mentoring"&gt;Do not shy away from discussing the purpose of mentoring&lt;/h1&gt;
&lt;p&gt;When I started mentoring, I tried to almost hide the fact that these meetings were there to help the mentee. I was trying to be attentive to what they wanted to talk about, without providing much structure or suggesting targets for these meetings. This led to many of the meandering discussions described above. Later on, I learned that it's OK to discuss the purpose of the meetings with the mentee and see what they think. Maybe they have clear goals they want to pursue, maybe they don't. This leads us to the next point.&lt;/p&gt;
&lt;h1 id="explore-career-direction-and-goals"&gt;Explore career direction and goals&lt;/h1&gt;
&lt;p&gt;Try to discuss career goals and aspirations, but accept that you might not get a clear answer. Also, accept that it's absolutely fine not to answer this question at all! If there's no clear purpose, it's absolutely fine. To be honest, I couldn't answer these questions for most of my life, and I don't think this is necessarily a problem.&lt;/p&gt;
&lt;h1 id="find-ways-to-explore-interests-at-work"&gt;Find ways to explore interests at work&lt;/h1&gt;
&lt;p&gt;A few months ago, I presented my manager a long list of technologies that I wanted to explore. He suggested going over the list one by one and figuring out if there were opportunities to explore each item within our work context. We asked: what other teams are using these technologies? Is there a way I can help these teams and learn something new along the way? That was a brilliant idea! I reached out to a few teams and got the ball rolling on things I wanted to learn. While I haven't used this technique yet with my mentees, I took note and plan to incorporate it in the future.&lt;/p&gt;
&lt;h1 id="retrospect"&gt;Retrospect&lt;/h1&gt;
&lt;p&gt;Don't run the tricks above just once. Go back to them. Ask the mentee what works. Make sure the mentoring sessions work for them. Make sure they trust you and can speak freely. The last thing you want is for them to say "it's useful" just to avoid offending you.&lt;/p&gt;
&lt;h1 id="take-notes"&gt;Take notes&lt;/h1&gt;
&lt;p&gt;Make sure to keep notes of the important points raised in these meetings. Personally, I don't share them with the mentee, because I think it can be overwhelming and suggest they need to do something about the notes, which is not the point. I take notes to help me ask questions about things they raised that are important to them. It helps with the retrospectives mentioned above.&lt;/p&gt;
&lt;h1 id="summary"&gt;Summary&lt;/h1&gt;
&lt;p&gt;Mentoring is a journey. While my first year of mentoring had its challenges, particularly with keeping discussions focused and valuable, I've learned a few effective tricks. Being transparent about the purpose of mentoring, understanding the mentee's goals, and regularly checking in on the effectiveness of the conversations are very useful. On the other hand, don't force these! Building trust and personal relationships should be the top priority, and it's fine to take it easy, have some meandering conversations, and have a good time.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Notes from AIAI London 2024</title><link href="/blog/notes-from-aiai-london-2024" rel="alternate"></link><published>2024-11-08T10:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2024-11-08:/blog/notes-from-aiai-london-2024</id><summary type="html">&lt;p&gt;&lt;img alt="AIAI GenAI Summit" src="/images/blog/aiai_gen_ai_summit.webp"&gt;&lt;/p&gt;
&lt;p&gt;I attended the &lt;a href="https://world.aiacceleratorinstitute.com/location/london/"&gt;AI Accelerator Institute's Generative AI Summit that happened yesterday in London&lt;/a&gt; - AIAI London in short. Here are my notes. These are by no means exhaustive. Just a bunch of things I found …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="AIAI GenAI Summit" src="/images/blog/aiai_gen_ai_summit.webp"&gt;&lt;/p&gt;
&lt;p&gt;I attended the &lt;a href="https://world.aiacceleratorinstitute.com/location/london/"&gt;AI Accelerator Institute's Generative AI Summit that happened yesterday in London&lt;/a&gt; - AIAI London in short. Here are my notes. These are by no means exhaustive. Just a bunch of things I found interesting.&lt;/p&gt;
&lt;h1 id="themes"&gt;Themes&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Multiple talks implied that companies struggle to get GenAI applications to production, or getting value from them. These talks focused on best practices for building AI applications (make sure there are guardrails in place, develop evaluation tools, etc.) or on making sure the applications produce value. As someone who works on a GenAI application that is in production for almost a year I was a bit surprised. It felt like there's an underlying problem of companies trying to come up with AI solutions for the sake of it (the "everything is a nail" problem).&lt;/li&gt;
&lt;li&gt;LLM as a judge is a common practice, and proved to be useful in large variety of cases. From my recent experience evaluating our GenAI application with the help of LLMs I'm not surprised (stay tuned for a blog post about this subject). This is a very powerful technique.&lt;/li&gt;
&lt;li&gt;Two talks about GenAI in healthcare stressed the point that we shouldn't let GenAI take decisions. The final decision, at least for now, should always be done by a human. AI can help us get to these decisions faster. This approach aligns with &lt;a href="/blog/thoughts-about-agi"&gt;my thoughts about AGI&lt;/a&gt;, that we are not ready for AI to take decisions, not because of AI capabilities, but because of social structures and ethics that help us navigate decision making.&lt;/li&gt;
&lt;li&gt;There were some discussions about safety. It wasn't about 'AI will kill us all', but about ensuring we build AI applications that do no harm, either to people or to the companies that develop them. A few speakers tackled these from different angles: healthcare, regulation (e.g. the EU AI Act), and the importance of putting guardrails in place when developing GenAI applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="talks"&gt;Talks&lt;/h1&gt;
&lt;p&gt;These are the talks that stood out to me personally.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;"Can't I just ask ChatGPT?" Production pipelines shaping the visual intelligence renaissance&lt;/strong&gt;. Dr. Dmitry Kazhdan from Tenyks talked about how new GenAI models simplifies and democratise the computer vision landscape. Instead of long and expensive processes for training AI models in house, most modern computer vision applications can be built using off-the-shelf AI models. The training process is replaced by prompting, potentially with minor fine-tuning. I'm not a data scientist, and have no interest in computer vision, so why did this talk speak to me? Mainly because it was full of excellent insight about building advance search capabilities on top of videos. For example, they discussed techniques to extract metadata from the raw material at index time, and how to search through this metadata on simple queries, or fallback to vector search on more complicated queries. I need to dig through &lt;a href="https://www.tenyks.ai/blog"&gt;Tenyks' blog&lt;/a&gt; to learn more about these ideas. I expect these to be super valuable for the work I'm doing.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Optimising GenAI outcomes in financial services with DSPy&lt;/strong&gt;. This very technical talk by Alberto Romero from Citi showed how to use DSPy to optimise system prompts, including few-shot, and chain-of-thought techniques, with examples and metrics. I was aware of DSPy, but nothing more than that. As mentioned earlier, I invested a lot of time recently on our quality evaluation suite. A few days ago I claimed that "we cannot achieve a higher groundedness  score (also known as faithfulness score) with prompt changes alone". This DSPy talk inspires me to try to automatically optimise for this metric. I still suspect that we are close to hitting a limit. We might be able to optimise for this metric on the expense of some other goals. In any case, that would be an interesting experiment.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Large language models in practice: Insights from building LLM-based pipelines for paediatric healthcare data&lt;/strong&gt;. This talk by Pavithra Rajendran and Shiren Patel from the NHS had two equaly interesting parts. First, Shiren dived into goals and design principles for AI applications for healthcare: human-in-the-loop, do no harm, explainability, and focusing on making clinicians more efficient, among other ideas. The second part, by Pavithra, was more technical. The NHS has to run everything in house and got no budget for expensive GPUs (surprise surprise) so the AI team had to figure out ways to work with very small LLMs that can run efficiently on CPUs. They showed a few examples of successes from running these models.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="small-talk"&gt;Small talk&lt;/h1&gt;
&lt;p&gt;Beyond the presentations, I enjoyed the chats I had with the attendees. In most (if not all) of the conferences I've been to before I barely had any interactions with others. Granted, this was a long time ago, so maybe I changed, but I think people were more approachable than I'm used to.&lt;/p&gt;
&lt;p&gt;I met two familiar faces and enjoyed hearing what they do these days. I had interesting conversations about relationships between productivity and religion, measuring carbon footprint of aeroplanes from satellite images, &lt;a href="/blog/thoughts-about-agi"&gt;thoughts about social readiness to GenAI and AGI&lt;/a&gt;, how ChatGPT is way more 'human' in voice mode, and more.&lt;/p&gt;
&lt;p&gt;In conclusion, I had great time at AIAI London. I learned a few tricks, got inspiration to try a few ideas, met interesting people, and enjoyed the presentations and the conversations I had.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Thoughts about AGI</title><link href="/blog/thoughts-about-agi" rel="alternate"></link><published>2024-10-11T13:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2024-10-11:/blog/thoughts-about-agi</id><summary type="html">&lt;p&gt;There's a lot of buzz these days around AI, and AGI in particular. It seems like everyone is busy sharing their thoughts on AGI on the internet. I would love to do the same on …&lt;/p&gt;</summary><content type="html">&lt;p&gt;There's a lot of buzz these days around AI, and AGI in particular. It seems like everyone is busy sharing their thoughts on AGI on the internet. I would love to do the same on this small corner of the internet of mine.&lt;/p&gt;
&lt;p&gt;In this post, I'm arguing that
- AGI, as it stands, is not a very useful measure of technological advancement.
- If anything, AGI is mostly a function of social readiness.&lt;/p&gt;
&lt;h1 id="definitions"&gt;Definitions&lt;/h1&gt;
&lt;p&gt;So, what is Artificial General Intelligence? There are many definitions. &lt;a href="https://openai.com/charter/"&gt;OpenAI defines it as "highly autonomous systems that outperform humans at most economically valuable work"&lt;/a&gt;. Sam Altman further said that AGI is &lt;a href="https://youtu.be/vd9GxG5Qn-k"&gt;"the equivalent of a median human that you can hire as a co-worker... they could do anything that you'd be happy with a remote co-worker doing"&lt;/a&gt;. DeepMind recently defined &lt;a href="https://arxiv.org/abs/2311.02462"&gt;5 levels of AGI&lt;/a&gt; with level 1 meaning "equal to or somewhat better than an unskilled human". Levels 2 to 4 mean "at least 50th/90th/99th percentile of skilled adults". Level 5 is reserved for outperforming all humans. They further claim we are currently at level 1.&lt;/p&gt;
&lt;p&gt;There are many more. For the interested reader I recommend checking the DeepMind paper above. It contains loads of relevant information. Also, check out &lt;a href="https://arxiv.org/abs/2303.12712"&gt;Microsoft's 'Sparks of AGI' paper from last year&lt;/a&gt; and &lt;a href="https://www.researchgate.net/publication/271390398_Artificial_General_Intelligence_Concept_State_of_the_Art_and_Future_Prospects"&gt;Goertzel's AGI review paper from 2014&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this blog post I'm going to mostly address the definition by OpenAI about AI capability to work like a human. Note that this excludes many other intellectual things people do: reading a book, playing an instrument, engaging in a pointless yet interesting discussion. No, we are not talking about these in this post. Let's talk about work.&lt;/p&gt;
&lt;h1 id="my-parents"&gt;My parents&lt;/h1&gt;
&lt;p&gt;My mother is a primary school teacher. Or, sort of a teacher. She doesn't have the necessary qualifications so cannot teach the curricular material. One can say she's working with primary school children. Her classes are all about learning about nature. She brings animals to the class - snakes, rabbits, insects, etc. Show them to the children and teach them about their senses and behaviours. She's also gardening with the children and is very proud about the school garden she maintains.&lt;/p&gt;
&lt;p&gt;My father runs a small accommodation business in our village. It's a Bedouin village. The bedouin community doesn't usually mix with the Jewish community in Israel, so our story as a Jewish family living together with Bedouins is quite unique. This is one of the main attractions for people coming to my father's place. People come over to hear the stories.&lt;/p&gt;
&lt;p&gt;Back to AI. Let's think how AGI can do these types of work. Can it? What does it mean for AI if it can? And if it can, is that a capability of the AI or of the primary school children, and the people interested in stories about co-existence, who can now be satisfied by listening and learning from an AI?&lt;/p&gt;
&lt;p&gt;Now, you can say "Tom, stop this emotional BS, it's just an irrelevant anecdote and it doesn't mean anything for the big picture. And besides, your parents exist on the fringes off society, they aren't the norm." and you will be totally right! You &lt;em&gt;should&lt;/em&gt; say that. In fact, if you didn't say that, that's a shame. I expected more from you, my critical reader.&lt;/p&gt;
&lt;p&gt;Let's dive deeper.&lt;/p&gt;
&lt;h1 id="interfacing-with-people-and-the-physical-world"&gt;Interfacing with people and the physical world&lt;/h1&gt;
&lt;p&gt;There are many jobs in which interacting with other people is the main activity: teachers, consultants, managers, sales representatives, etc. Yes, the world might be changing by AI but to replace someone in these jobs your goal is not necessarily to replace the person, but to replace the entire system around it.&lt;/p&gt;
&lt;p&gt;Many other jobs are about interfacing with the physical world. Drivers, builders, and plant workers come to mind. Since the industrial revolution we are pushing to automate more and more of these jobs, but that has nothing to do with AGI either.&lt;/p&gt;
&lt;p&gt;In both of these examples I would argue that achieving AGI would reflect much more about the people and the social systems around the AI, than about the AI itself.&lt;/p&gt;
&lt;p&gt;Now, Sam Altman is a smart guy. His definition of AGI avoids this problem by saying that AGI can replace the work of a &lt;em&gt;remote worker&lt;/em&gt;. By that, I think he tries to avoid any physical aspect of the work. But interfacing with other people still remains a tricky point for AGI.&lt;/p&gt;
&lt;h1 id="the-ceo-dilemma"&gt;The CEO dilemma&lt;/h1&gt;
&lt;p&gt;Now imagine GPT 5 comes out, and Sam Altman announces 'AGI is here!'. This model can do the work of the average remote worker. Large language models often exhibit a &lt;a href="https://www.oneusefulthing.org/p/centaurs-and-cyborgs-on-the-jagged?open=false#%C2%A7inside-the-jagged-frontier"&gt;jagged frontier&lt;/a&gt; - they can do some tasks amazingly well and fail miserably on simpler tasks (try to play a rock paper scissors with an LLM). So, it happens to be that this new GPT 5 has exactly the right capabilities to replace the CEO in the your company. It will make better decisions, have perfect understanding of the business, clients, and market, form an immaculate strategy, write highly motivational speeches, manage to align people to their vision, and drive the company forwards. This doesn't mean AI will replace the entire company. You still need people to physically meet with clients, IT support to fix devices when they break, cleaners, you name it. But the CEO, there's no need for them any more. What happens in this situation? Will they accept the new reality and just leave? Will the employees want them to leave, knowing AI can make better calls most of the time? Or do we still want to be guided be people? I think we do. I think we are not ready to be told what to do by an AI, even if we know well that the AI guidance is top notch.&lt;/p&gt;
&lt;h1 id="my-point"&gt;My point&lt;/h1&gt;
&lt;p&gt;We've covered examples of jobs that involve integration with social systems and human processes. For these, I don't think it's clear what AGI means exactly, as the AI capabilities question is not the most important question. The main reason AI hasn't take over teachers, drivers, and CEOs is not a technical question, it's a question of social readiness. We, as humans, have some work to do to figure out what it means to live alongside AI.&lt;/p&gt;
&lt;p&gt;So, what's next? I'm not sure. I think tech people generally underestimate the amount of social inertia we all operate in. Overall I think things will evolve but slower than most people predict. I guess the technology will improve, but I don't think AGI, as currently defined, is something that will happen along these advancements. The main reason is that these definitions don't take social context into account and are, therefore, not very useful. To be honest, I think we will forget the term AGI, or it will change from what it currently means, as I don't think the current term is very useful.&lt;/p&gt;
&lt;p&gt;Note that none of that is about the usefulness of AI. There are plenty of use cases and I have no doubt it is going to have great implications on society.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This blog post was made with the help of ChatGPT and Claude 3.5 Sonnet.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Starting a tech book club!</title><link href="/blog/starting-a-tech-book-club" rel="alternate"></link><published>2024-08-29T23:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2024-08-29:/blog/starting-a-tech-book-club</id><summary type="html">&lt;p&gt;&lt;img alt="A stack of software engineering books" src="/images/blog/book_club_cover.avif"&gt;&lt;/p&gt;
&lt;p&gt;I'm kickstarting a technical book club! It's going to be based around a mailing list with one thread per week discussing the scope covered that week. I have some ideas for what to read, but …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="A stack of software engineering books" src="/images/blog/book_club_cover.avif"&gt;&lt;/p&gt;
&lt;p&gt;I'm kickstarting a technical book club! It's going to be based around a mailing list with one thread per week discussing the scope covered that week. I have some ideas for what to read, but happy to get feedback and hear from other interested people.&lt;/p&gt;
&lt;p&gt;If this sounds like an interesting idea, join me on &lt;a href="https://groups.io/g/tech-book-club"&gt;https://groups.io/g/tech-book-club&lt;/a&gt;&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>A non-review of half of Designing Data-Intensive Applications</title><link href="/blog/a-non-review-of-half-of-designing-data-intensive-applications" rel="alternate"></link><published>2024-08-02T12:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2024-08-02:/blog/a-non-review-of-half-of-designing-data-intensive-applications</id><summary type="html">&lt;p&gt;I read the first seven chapters of "Designing Data-Intensive Applications" before deciding to stop. It's about half of this hefty book. In the spirit of learning in public through this blog, I'll reflect on what …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I read the first seven chapters of "Designing Data-Intensive Applications" before deciding to stop. It's about half of this hefty book. In the spirit of learning in public through this blog, I'll reflect on what I learned from this experience before putting the book aside.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Book cover" src="/images/blog/designing_data_intensive_applications_cover.avif"&gt;&lt;/p&gt;
&lt;p&gt;The book delves deep into the internals of databases and distributed systems. By dive deep I mean, really deep! It starts slowly with the first chapter covering reliability, scalability, and maintainability - the main concerns in these sorts of applications. From there it goes into covering types of databases (SQL, NoSQL, graph) and query languages, the techniques databases use to store data on disk, data serialization formats, replication, partitioning, and transactions. The list goes on, but I will stop here, because that's what I read.&lt;/p&gt;
&lt;h1 id="the-review-part"&gt;The review part&lt;/h1&gt;
&lt;p&gt;This is a very well-written book that's easy to read and nicely structured. I'm impressed by how much the author knows and how well he explains complex ideas.&lt;/p&gt;
&lt;p&gt;The book is very nuanced and detailed. The author leads the reader through historical context, covering issues and trade-offs in each topic. This makes the book very informative and gives you a deep understanding of the topics.&lt;/p&gt;
&lt;p&gt;There's zero fluff in this book. Every bit of information serves a purpose. The author doesn't just state opinions; issues are discussed, solutions are explained, including trade-offs and historical context. Everything is supported with examples and references.&lt;/p&gt;
&lt;p&gt;I also like how the book jumps into the details quickly. There's just enough introduction to set the stage, then it's straight into the meat of each topic. This keeps things engaging and lets the book cover a lot of ground.&lt;/p&gt;
&lt;h1 id="the-non-review-part"&gt;The non-review part&lt;/h1&gt;
&lt;p&gt;So, why am I stopping, and what's with the "non-review" in the title?&lt;/p&gt;
&lt;p&gt;When I picked up this book, I had two main goals:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I wanted to learn more about solving scaling problems. Why? Because I find it interesting, even though I don't deal with these issues in my current job.&lt;/li&gt;
&lt;li&gt;I wanted to get better at designing software systems, dipping my toes into software architecture. I think understanding data challenges should be a good start. It sounds like the harder part of the problem, usually. It's also an area in software architecture that I'm not very familiar with.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Did I achieve these goals? Not really. The main issue is that I'm not in a position to learn well from this book right now. I understand what I'm reading, but I don't have hands-on experience with the problems it discusses and don't have the opportunities to tackle these challenges in my day-to-day work.&lt;/p&gt;
&lt;p&gt;This makes it hard for me to really absorb the knowledge. I get it while I'm reading, but I forget it quickly because I can't see how to use it in my work.
Compare this to the last technical book I read, "The Pragmatic Programmer" (see my review &lt;a href="/blog/the-pragmatic-programmer-review"&gt;here&lt;/a&gt;). That book immediately impacted how I work as the concepts resonated with me and provided actionable solutions for many issues I face.
There's just so much to learn and so little time. I can't justify spending time on a 500+ page book that doesn't help me right now, no matter how good it is.&lt;/p&gt;
&lt;p&gt;Having said all that. Here are a few tips for my future self (and maybe for you too), in case I need to get on top of these topics in the future:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The chapter summaries in this book are great. They give you a quick overview of the main points and trade-offs for each topic. If I need to refresh my memory, I should skim through the summaries first, and get back to the chapter body if I need more information.&lt;/li&gt;
&lt;li&gt;The book is so well-organized that it should be ideal as a reference book. I'm sure it'll be easy to find specific information when I need it in the future.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, I'm putting "Designing Data-Intensive Applications" aside for now. But I do want to come back to it someday. First, I need to gain more experience and start dealing with some of the problems the book covers. I'm sure it'll be super valuable then.&lt;/p&gt;
&lt;p&gt;To sum up, this is a great book, but it's not the right time for me to read it. I'll focus on resources that are more directly useful for my current work and immediate career goals. And when the time is right, I'll definitely pick this book up again.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This blog post was made with the help of Claude 3.5 Sonnet and GitHub Copilot.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Anthropic is onto something interesting with Artifacts</title><link href="/blog/anthropic-is-onto-something-interesting-with-artifacts" rel="alternate"></link><published>2024-07-09T23:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2024-07-09:/blog/anthropic-is-onto-something-interesting-with-artifacts</id><summary type="html">&lt;p&gt;A few weeks ago, Anthropic released a new feature to their Claude chatbot — &lt;a href="https://www.anthropic.com/news/claude-3-5-sonnet"&gt;Artifacts&lt;/a&gt;. It was announced together with Claude 3.5 Sonnet. You can find more details in the section about the feature. It's …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A few weeks ago, Anthropic released a new feature to their Claude chatbot — &lt;a href="https://www.anthropic.com/news/claude-3-5-sonnet"&gt;Artifacts&lt;/a&gt;. It was announced together with Claude 3.5 Sonnet. You can find more details in the section about the feature. It's an interactive UI panel that can run HTML, JS, and CSS generated by the model. For example, you can ask the chatbot to create a platformer game and can then interact with it directly in the chatbot interface. As with anything involving AI chatbots, you can work on the Artifact iteratively together. This is nice and useful but not groundbreaking. It saves you the time to copy things over to your editor or another site to try them out. Very convenient, but not much more than that.&lt;/p&gt;
&lt;p&gt;Then they added a new feature that makes Artifact far more interesting — &lt;a href="https://support.anthropic.com/en/articles/9547008-publishing-and-remixing-artifacts"&gt;publishing and remixing Artifacts&lt;/a&gt;. It's now possible to publish an Artifact and get a link you can share on the internet. Now, I think this is groundbreaking! It democratises creating simple web apps. Everyone can now create something and share it with others without any technical knowledge. The remixing bit is the ability to take a published Artifact and start chatting about it with Claude in a new discussion.&lt;/p&gt;
&lt;p&gt;While this is an interesting paradigm for creating code, I'm worried about security here. As these tiny generated apps start appearing all over the internet, social media, etc. how can we ensure they are safe? Having said that, my understanding of web security is very basic. I would love to see some analysis of this feature by someone who understands the problem better.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>In-browser LLM on Chrome Canary</title><link href="/blog/in-browser-llm-on-chrome-canary" rel="alternate"></link><published>2024-07-03T23:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2024-07-03:/blog/in-browser-llm-on-chrome-canary</id><summary type="html">&lt;p&gt;The nightly version of Google Chrome ships with an on-device LLM. The model it runs is &lt;a href="https://deepmind.google/technologies/gemini/nano/"&gt;Gemini Nano&lt;/a&gt;. Some documentation about this can be found &lt;a href="https://github.com/explainers-by-googlers/prompt-api/tree/main"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It's not surprising to be honest, that tiny LLMs …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The nightly version of Google Chrome ships with an on-device LLM. The model it runs is &lt;a href="https://deepmind.google/technologies/gemini/nano/"&gt;Gemini Nano&lt;/a&gt;. Some documentation about this can be found &lt;a href="https://github.com/explainers-by-googlers/prompt-api/tree/main"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It's not surprising to be honest, that tiny LLMs make their way into browsers. We have already heard that &lt;a href="/blog/mozilla-is-experimenting-with-local-alt-text-generation-in-firefox"&gt;Mozilla is experimenting with automatically generating image alt tags with on-device AI&lt;/a&gt;. I'm sure we will see similar initiatives come to fruition in the upcoming months. What I do hope, though, is that some of these improvements will also make their way into web standards. That will probably take a bit more time.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>The Pragmatic Programmer Review</title><link href="/blog/the-pragmatic-programmer-review" rel="alternate"></link><published>2024-06-21T22:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2024-06-21:/blog/the-pragmatic-programmer-review</id><summary type="html">&lt;p&gt;&lt;img alt="The Pragmatic Programmer 20th Anniversary Edition book cover" src="/images/blog/pragmatic_programmer_cover.avif"&gt;&lt;/p&gt;
&lt;p&gt;The Pragmatic Programmer 20th Anniversary Edition, by David Thomas and Andrew Hunt, offers high-level, actionable advice for software engineers. Unlike many technical books that focus on specific coding practices or languages, it focuses on cultivating …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;img alt="The Pragmatic Programmer 20th Anniversary Edition book cover" src="/images/blog/pragmatic_programmer_cover.avif"&gt;&lt;/p&gt;
&lt;p&gt;The Pragmatic Programmer 20th Anniversary Edition, by David Thomas and Andrew Hunt, offers high-level, actionable advice for software engineers. Unlike many technical books that focus on specific coding practices or languages, it focuses on cultivating a mindset that leads to better software development practices.&lt;/p&gt;
&lt;p&gt;The authors emphasize principles like designing for ease of change, adapting to evolving environments and requirements, and embracing incremental development with regular reflection. These concepts may seem abstract, but the book excels at providing concrete, actionable advice for putting them into practice.&lt;/p&gt;
&lt;p&gt;I think that's the book's greatest strength: it tackles high-level concepts and challenges, and yet manages to provide practical advice that you can apply immediately. It is full of pragmatic advice for improving the most important soft and hard skills required in modern software engineering.&lt;/p&gt;
&lt;p&gt;The fact that the advice in the book remains, in most part, quite high-level, doesn't mean that it shies away from technical discussion. It highlights the importance of mastering basic tools like the command line and version control, and discusses testing, refactoring, automation, various design patterns, and other technical topics in detail.&lt;/p&gt;
&lt;p&gt;In this review, I'll share some of my key takeaways from this seminal book, discuss its impact on my work, and explore how its principles can be adapted for different roles in the tech industry.&lt;/p&gt;
&lt;h2 id="my-key-takeaways"&gt;My Key Takeaways&lt;/h2&gt;
&lt;p&gt;Here are some of the key principles and concepts from The Pragmatic Programmer that have resonated with me:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Easy to Change (ETC) Design:&lt;/strong&gt; The authors stress that good software should be easy to modify. The world is changing, decisions change, and so should our software systems. This principle underpins many of the recommendations in the book. It is tightly linked to agility.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Don't Repeat Yourself (DRY) and Orthogonality:&lt;/strong&gt; These closely related principles are about eliminating knowledge duplication across all aspects of a system and ensuring components are independent. It's not really about avoiding code duplication, but about avoiding duplication of knowledge. This extends to documentation, comments, and even communication patterns. For example, think about a concept, idea, or decision that where communicated multiple times in different ways. Maybe this can be avoided by creating a single source of truth.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tracer Bullets and Prototypes:&lt;/strong&gt; The tracer bullet approach involves rapidly developing a thin slice of functionality that integrates all system components, providing a foundation for iterative development. This is different from prototypes, which are throwaway code meant for testing ideas. Both have their place, but they serve very different functions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Agility and Adaptability:&lt;/strong&gt; The ability to respond to change is crucial, whether at the code or the project level. The book critiques the idea of blindly following methodologies and processes, and instead, advocates for an agile, feedback-driven approach that allows for continuous improvement - try different things, fail fast, and keep what works. It cautions against replicating processes from other companies (Big Tech, usually) without understanding the context.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Requirements Learning:&lt;/strong&gt; No one knows what they want, so the requirements should be learned, with the clients, in a feedback guided process. Better to think about requirements as business needs. The goal of the developer in this context is to give feedback to highlight the trade-offs and ask questions to work out the requirements with the stakeholders.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pragmatic Teams:&lt;/strong&gt; The book extends its advice to team dynamics and project management, emphasizing the importance of communication, collaboration, and shared responsibility. It discusses some of the ideas targeted at individuals in earlier chapter in a new lens. One example I liked in particular is the concept of tracer bullet teams, in which the team should be optimised to deliver tracer bullets - fully integrated software. It requires good communication paths between all necessary parties.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="personal-impact"&gt;Personal Impact&lt;/h2&gt;
&lt;p&gt;Since I started reading this book, I've found myself applying its principles almost daily. It's not just about writing better code; it's about approaching problems more thoughtfully, communicating more effectively with my team, and taking a more holistic view of software development. I find myself constantly referring back to the principles in this book when making decisions and communicating with my team. It's given me a new vocabulary and framework for thinking about software development.&lt;/p&gt;
&lt;p&gt;I'm currently exploring ways to improve my communication with colleagues and stakeholders. Instead of simply following requirements, I'm experimenting with providing more thoughtful feedback focused on trade-offs and implications. For instance, I'm learning to highlight potential maintenance burdens or how certain requirements might affect other aspects of a project.&lt;/p&gt;
&lt;p&gt;The book has also prompted me to start thinking more critically about our development processes and ceremonies. I try to be more mindful about the value these bring and suggest improvements when needed. This is an ongoing challenge, but I'm excited about the potential to streamline our workflows and improve team efficiency.&lt;/p&gt;
&lt;p&gt;I make sure to apply the Easy to Change (ETC) Design principle in my decision-making process. When faced with unclear requirements, I'm trying to opt for reduced scope and functionality to keep the system flexible. It's a balancing act I'm still learning, but I'm optimistic about the long-term benefits of this approach in making our projects more adaptable to changing needs and more maintainable in the long run.&lt;/p&gt;
&lt;p&gt;Perhaps most significantly, the book has inspired me to be more intentional about my learning and professional growth - a journey that's very much in progress. I'm exploring new ways to seek out and process knowledge, and constantly looking for opportunities to apply what I'm learning. The recent increase in activity on this blog is part of this ongoing commitment to continuous improvement.&lt;/p&gt;
&lt;h2 id="adapting-the-book-for-different-readers"&gt;Adapting the Book for Different Readers&lt;/h2&gt;
&lt;p&gt;While The Pragmatic Programmer is primarily aimed at software engineers, many of its lessons are applicable to other roles in the tech industry. The suggestions below are definitely non exhaustive. These came to mind as I was reading the book, and thinking about my colleagues and daily interactions. I'm sure there are many more ways to adapt its principles to different roles.&lt;/p&gt;
&lt;h3 id="engineering-managers"&gt;Engineering Managers&lt;/h3&gt;
&lt;p&gt;Non technical engineering managers who want to better understand their reports can benefit from understanding the guiding principles for Pragmatic Programmers, Teams, and Projects.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Chapter 1 - A Pragmatic Philosophy:&lt;/strong&gt; This is the least technical chapter in the book, and it's a great starting point for understanding the mindset of a Pragmatic Programmer. Relevant topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Topic 3 - Software Entropy:&lt;/strong&gt; All software degrade over time. This is a good starting point for understanding the importance of maintenance and refactoring.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Topic 4 - Stone Soup and Boiled Frogs:&lt;/strong&gt; This confusingly named topic covers the importance of taking small steps towards change, how to convince stakeholders of the benefits of your approach, and the importance of noticing and acknowledging changes in your environment.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Topic 5 - Good Enough Software:&lt;/strong&gt; This topic is about discussing the quality of a deliverable as a trade-off. Good software now is better than perfect software later. Or is it? It depends on the context! Software quality should be discussed as other requirements are.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Chapter 2 - A Pragmatic Approach (or, simply, generic advice for good design):&lt;/strong&gt; All but the Domain Languages and Estimation topics are great! They cover what's important in software design without getting very technical. I think non technical people who are responsible for delivering technical projects can benefit from understanding these principles.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Chapters 8 and 9 - Pragmatic Projects and Pragmatic Teams:&lt;/strong&gt; To be honest, I don't understand the division between these two chapters. They are both about teams and projects. Overall they discuss requirements, collaboration, agile practices, and providing value to our users. I think most of the content here will be relevant to engineering managers, except, maybe for topic 46 about problem solving skills.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In addition to this, there's very good advice about staying agile, working incrementally, and adapting to change in topics 27, 48, and 50. I don't know why these are spread over three different chapters, but they are all very relevant to managing software projects.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you're short on time and want to start somewhere I would say start with either chapter 2 if you're interested in software design, chapters 8 and 9 if you're interested in teams and projects related topics, or the topics about agility.&lt;/p&gt;
&lt;h3 id="product-managers"&gt;Product Managers&lt;/h3&gt;
&lt;p&gt;Product managers, there's something in here for you as well! "The Requirements Pit" topic is a great starting point. Related to this are also the "Good-Enough Software" and "Delight Your Users" topics. The first two were discussed above, so unnecessary to repeat here. In "Delight Your Users" the authors discuss the importance of understanding the expectations of your users, and how to align your software with those expectations, as it is not the software that users are usually care about, but what it can do for them.&lt;/p&gt;
&lt;p&gt;The idea of tracer bullets teams, discussed in the "Pragmatic Teams" topic, is also very relevant. &lt;a href="https://en.wikipedia.org/wiki/Conway's_law"&gt;Conway's Law&lt;/a&gt; is mentioned a few topics earlier. It states that:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Organizations which design systems are constrained to produce designs which are copies of the communication structures of these organizations.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So, if you want to improve your software, you might want to improve your team's communication first, making sure that communication paths are built end-to-end, connecting engineers with stakeholders and users.&lt;/p&gt;
&lt;h2 id="weaknesses-and-criticisms"&gt;Weaknesses and Criticisms&lt;/h2&gt;
&lt;p&gt;The Pragmatic Programmer isn't without its weaknesses. As alluded to earlier, the structure of the book can sometimes feel disjointed, with related topics separated by unrelated material. Some of the topic titles are also confusing, making it harder to remember what they're about when you want to refer back to them. Can you guess what "Coconuts Don't Cut It" is about? It's about not copying methodologies and processes without understanding the context 🤷&lt;/p&gt;
&lt;p&gt;Some readers might find certain sections preachy. The authors often make bold judgement calls about certain practices (e.g. 'Some team methodologies have a "quality officer" ... This is clearly ridiculous', or 'Without external configuration, your code is not adaptable ... in the real world species that don't adapt die'). While I don't disagree, I think it can unnecessarily alienate some readers who might not share the same views.&lt;/p&gt;
&lt;p&gt;Additionally, some of the more concrete technical sections feel less valuable compared to the high-level advice in most of the book. Take the concurrency chapter for example, I think the introduction to it and the first topic are good, but then it goes into some techniques that feel disjointed from the type of advice in the rest of the book, and somewhat dated. I would prefer to read about techniques to deal with these issues on a specialised book. The same applies, to some degree, to a few other topics (e.g. Domain Languages).&lt;/p&gt;
&lt;p&gt;Having said all that, these are minor criticisms in the grand scheme of things. Don't make these stop you from reading the book!&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;In conclusion, The Pragmatic Programmer has already begun to reshape my approach to software development, even in the short time since I started applying its principles. The book's emphasis on adaptability, thoughtful design, and effective communication has provided me with valuable tools for tackling daily challenges in my work. While it's not without its flaws, the practical wisdom contained within its pages far outweighs any minor structural issues or occasional preachiness. Based on my preliminary experience of putting its advice into practice, I wholeheartedly recommend The Pragmatic Programmer to software developers at any stage of their career. It offers a wealth of insights that can help you become a more effective and thoughtful professional in the ever-evolving field of software development.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;This blog post was made with the help of Claude 3.5 Sonnet and GitHub Copilot.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Thoughts about Anthropic / OpenAI work on interpretability in LLMs</title><link href="/blog/thoughts-about-anthropic-openai-work-on-interpretability-in-llms" rel="alternate"></link><published>2024-06-07T10:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2024-06-07:/blog/thoughts-about-anthropic-openai-work-on-interpretability-in-llms</id><summary type="html">&lt;p&gt;A few weeks ago, Anthropic came out with &lt;a href="https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html"&gt;this paper&lt;/a&gt;, showing how they found interpretable features in one of their models. This means that they could see which features activate when the LLM generates, and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A few weeks ago, Anthropic came out with &lt;a href="https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html"&gt;this paper&lt;/a&gt;, showing how they found interpretable features in one of their models. This means that they could see which features activate when the LLM generates, and the feature could be scaled up and down to make the generation more or less focused on that feature. For example, their "Golden Gate Claude" model, with the Golden Gate feature boosted to the max, kept steering the conversation to talk about the Golden Gate.&lt;/p&gt;
&lt;p&gt;Yesterday, OpenAI published &lt;a href="https://openai.com/index/extracting-concepts-from-gpt-4/"&gt;a similar paper&lt;/a&gt;. Maybe it's just me, or the high pace of news in AI is enough to make groundbreaking research seem underwhelming, but this new paper seems lacking in comparison. Note that my understanding of the internal workings of these models, and the two studies above, are very limited, so take this with a grain of salt. Having said that, here are some thought for why the OpenAI paper is underwhelming.&lt;/p&gt;
&lt;p&gt;They extracted 16 million features from their GPT-4 model. Who needs 16 million features?!? We are trying to understand, in human terms, how these things work. For that we need to find ways to get them down to human understandable scales. How many characteristics can you find in a person? For example, someone might be a great leader, very inspiring, but also a bit rush, and cannot stop fidgeting their legs. Can you think about 100 basic characteristics for people? Yeah, potentially. Obviously these are going to be a reduction of who this person really is, but so do the 16 million features in OpenAI's research. If the goal is interpretability, then extracting that many features "that we hope are human interpretable" doesn't seem like the best approach.&lt;/p&gt;
&lt;p&gt;To be fair here, Anthropic encoded 1 million, 4 million, and 34 million features, so they didn't reduce the problem to a more human-understandable scale either, but the focus of their research is not the number of features, and how well they cover the model capabilities, and more about extracting meaning from the model.&lt;/p&gt;
&lt;p&gt;The second reason for the OpenAI research to feel weak is the examples they give for feature activation. Take this snippet for example:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;most people, it isn't. We all have wonderful days, glimpses of what we perceive to be perfection, but we can also all have truly shit-tastic ones, and I can assure you that you're not alone. So toddler of mine, and most other toddlers out there, remember; Don't be a&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If I tell you to highlight the words / phrases associated with 'phrases relating to things (especially humans) being flawed', what would you do? I would probably highlight 'we can also all have truly shit-tastic ones' and 'you're not alone'.&lt;/p&gt;
&lt;p&gt;Here's what the extracted feature picked:&lt;/p&gt;
&lt;p&gt;&lt;img alt="A snippet of text with the phrases 'but we' and 'you that you're' highlighted." src="/images/blog/openai_human_imperfection_feature_extraction_example.webp"&gt;&lt;/p&gt;
&lt;p&gt;This is not an isolated critique. It is the first example provided in their blog post.&lt;/p&gt;
&lt;p&gt;Having said all of that, I would love to see more work on interpretability of these models, both from OpenAI and Anthropic.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Mozilla is experimenting with local alt text generation in Firefox</title><link href="/blog/mozilla-is-experimenting-with-local-alt-text-generation-in-firefox" rel="alternate"></link><published>2024-06-02T23:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2024-06-02:/blog/mozilla-is-experimenting-with-local-alt-text-generation-in-firefox</id><summary type="html">&lt;p&gt;As the title suggests, &lt;a href="https://hacks.mozilla.org/2024/05/experimenting-with-local-alt-text-generation-in-firefox-nightly/"&gt;Mozilla is experimenting with using on-device Generative AI to generate alt text&lt;/a&gt;. Here are some meandering thoughts.&lt;/p&gt;
&lt;p&gt;This raises the question whether it makes sense to invest in AI generated alt-text …&lt;/p&gt;</summary><content type="html">&lt;p&gt;As the title suggests, &lt;a href="https://hacks.mozilla.org/2024/05/experimenting-with-local-alt-text-generation-in-firefox-nightly/"&gt;Mozilla is experimenting with using on-device Generative AI to generate alt text&lt;/a&gt;. Here are some meandering thoughts.&lt;/p&gt;
&lt;p&gt;This raises the question whether it makes sense to invest in AI generated alt-text in the source, as a feature of your content editing software. Projects like these might be redundant in the long run. Or maybe not? 🤔&lt;/p&gt;
&lt;p&gt;It depends on what alt text is for. Its primary use is for accessibility, obviously (I hope). But this can be crawled, or otherwise reused, by machines. In general, if we assume content is read more than written, it might be is less wasteful to automatically generate alt text in the source, regardless of who reads it - humans with assisting technologies, or other machines.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Docker, compose, secrets, and environment variables</title><link href="/blog/docker-compose-secrets-and-environment-variables" rel="alternate"></link><published>2024-05-30T23:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2024-05-30:/blog/docker-compose-secrets-and-environment-variables</id><summary type="html">&lt;p&gt;A dockerised app I'm working on needs some secrets at build time. In my case, it needs to &lt;code&gt;pip install&lt;/code&gt; from a private repository. Note that this is a generic problem, luckily with quite an …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A dockerised app I'm working on needs some secrets at build time. In my case, it needs to &lt;code&gt;pip install&lt;/code&gt; from a private repository. Note that this is a generic problem, luckily with quite an elegant generic solution.&lt;/p&gt;
&lt;h2 id="how-not-to-pass-secrets-to-docker"&gt;How NOT to pass secrets to docker&lt;/h2&gt;
&lt;p&gt;In the past, we solved this by passing a build argument with the secret.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# docker-compose.yml&lt;/span&gt;
&lt;span class="nt"&gt;services&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;my-app&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;build&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;args&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;CONTAINER_SECRET&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;${HOST_SECRET}&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This is going to pass the &lt;code&gt;HOST_SECRET&lt;/code&gt; environment variable from the host machine, to the container as an &lt;code&gt;ARG&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c"&gt;# Dockerfile&lt;/span&gt;
&lt;span class="k"&gt;ARG&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;CONTAINER_SECRET
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt; that I'm calling these &lt;code&gt;CONTAINER_SECRET&lt;/code&gt; and &lt;code&gt;HOST_SECRET&lt;/code&gt; to make things easier to follow, but these will often have the same name. Up to you really.&lt;/p&gt;
&lt;p&gt;There are two significant drawbacks to this approach:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If the secret is a token that refreshes from time to time, it will mess up the docker build caching. In other words, when your token changes, every step after &lt;code&gt;ARG CONTAINER_SECRET&lt;/code&gt; will have to be rerun during the build.&lt;/li&gt;
&lt;li&gt;The secret can be extracted from the image, which is a security concern.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="how-to-pass-secrets-to-docker"&gt;How to pass secrets to docker&lt;/h2&gt;
&lt;p&gt;Luckily, &lt;a href="https://docs.docker.com/build/building/secrets/"&gt;docker supports build secrets&lt;/a&gt;. But until recently it was hard to fully utilize them because they were not supported by docker compose, which I almost always use for local development.&lt;/p&gt;
&lt;p&gt;So, what are we trying to achieve?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Call a command that requires a secret, stored in &lt;code&gt;HOST_SECRET&lt;/code&gt; on the host, during the docker image build.&lt;/li&gt;
&lt;li&gt;Use docker compose in local development to build the app.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's start from the &lt;code&gt;Dockerfile&lt;/code&gt;. It needs to call &lt;code&gt;pip install my-private-package&lt;/code&gt; with our secret in the environment variable &lt;code&gt;CONTAINER_SECRET&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c"&gt;# Dockerfile&lt;/span&gt;
&lt;span class="k"&gt;RUN&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;--mount&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;secret,id&lt;span class="o"&gt;=&lt;/span&gt;my_secret&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nv"&gt;CONTAINER_SECRET&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;cat&lt;span class="w"&gt; &lt;/span&gt;/run/secrets/my_secret&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;my-private-package
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;Dockerfile&lt;/code&gt; mounts the value of the secret called &lt;code&gt;my_secret&lt;/code&gt; on &lt;code&gt;/run/secrets/my_secret&lt;/code&gt;, which we load into an environment variable before calling the command. For security, the secret will only be accessbile during this &lt;code&gt;RUN&lt;/code&gt; command. See &lt;a href="https://docs.docker.com/build/building/secrets/"&gt;the docs&lt;/a&gt; for more info about using secrets in docker builds.&lt;/p&gt;
&lt;p&gt;Now let's have a look at the &lt;code&gt;docker-compose.yml&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# docker-compose.yml&lt;/span&gt;
&lt;span class="nt"&gt;services&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;my-app&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;build&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;...&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;secrets&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;my_secret&lt;/span&gt;

&lt;span class="nt"&gt;secrets&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;my_secret&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="nt"&gt;environment&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;HOST_SECRET&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;docker-compose.yml&lt;/code&gt; defines a global secret that is loaded from the environment variable &lt;code&gt;HOST_SECRET&lt;/code&gt; on the host. There are other options for defining secrets (e.g. from a file). Again, consult &lt;a href="https://docs.docker.com/compose/use-secrets/"&gt;the docs&lt;/a&gt;. Then, the service that needs the secret can ask for it by name.&lt;/p&gt;
&lt;h1 id="nice-to-haves"&gt;Nice to haves&lt;/h1&gt;
&lt;h2 id="build-with-docker"&gt;Build with docker&lt;/h2&gt;
&lt;p&gt;While I mostly use docker compose for local development, sometimes it's useful to just build with docker, even for the same project! A good example is unit-tests. It's simple to build and run unit tests in the container without docker compose because there's no need for the surrounding services, environment variables, networking configuration, volumes, etc.&lt;/p&gt;
&lt;p&gt;Here's how this is done&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;docker build --secret id=my_secret,env=HOST_SECRET --tag my-app:test .
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id="passing-secrets-to-running-containers"&gt;Passing secrets to running containers&lt;/h2&gt;
&lt;p&gt;Lastly, it's often useful to run commands that require secrets from within the container in development, not during the build. For example, when modifying dependencies (something like &lt;code&gt;pip install --upgrade my-private-package &amp;amp;&amp;amp; pip freeze &amp;gt; requirements.txt&lt;/code&gt;). In this case we need &lt;code&gt;CONTAINER_SECRET&lt;/code&gt; in the container at runtime. A simple solution is to pass an environment variable to the container:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="c1"&gt;# docker-compose.yml&lt;/span&gt;
&lt;span class="nt"&gt;services&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;my-app&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;...&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;environment&lt;/span&gt;&lt;span class="p p-Indicator"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;CONTAINER_SECRET&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;${ HOST_SECRET }&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;While it's possible to use secrets at runtime there's no need to do so. Think about the two issues secrets solve: security and build time. The environment variable is not stored in the image so there's no security issue here. And the build is long done so there are no effect on that front either.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>LLM synthetic data in bash</title><link href="/blog/llm-synthetic-data-in-bash" rel="alternate"></link><published>2024-05-23T23:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2024-05-23:/blog/llm-synthetic-data-in-bash</id><summary type="html">&lt;p&gt;The &lt;a href="https://github.com/simonw/llm"&gt;&lt;code&gt;llm&lt;/code&gt; command line tool by Simon Willison&lt;/a&gt; lets you interact with LLMs from the command line. I've been using it recently, and while it's nice and convenient, I wasn't doing anythin I couldn't do …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The &lt;a href="https://github.com/simonw/llm"&gt;&lt;code&gt;llm&lt;/code&gt; command line tool by Simon Willison&lt;/a&gt; lets you interact with LLMs from the command line. I've been using it recently, and while it's nice and convenient, I wasn't doing anythin I couldn't do with a "vanila" LLM ChatBot a la ChatGPT. Until today!&lt;/p&gt;
&lt;p&gt;Today, I had to test our retrieval-augmented generation (RAG) system. I wanted to hit a endpoint repeatedly and monitor the response time while running some operations on the server. Sure, I can throw something together with a bash loop and &lt;code&gt;curl&lt;/code&gt;. But what if my experiment will be skewed by caching somewhere in the system if the request is always the same 🤔&lt;/p&gt;
&lt;p&gt;Here's what I ended up with&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;code&gt;&lt;span class="k"&gt;while&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="k"&gt;do&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;curl&lt;span class="w"&gt; &lt;/span&gt;https://my-server.com/&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;-d&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;{\&amp;quot;query\&amp;quot;: \&amp;quot;`llm &amp;quot;&lt;/span&gt;Give&lt;span class="w"&gt; &lt;/span&gt;me&lt;span class="w"&gt; &lt;/span&gt;a&lt;span class="w"&gt; &lt;/span&gt;one&lt;span class="w"&gt; &lt;/span&gt;sentence&lt;span class="w"&gt; &lt;/span&gt;interesting&lt;span class="w"&gt; &lt;/span&gt;question&lt;span class="w"&gt; &lt;/span&gt;about&lt;span class="w"&gt; &lt;/span&gt;consumers&lt;span class="w"&gt; &lt;/span&gt;behaviours&lt;span class="s2"&gt;&amp;quot;`\&amp;quot;}&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;--output&lt;span class="w"&gt; &lt;/span&gt;/dev/null&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;--silent&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="se"&gt;\&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;--write-out&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;%{http_code} %{time_total}s\n&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It hits the system with a new query every time, running in an endless loop.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--output /dev/null&lt;/code&gt; is there to discard the response from the server. I'm not really interested in that.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--silent&lt;/code&gt; is there to discard any output from &lt;code&gt;curl&lt;/code&gt; itself.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--write-out "%{http_code} %{time_total}s\n"&lt;/code&gt; is to get the debugging output I'm interested in: status code and the time it took the server to respond, in seconds.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;BTW, &lt;code&gt;llm&lt;/code&gt; helped me to come up with this solution 😉&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Andrew Ng's advice for iteratively writing LLM prompts</title><link href="/blog/andrew-ngs-advice-for-iteratively-writing-llm-prompts" rel="alternate"></link><published>2024-05-19T23:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2024-05-19:/blog/andrew-ngs-advice-for-iteratively-writing-llm-prompts</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;When building complex workflows, I see developers getting good results with this process:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Write quick, simple prompts and see how it does.&lt;/li&gt;
&lt;li&gt;Based on where the output falls short, flesh out the prompt
  iteratively. This …&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;When building complex workflows, I see developers getting good results with this process:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Write quick, simple prompts and see how it does.&lt;/li&gt;
&lt;li&gt;Based on where the output falls short, flesh out the prompt
  iteratively. This often leads to a longer, more detailed, prompt,
  perhaps even a mega-prompt.&lt;/li&gt;
&lt;li&gt;If that's still insufficient, consider few-shot or many-shot learning (if applicable) or, less frequently, fine-tuning.&lt;/li&gt;
&lt;li&gt;If that still doesn't yield the results you need, break down the task into subtasks and apply an agentic workflow.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="https://info.deeplearning.ai/openais-rules-for-model-behavior-better-brain-controlled-robots-alphafold-3-covers-all-biochemistry-ai-oasis-in-the-desert"&gt;Source&lt;/a&gt;&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>OpenAI Model Spec</title><link href="/blog/openai-model-spec" rel="alternate"></link><published>2024-05-08T23:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Leverstone</name></author><id>tag:None,2024-05-08:/blog/openai-model-spec</id><summary type="html">&lt;p&gt;OpenAI has recently published a document titled &lt;a href="https://cdn.openai.com/spec/model-spec-2024-05-08.html"&gt;'Model Spec'&lt;/a&gt;. It defines an ethics and norms framework models should follow. A few things that stood out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It surprisingly resembles Isaac Asimov's "Three Laws of Robotics", with …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;OpenAI has recently published a document titled &lt;a href="https://cdn.openai.com/spec/model-spec-2024-05-08.html"&gt;'Model Spec'&lt;/a&gt;. It defines an ethics and norms framework models should follow. A few things that stood out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It surprisingly resembles Isaac Asimov's "Three Laws of Robotics", with a 'chain of command' for resolving conflicting objectives. The logic is &lt;code&gt;Platform &amp;gt; Developer &amp;gt; User &amp;gt; Tool&lt;/code&gt;. The platform consists of the instructions given to the model by OpenAI themselves (training, reinforcement learning from human feedback, and platform message that is added before the system message). The term 'developer' here refers to what was previously known as the system role message. User and tool are self explanatory, I think. Then, the document provides numerous examples of conflicts, demonstrating the preferred resolution for each.&lt;/li&gt;
&lt;li&gt;The document gives a lot of context for the difference between a developer/system messages and user messages. I think that's quite important to understand to improve prompting.&lt;/li&gt;
&lt;li&gt;The document mentions settings that can be passed to message objects. One of them is &lt;code&gt;interactive&lt;/code&gt; (a boolean). The document describes in length how this can change the behaviour of the assistant, to tune the assistant for interactive chat behaviour (the default) or for single response. The differences are quite striking. I couldn't find anything about this in the API docs. I wonder if it's worth trying playing with this against the actual API to see if this is implemented but not yet documented.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The document is lengthy, but I think worth reading, or at least skimming through.&lt;/p&gt;</content><category term="Blog"></category></entry><entry><title>Deployment tech for the hobbyist, again</title><link href="/blog/deployment-tech-for-the-hobbyist-again" rel="alternate"></link><published>2023-12-15T00:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2023-12-15:/blog/deployment-tech-for-the-hobbyist-again</id><summary type="html">&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; Try &lt;a class="reference external" href="https://dokku.com/"&gt;Dokku&lt;/a&gt; if you want to run multiple toy web apps on a single server and keep the cost at minimum.&lt;/p&gt;
&lt;img alt="Dokku logo with name" src="/images/blog/dokku-logo-with-name.webp" style="width: 100%;" /&gt;
&lt;p&gt;Let's talk, yet again, about deploying toy web apps.
I wrote about …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; Try &lt;a class="reference external" href="https://dokku.com/"&gt;Dokku&lt;/a&gt; if you want to run multiple toy web apps on a single server and keep the cost at minimum.&lt;/p&gt;
&lt;img alt="Dokku logo with name" src="/images/blog/dokku-logo-with-name.webp" style="width: 100%;" /&gt;
&lt;p&gt;Let's talk, yet again, about deploying toy web apps.
I wrote about this topic many moons ago (see docker-compose in production &lt;a class="reference external" href="/blog/docker-compose-in-production"&gt;part 1&lt;/a&gt; and &lt;a class="reference external" href="/blog/docker-compose-in-production-part-2"&gt;part 2&lt;/a&gt;), but things have changed and it's time for an update.&lt;/p&gt;
&lt;p&gt;The main thing that changed, really, is having much less time to maintain projects and money to keep the servers up.
In the past I had a single virtual server (a &lt;a class="reference external" href="https://www.digitalocean.com/products/droplets"&gt;Digital Ocean droplet&lt;/a&gt;) that ran everything.
It had &lt;a class="reference external" href="https://nginx.org/en/"&gt;nginx&lt;/a&gt; installed manually, and whenever I added a project, I had to reconfigure it to pass traffic to the port the project was running on.
This, again, was done manually.
The deployment itself was done by running a custom script somewhere, either from the local machine or from CI/CD.
That's pretty old-school, isn't it?
And what about SSL?
Forget it; that was too complicated.&lt;/p&gt;
&lt;p&gt;Over time projects started to transition to different platforms that automated the process.
I had projects on &lt;a class="reference external" href="https://www.heroku.com/"&gt;Heroku&lt;/a&gt; for years, using their now-retired free dev offering.
The cheapest option at the moment is $5 a month.
Some projects were deployed to &lt;a class="reference external" href="https://docs.digitalocean.com/products/app-platform/"&gt;Digital Ocean's App Platform&lt;/a&gt; which also starts at the same cost.
I found both platform very convenient to use, and although not particularly expensive, the cost ramps up quickly when you have a few projects, and that's without considering having a DB and other services to support the web app.
Last year, I invested some time learning AWS (Amazon Web Services), and in the process, deployed a toy project to &lt;a class="reference external" href="https://aws.amazon.com/elasticbeanstalk/"&gt;Elastic Beanstalk&lt;/a&gt;.
In the first year I was on the AWS free tier, but after that the price got really high.
If memory serves the forecast was &amp;gt;$50 a month for a load balancer, two of the smallest server instances possible, and a relational DB.
Two days after the end of the free tier period the project was shut down due to the cost.&lt;/p&gt;
&lt;p&gt;A solution was called for hosting my toy projects.
If you read this far, you can understand the requirements:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;It needs to be cheap. Ideally, I don't want to consider cost for adding or removing toy projects. A one-server solution sounds good for this.&lt;/li&gt;
&lt;li&gt;It needs to be simple and easy to maintain. &lt;a class="reference external" href="https://docs.aws.amazon.com/lambda/"&gt;AWS Lambdas&lt;/a&gt; are cheap and, in that sense, might be a good solution for toy projects, but my projects already exist in the form of servers and changing them to Lambda functions is too much effort.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I had a look at &lt;a class="reference external" href="https://dokku.com/"&gt;Dokku&lt;/a&gt; many years ago, and decided to check it again now.
The tagline is 'An open-source PaaS alternative to Heroku', and based on my good experience with &lt;a class="reference external" href="https://www.heroku.com/"&gt;Heroku&lt;/a&gt; it sounds pretty much up my alley.&lt;/p&gt;
&lt;p&gt;As already mentioned, I also have good experience with &lt;a class="reference external" href="https://www.digitalocean.com/"&gt;Digital Ocean&lt;/a&gt;.
If only I can have &lt;a class="reference external" href="https://dokku.com/"&gt;Dokku&lt;/a&gt; running in a Digital Ocean droplet 🤔&lt;/p&gt;
&lt;img alt="Dokku on Digit Ocean" src="/images/blog/dokku-on-digitalocean.webp" /&gt;
&lt;p&gt;Yes! A quick search reveals a &lt;a class="reference external" href="https://docs.digitalocean.com/products/marketplace/catalog/dokku/"&gt;one click deployment of Dokku on Digital ocean through their marketplace&lt;/a&gt;.
I went for a $12 virtual machine with 1 CPU, 2GB RAM, and 50GB of SSD storage, hoping it will be enough for a handful of projects for a while.
Within 20 minutes I was trying to deploy my first abandoned toy project on my new &lt;a class="reference external" href="https://dokku.com/"&gt;Dokku&lt;/a&gt; instance.
Another 20 minutes in, and the project was up and running.
Three more projects followed in what amounts to 2-3 hours work.
From these 4 project, 3 were previously deployed to &lt;a class="reference external" href="https://www.heroku.com/"&gt;Heroku&lt;/a&gt; using &lt;a class="reference external" href="https://buildpacks.io/"&gt;buildpacks&lt;/a&gt; and &lt;a class="reference external" href="https://docs.digitalocean.com/products/app-platform/"&gt;Digital Ocean's App Platform&lt;/a&gt; using containers (having a &lt;tt class="docutils literal"&gt;Dockerfile&lt;/tt&gt; at the root of the repo).
Moving these to the new system was a breeze:
adding a git remote locally and pushing, then on the new server configuring environment variables and &lt;a class="reference external" href="https://dokku.com/docs/deployment/application-deployment/#setting-up-ssl"&gt;configuring SSL following the deployment tutorial&lt;/a&gt;, followed by creating A tags on my DNS provider, and that's it!&lt;/p&gt;
&lt;p&gt;The 4th project was previously on &lt;a class="reference external" href="https://aws.amazon.com/elasticbeanstalk/"&gt;Elastic Beanstalk&lt;/a&gt; and backed by a relational DB.
I had the data from the DB exported into JSON before shutting the project down.
I was worried about transitioning it, but found it extremely easy as well!
Adding a DB to it was very simple following the so-far-excellent docs.
It took me a while to wrap my head around loading the backup, but the following did the trick:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;docker&lt;span class="w"&gt; &lt;/span&gt;ps&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;# to find the container ID of my app&lt;/span&gt;
docker&lt;span class="w"&gt; &lt;/span&gt;cp&lt;span class="w"&gt; &lt;/span&gt;my-backup.json&lt;span class="w"&gt; &lt;/span&gt;my-app-container-id:/app
dokku&lt;span class="w"&gt; &lt;/span&gt;enter&lt;span class="w"&gt; &lt;/span&gt;my-app
&lt;span class="c1"&gt;# Now run whatever command within the image to load the data&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;One last project is an &lt;a class="reference external" href="https://elixir-lang.org/"&gt;Elixir&lt;/a&gt;/&lt;a class="reference external" href="https://www.phoenixframework.org/"&gt;Phoenix&lt;/a&gt; project that was previously deployed on &lt;a class="reference external" href="https://www.gigalixir.com/"&gt;Gigalixir&lt;/a&gt; with their custom buildpacks.
I had to containerise the project to make it work with the new system, and that took a while.
Nothing to blame the new system for though.
Just the usual modernisation of an old project.&lt;/p&gt;
&lt;p&gt;Do I care about having these project highly available? no.
Do I care about no-downtime deployments? also no.
What about data loss (e.g. losing the DB)? That's not the end of the world either.
&lt;a class="reference external" href="https://dokku.com/"&gt;Dokku&lt;/a&gt; supports cron jobs, so it might be interesting to explore doing regular DB backups.
Or, alternatively, I can accept the $2.40 per month to enable weekly backups of the entire droplet.
If you do care about these then maybe your toy project is not that much of a toy any more 😄.&lt;/p&gt;
&lt;p&gt;In summary, all of the deployment stories above are here to say that so far I find &lt;a class="reference external" href="https://dokku.com/"&gt;Dokku&lt;/a&gt; really easy to work with.
There's no much traffic to any of these projects, so CPU / network / disk usage are low as expected.
Memory usage is constantly around %40-%50.
As long as it doesn't creep up dramatically that's probably fine.
So overall it seems that the transition succeeded.&lt;/p&gt;
&lt;div class="section" id="shameless-plug"&gt;
&lt;h2&gt;Shameless plug&lt;/h2&gt;
&lt;p&gt;Here are the projects that are running on my &lt;a class="reference external" href="https://dokku.com/"&gt;Dokku&lt;/a&gt; instance at the time of writing this post. Source code for all of them can be found on &lt;a class="reference external" href="https://github.com/nagasaki45/"&gt;my GitHub profile&lt;/a&gt;.&lt;/p&gt;
&lt;div class="section" id="cardigan"&gt;
&lt;h3&gt;&lt;a class="reference external" href="https://cardigan.leverstone.me/"&gt;Cardigan&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;A &amp;quot;platform&amp;quot; for playing card games online. Created during COVID to play &lt;a class="reference external" href="https://boardgamegeek.com/boardgame/284083/crew-quest-planet-nine"&gt;The Crew&lt;/a&gt; with friend before it was available on &lt;a class="reference external" href="https://boardgamearena.com/"&gt;BGA&lt;/a&gt;. It was previously deployed to &lt;a class="reference external" href="https://www.gigalixir.com/"&gt;Gigalixir&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="proker"&gt;
&lt;h3&gt;&lt;a class="reference external" href="https://proker.leverstone.me/"&gt;Proker&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;A tool we use at work to vote on the complexity of tickets (bugs, feature enhancements, tech debt, etc.) It was previously deployed to &lt;a class="reference external" href="https://docs.digitalocean.com/products/app-platform/"&gt;Digital Ocean's App Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="xteams"&gt;
&lt;h3&gt;&lt;a class="reference external" href="https://xteams.leverstone.me/"&gt;Xteams!&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;An app I made many years ago when I was playing volleyball with a group of 15-20 people who were too polite to make up teams. I know a few people were still using it until 3-4 years ago (including the coach of the Hebrew University of Jerusalem Women Volleyball Team). Have no idea if anyone still does. It was previously deployed to &lt;a class="reference external" href="https://aws.amazon.com/elasticbeanstalk/"&gt;Elastic Beanstalk&lt;/a&gt;, and before that to &lt;a class="reference external" href="https://www.heroku.com/"&gt;Heroku&lt;/a&gt; (I think).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="grabacoffee"&gt;
&lt;h3&gt;&lt;a class="reference external" href="https://grab-a-coffee.leverstone.me/"&gt;GrabACoffee&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;A hackathon project made at work to encourage people to take coffee breaks together. It was previously on &lt;a class="reference external" href="https://docs.digitalocean.com/products/app-platform/"&gt;Digital Ocean's App Platform&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="web-audio"&gt;
&lt;h3&gt;&lt;a class="reference external" href="https://web-audio.leverstone.me/"&gt;web-audio&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;An attempt to play with the WebAudio API that ended up more like an experiment in ajax / websockets. Made when I just started writing code and had no idea what I'm doing. Happy to see it online mainly for nostalgia. Previously deployed on &lt;a class="reference external" href="https://www.heroku.com/"&gt;Heroku&lt;/a&gt; but went down when they changed the pricing model because there was no point in paying for it.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="thoughts"></category><category term="dokku"></category><category term="docker"></category><category term="web"></category><category term="tools"></category></entry><entry><title>Remote TidalCycles jamming setup</title><link href="/blog/remote-tidal-cycles-jamming-setup" rel="alternate"></link><published>2020-09-18T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2020-09-18:/blog/remote-tidal-cycles-jamming-setup</id><summary type="html">&lt;object data="https://upload.wikimedia.org/wikipedia/commons/8/80/TidalCycles_identity.svg" style="width: 100%;" type="image/svg+xml"&gt;TidalCycles logo&lt;/object&gt;
&lt;p&gt;&lt;a class="reference external" href="https://tidalcycles.org"&gt;TidalCycles&lt;/a&gt; (tidal in short) is a live coding language for music performance / composition.
I don't use it myself but been playing with a live coder, Lizzie, AKA &lt;a class="reference external" href="https://lwlsn.github.io/digitalselves-web/"&gt;digital selves&lt;/a&gt;, for the last year …&lt;/p&gt;</summary><content type="html">&lt;object data="https://upload.wikimedia.org/wikipedia/commons/8/80/TidalCycles_identity.svg" style="width: 100%;" type="image/svg+xml"&gt;TidalCycles logo&lt;/object&gt;
&lt;p&gt;&lt;a class="reference external" href="https://tidalcycles.org"&gt;TidalCycles&lt;/a&gt; (tidal in short) is a live coding language for music performance / composition.
I don't use it myself but been playing with a live coder, Lizzie, AKA &lt;a class="reference external" href="https://lwlsn.github.io/digitalselves-web/"&gt;digital selves&lt;/a&gt;, for the last year and a half.
Check her out!
With a COVID 2nd wave around the corner we decided to search for a solution for remote jamming together.
This blog post is a summary of what seems to work.
It's written mainly as a documentation for Lizzie and self.
Hopefully others will find it useful as well.&lt;/p&gt;
&lt;p&gt;So, what do we want to achieve?
We want Lizzie to run tidal code on her laptop and having the audio generated on my laptop at the other side of town.
The clock to sync my hardware synth will be generated with the audio.
So, audio-wise, both Lizzie's output and my hardware synth will generate locally on my side, fully in sync.
Then, the mix of Lizzie's live coding and my hardware synth will be streamed back to Lizzie, so she could hear it too.&lt;/p&gt;
&lt;p&gt;How do we plan to do it?
Tidal uses a client / server architecture with the tidal haskell library as the client and SuperCollider (SC) running the audio as the server.
Communication is done over UDP on port 57120 by default.
Our idea is to route the messages from tidal, through a server, to my machine, which runs the SC server.
With such a solution there won't be any need to change anything around tidal, nor around SC, just set up the network properly.
I will listen to the mix locally on my side and send it to Lizzie over zoom / skype / whatever.&lt;/p&gt;
&lt;p&gt;With the overall picture in mind, let's dive in.&lt;/p&gt;
&lt;div class="section" id="prerequisits"&gt;
&lt;h2&gt;Prerequisits&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;You'll need a server with admin previliges.&lt;/li&gt;
&lt;li&gt;Both ends (the computer running tidal and the computer running SC) should have &lt;a class="reference external" href="https://linux.die.net/man/1/socat"&gt;socat&lt;/a&gt; installed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here's the overall process:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference internal" href="#prepare-the-server"&gt;Prepare the server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#create-an-ssh-reverse-tunnel-from-the-server-to-the-laptop-running-sc"&gt;Create an SSH reverse tunnel from the server to the laptop running SC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#convert-tcp-messages-back-to-udp-on-the-laptop-running-sc"&gt;Convert TCP messages back to UDP on the laptop running SC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#send-the-udp-messages-from-the-laptop-running-tidal-to-the-server"&gt;Send the UDP messages from the laptop running tidal to the server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#start-tidal"&gt;Start tidal&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference internal" href="#stream-the-audio-back-to-the-tidal-user"&gt;Stream the audio back to the tidal user&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="prepare-the-server"&gt;
&lt;h2&gt;Prepare the server&lt;/h2&gt;
&lt;p&gt;For a server we created a droplet on &lt;a class="reference external" href="https://digitalocean.com/"&gt;digital ocean&lt;/a&gt;.
There's almost no setup for the droplet, so we can create one for jamming and delete it later to keep the cost low.&lt;/p&gt;
&lt;p&gt;The only configuration needed on the server is to change the SSH settings on the server to allow forwarded ports to bind to the wildcard address (meaning that the address will be publicly accessible) &lt;a class="footnote-reference" href="#footnote-1" id="footnote-reference-1"&gt;[1]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Edit &lt;tt class="docutils literal"&gt;/etc/ssh/sshd_config&lt;/tt&gt; and add:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;
GatewayPorts yes
&lt;/pre&gt;
&lt;p&gt;Now reload the SSH settings on the server with&lt;/p&gt;
&lt;pre class="code literal-block"&gt;
systemctl reload ssh.service
&lt;/pre&gt;
&lt;p&gt;Note the IP of your server and use it everywhere that &lt;tt class="docutils literal"&gt;SERVER_IP&lt;/tt&gt; is mentioned below.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="create-an-ssh-reverse-tunnel-from-the-server-to-the-laptop-running-sc"&gt;
&lt;h2&gt;Create an SSH reverse tunnel from the server to the laptop running SC&lt;/h2&gt;
&lt;p&gt;SSH tunnelling doesn't support UDP, so we'll create a tunnel for TCP and convert the UDP messages sent by tidal to TCP on one machine, and back to UDP on the other machine.&lt;/p&gt;
&lt;p&gt;On the machine that runs SC run&lt;/p&gt;
&lt;pre class="code literal-block"&gt;
ssh -R 12345:localhost:12345 root&amp;#64;SERVER_IP
&lt;/pre&gt;
&lt;p&gt;The port doesn't really matter, 12345 is used here for convenience.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="convert-tcp-messages-back-to-udp-on-the-laptop-running-sc"&gt;
&lt;h2&gt;Convert TCP messages back to UDP on the laptop running SC&lt;/h2&gt;
&lt;pre class="code literal-block"&gt;
socat TCP-LISTEN:12345,fork UDP4:localhost:57120
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="send-the-udp-messages-from-the-laptop-running-tidal-to-the-server"&gt;
&lt;h2&gt;Send the UDP messages from the laptop running tidal to the server&lt;/h2&gt;
&lt;pre class="code literal-block"&gt;
socat UDP-LISTEN:57120,fork TCP4:SERVER_IP:12345
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="start-tidal"&gt;
&lt;h2&gt;Start tidal&lt;/h2&gt;
&lt;p&gt;Spin up tidal on one side, SC on the other side, put some patterns in and it should work, almost!
The user on the SC side will probably notice that the timing is not super stable and there are warnings about that in the SC log.
This is a result of the network latency.
To fix that, increase tidal's latency.
If you're using atom go to preferences &amp;gt; open config folder. This brings up the tidal source code. In &lt;tt class="docutils literal"&gt;tidalcycles/lib/boot.tidal&lt;/tt&gt;, change the &lt;tt class="docutils literal"&gt;oLatency&lt;/tt&gt; value to 0.4 or so in this line of code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nf"&gt;tidal&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;startTidal&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;superdirtTarget&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;oLatency&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;oAddress&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;&amp;quot;127.0.0.1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;oPort&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;57120&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;defaultConfig&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;cFrameTimespan&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;A value of 0.4 worked for us.
If it's still too low try to increase the value until there's no more jitter and warnings in the log.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="stream-the-audio-back-to-the-tidal-user"&gt;
&lt;h2&gt;Stream the audio back to the tidal user&lt;/h2&gt;
&lt;p&gt;So now the live coder's music is coming from the laptop running SC.
In our case, one audio channel from SC is an analog clock to sync the hardware sync.
The other channels from SC, and the hardware synth, are connected to a mixer and the entire mix can now be heard on the SC end of the system.
But the live coder cannot hear anything yet.
We used a 2nd computer that takes mixer's output and streams it back to the live coder over zoom.&lt;/p&gt;
&lt;p&gt;The entire system looks something like this.
The area in blue is for the laptop running tidal and the area in pink is the SC + hardware synth end of the system.&lt;/p&gt;
&lt;img alt="TidalCycles logo" src="/images/blog/tidal_remote_diagram.avif" style="width: 100%;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="advice-on-testing-things-locally"&gt;
&lt;h2&gt;Advice on testing things locally&lt;/h2&gt;
&lt;p&gt;If you want to test things on a single computer make sure to change the port SC is listening to.
Otherwise you are trying to use the same port twice: once listening to tidal and sending the messages to the server, and again listening to the messages coming from the server.
To do so, start the SuperDirt synth in SC as follows:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;
SuperDirt.start(port: 57121)
&lt;/pre&gt;
&lt;p&gt;You'll also have to change the port that the TCP stream is converted to, so replace&lt;/p&gt;
&lt;pre class="code literal-block"&gt;
socat TCP-LISTEN:12345,fork UDP4:localhost:57120
&lt;/pre&gt;
&lt;p&gt;with&lt;/p&gt;
&lt;pre class="code literal-block"&gt;
socat TCP-LISTEN:12345,fork UDP4:localhost:57121
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Enjoy jamming and keep safe!&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="footnotes"&gt;
&lt;h2&gt;Footnotes&lt;/h2&gt;
&lt;table class="docutils footnote" frame="void" id="footnote-1" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#footnote-reference-1"&gt;[1]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Setting the server this way is not 100% secure. We didn't mind it too much as this is a throwaway server with IP that no one except for us will ever know. If you are worried about security consider creating a forward tunnel from the laptop running tidal to the server instead of exposing the port to the public.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="tutorials"></category><category term="live coding"></category><category term="network"></category><category term="hack"></category></entry><entry><title>bibo, the command line reference manager, is in beta now!</title><link href="/blog/bibo-beta" rel="alternate"></link><published>2020-05-28T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2020-05-28:/blog/bibo-beta</id><summary type="html">&lt;object data="/images/blog/bibo_beta_release_banner.svg" style="width: 100%;" type="image/svg+xml"&gt;bibo beta release banner&lt;/object&gt;
&lt;p&gt;bibo is a command line reference manager with a single source of truth: the &lt;tt class="docutils literal"&gt;.bib&lt;/tt&gt; file. It is inspired by &lt;a class="reference external" href="https://github.com/beetbox/beets"&gt;beets&lt;/a&gt;. After 3 years in the making I believe it's ready …&lt;/p&gt;</summary><content type="html">&lt;object data="/images/blog/bibo_beta_release_banner.svg" style="width: 100%;" type="image/svg+xml"&gt;bibo beta release banner&lt;/object&gt;
&lt;p&gt;bibo is a command line reference manager with a single source of truth: the &lt;tt class="docutils literal"&gt;.bib&lt;/tt&gt; file. It is inspired by &lt;a class="reference external" href="https://github.com/beetbox/beets"&gt;beets&lt;/a&gt;. After 3 years in the making I believe it's ready for other people to use.&lt;/p&gt;
&lt;p&gt;What are the advantages over mendeley / zotero / etc. you ask?&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;It gives you control over your files. They are not hidden in some obscure database, hence easy to backup, share, etc.&lt;/li&gt;
&lt;li&gt;It's a thin editor of .bib files, so no need to export your bibliography anywhere.&lt;/li&gt;
&lt;li&gt;It's extensible with plugins.&lt;/li&gt;
&lt;li&gt;It's a command line tool. So if you're a fan of the unix philosophy (small building blocks that are easy to integrate with each other) you might love it.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="reference external" href="https://bibo.readthedocs.io/en/latest/index.html"&gt;Here are the docs&lt;/a&gt; with everything you need to learn more about the project and to get started.&lt;/p&gt;
&lt;p&gt;This beta release (0.1.0) marks the first release that is fully functional, was tested extensively, and should work for most people. It's not a production ready software yet, so make sure you backup your bibliography (and PDFs) before using it! It is, however, used already by a few people, so give it a spin if you like the idea.&lt;/p&gt;
&lt;p&gt;If anything is broken, please reach out! I will be happy to read about &lt;a class="reference external" href="https://github.com/Nagasaki45/bibo/issues"&gt;issues on github&lt;/a&gt;. Contributions are also super welcome. More about this in the docs.&lt;/p&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="python"></category><category term="tools"></category></entry><entry><title>The Krihelinator reached end-of-life</title><link href="/blog/krihelinator-eol" rel="alternate"></link><published>2020-04-09T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2020-04-09:/blog/krihelinator-eol</id><summary type="html">&lt;img alt="The Krihelinator RIP" src="/images/blog/krihelinator-eol.webp" style="width: 100%;" /&gt;
&lt;p&gt;After more than 4 years online, the Krihelinator was shut down today. The idea behind this project was to propose an alternative to github's trading page by highlighting projects with high contribution rate instead of …&lt;/p&gt;</summary><content type="html">&lt;img alt="The Krihelinator RIP" src="/images/blog/krihelinator-eol.webp" style="width: 100%;" /&gt;
&lt;p&gt;After more than 4 years online, the Krihelinator was shut down today. The idea behind this project was to propose an alternative to github's trading page by highlighting projects with high contribution rate instead of stars. I'm a bit sorry to let this project go, as it was one of my main side projects for many years. The decision came after multiple changes to some github pages that the project was scraping. After the last change the data that the project collected was so broken that it didn't make much sense to keep it online as is. I decided not to fix it, as I have other side projects that I would like to dedicate more time to at the moment.&lt;/p&gt;
&lt;p&gt;More information about the project can be found on &lt;a class="reference external" href="https://github.com/nagasaki45/krihelinator"&gt;github&lt;/a&gt;.&lt;/p&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="code"></category><category term="elixir"></category></entry><entry><title>New portfolio site</title><link href="/blog/new-portfolio-site-2020" rel="alternate"></link><published>2020-04-03T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2020-04-03:/blog/new-portfolio-site-2020</id><summary type="html">&lt;p&gt;&lt;a class="reference external" href="/blog/my-new-portfolio-site"&gt;Yet again&lt;/a&gt;, I have a new portfolio site. Actually, it's just a redesign. Wanted to simplify the previous over-the-top site. Check it out at &lt;a class="reference external" href="https://leverstone.me"&gt;leverstone.me&lt;/a&gt;. Here's a reminder for how the old one looked …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a class="reference external" href="/blog/my-new-portfolio-site"&gt;Yet again&lt;/a&gt;, I have a new portfolio site. Actually, it's just a redesign. Wanted to simplify the previous over-the-top site. Check it out at &lt;a class="reference external" href="https://leverstone.me"&gt;leverstone.me&lt;/a&gt;. Here's a reminder for how the old one looked like.&lt;/p&gt;
&lt;video controls src="/images/blog/old-portfolio-site.mp4" /&gt;</content><category term="Blog"></category><category term="projects"></category></entry><entry><title>Intro to git workshop</title><link href="/blog/intro-to-git-workshop" rel="alternate"></link><published>2019-02-21T19:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2019-02-21:/blog/intro-to-git-workshop</id><summary type="html">&lt;p&gt;A 4 hours introduction to git workshop for my PhD fellas.
Based on an old &lt;a class="reference external" href="/blog/git-crash-course"&gt;git crash course&lt;/a&gt; blog post.&lt;/p&gt;
&lt;img alt="git logo" src="/images/blog/git_logo.gif" style="width: 100%;" /&gt;
&lt;div class="section" id="why"&gt;
&lt;h2&gt;Why?&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Keep your projects organized.&lt;/li&gt;
&lt;li&gt;Collaborate with others.&lt;/li&gt;
&lt;li&gt;Get involved with open source.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="command-what"&gt;
&lt;h2&gt;Command what …&lt;/h2&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;A 4 hours introduction to git workshop for my PhD fellas.
Based on an old &lt;a class="reference external" href="/blog/git-crash-course"&gt;git crash course&lt;/a&gt; blog post.&lt;/p&gt;
&lt;img alt="git logo" src="/images/blog/git_logo.gif" style="width: 100%;" /&gt;
&lt;div class="section" id="why"&gt;
&lt;h2&gt;Why?&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Keep your projects organized.&lt;/li&gt;
&lt;li&gt;Collaborate with others.&lt;/li&gt;
&lt;li&gt;Get involved with open source.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="command-what"&gt;
&lt;h2&gt;Command what?&lt;/h2&gt;
&lt;p&gt;&lt;a class="reference external" href="https://tutorial.djangogirls.org/en/intro_to_command_line/"&gt;Introduction to the command line&lt;/a&gt;.
From now on, the rest is done there.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="configuring-git-for-the-first-time"&gt;
&lt;h2&gt;Configuring git for the first time&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;config&lt;span class="w"&gt; &lt;/span&gt;--global&lt;span class="w"&gt; &lt;/span&gt;user.name&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Your name here&amp;quot;&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;config&lt;span class="w"&gt; &lt;/span&gt;--global&lt;span class="w"&gt; &lt;/span&gt;user.email&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;your_email@example.com&amp;quot;&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;config&lt;span class="w"&gt; &lt;/span&gt;--global&lt;span class="w"&gt; &lt;/span&gt;core.editor&lt;span class="w"&gt; &lt;/span&gt;nano
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="working-locally"&gt;
&lt;h2&gt;Working locally&lt;/h2&gt;
&lt;p&gt;When git manages a directory on your computer we call this directory a local git repository.&lt;/p&gt;
&lt;p&gt;There are two ways to start to work in such a repository:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git clone &lt;span class="pre"&gt;https://github.com/some_user/some_repo.git&lt;/span&gt;&lt;/tt&gt; to download a project into a new directory &lt;tt class="docutils literal"&gt;some_repo&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git init&lt;/tt&gt; to make the current directory a git repository.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="unstaged-staged-committed"&gt;
&lt;h3&gt;Unstaged ➜ staged ➜ committed&lt;/h3&gt;
&lt;img alt="git local workflow" src="/images/blog/git_staging_commit.webp" style="width: 100%;" /&gt;
&lt;p&gt;&lt;strong&gt;Remember!&lt;/strong&gt; you can always see the current state and the staging / unstaging commands with &lt;tt class="docutils literal"&gt;git status&lt;/tt&gt;, so don't try to memorize them.&lt;/p&gt;
&lt;p&gt;When you are satisfied with the changes commit them:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;commit&lt;span class="w"&gt; &lt;/span&gt;-m&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;an informative message describing your change&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="exercise"&gt;
&lt;h3&gt;Exercise&lt;/h3&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Create a directory called &lt;tt class="docutils literal"&gt;jokes&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Make it a local git repository.&lt;/li&gt;
&lt;li&gt;Create a file called &lt;tt class="docutils literal"&gt;jokes.txt&lt;/tt&gt; in that directory.&lt;/li&gt;
&lt;li&gt;Write some funny stuff.&lt;/li&gt;
&lt;li&gt;Add and commit.
Try to have an informative commit message.&lt;/li&gt;
&lt;li&gt;Repeat steps 4-5 as many times as you want 🙃.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="explore-your-repo"&gt;
&lt;h3&gt;Explore your repo&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;log&lt;span class="w"&gt;                 &lt;/span&gt;&lt;span class="c1"&gt;# see the history&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;diff&lt;span class="w"&gt;                &lt;/span&gt;&lt;span class="c1"&gt;# see the unstaged changes&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;diff&lt;span class="w"&gt; &lt;/span&gt;--staged&lt;span class="w"&gt;       &lt;/span&gt;&lt;span class="c1"&gt;# see the staged changes&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;show&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;COMMIT_HASH&amp;gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;# see the changes in a commit&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="collaborating-through-github"&gt;
&lt;h2&gt;Collaborating through GitHub&lt;/h2&gt;
&lt;p&gt;GitHub is a place to share and collaborate on git repositories.
Go head and create an account!&lt;/p&gt;
&lt;p&gt;Your local git repository can be &amp;quot;linked&amp;quot; to remote repositories.
To see them run &lt;tt class="docutils literal"&gt;git remote&lt;/tt&gt; (or with extra info using &lt;tt class="docutils literal"&gt;git remote &lt;span class="pre"&gt;-v&lt;/span&gt;&lt;/tt&gt;).
If you cloned an existing repository you should see one remote, called &lt;tt class="docutils literal"&gt;origin&lt;/tt&gt;, in the list.
Otherwise, create a new GitHub repository and add it as a remote with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;remote&lt;span class="w"&gt; &lt;/span&gt;add&lt;span class="w"&gt; &lt;/span&gt;origin&lt;span class="w"&gt; &lt;/span&gt;https://github.com/you/your_repo.git
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Naming a remote &lt;tt class="docutils literal"&gt;origin&lt;/tt&gt; is just a convention. It has no special meaning.&lt;/p&gt;
&lt;div class="section" id="pull"&gt;
&lt;h3&gt;&lt;tt class="docutils literal"&gt;pull&lt;/tt&gt;&lt;/h3&gt;
&lt;p&gt;To get the latest changes (commits) from your remote run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;pull&lt;span class="w"&gt; &lt;/span&gt;origin&lt;span class="w"&gt; &lt;/span&gt;master
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;What's master? The name of the default branch.
More on that later.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="push"&gt;
&lt;h3&gt;&lt;tt class="docutils literal"&gt;push&lt;/tt&gt;&lt;/h3&gt;
&lt;p&gt;If you have permissions to push code to the remote repository you can update the remote with your changes (commits) by running:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;push&lt;span class="w"&gt; &lt;/span&gt;origin&lt;span class="w"&gt; &lt;/span&gt;master
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Remember!&lt;/strong&gt; Always &lt;tt class="docutils literal"&gt;pull&lt;/tt&gt; before you &lt;tt class="docutils literal"&gt;push&lt;/tt&gt; to avoid unnecessary conflicts.&lt;/p&gt;
&lt;img alt="git Austin Powers meme" src="/images/blog/git_meme.avif" style="width: 100%;" /&gt;
&lt;p&gt;Assuming that you already have a local repository with a remote (called &lt;tt class="docutils literal"&gt;origin&lt;/tt&gt;) that you can push code to, a simple but complete workflow might look like that:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;pull&lt;span class="w"&gt; &lt;/span&gt;origin&lt;span class="w"&gt; &lt;/span&gt;master&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="c1"&gt;# to get the latest changes&lt;/span&gt;
&lt;span class="c1"&gt;# work work work...&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;status&lt;span class="w"&gt;                     &lt;/span&gt;&lt;span class="c1"&gt;# to see all of the changes you did&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;diff&lt;span class="w"&gt;                       &lt;/span&gt;&lt;span class="c1"&gt;# optional but handy&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;add&lt;span class="w"&gt; &lt;/span&gt;FILE_WITH_CHANGES&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="c1"&gt;# repeat as necessary&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;commit&lt;span class="w"&gt; &lt;/span&gt;-m&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;your message&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="c1"&gt;# commit the changes to the repository&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;push&lt;span class="w"&gt; &lt;/span&gt;origin&lt;span class="w"&gt; &lt;/span&gt;master&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="c1"&gt;# to upload your changes&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="exercise-1"&gt;
&lt;h3&gt;Exercise&lt;/h3&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Create a new GitHub repo, called &lt;tt class="docutils literal"&gt;jokes&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Add it as a remote for your local &lt;tt class="docutils literal"&gt;jokes&lt;/tt&gt; repo.&lt;/li&gt;
&lt;li&gt;Push your jokes to GitHub.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="forks-and-pull-requests"&gt;
&lt;h3&gt;Forks and pull requests&lt;/h3&gt;
&lt;p&gt;If you don't have permissions to push code to a remote repository.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Fork the repository.
It will copy the remote repository to your account.&lt;/li&gt;
&lt;/ol&gt;
&lt;img alt="GitHub fork button" src="/images/blog/github_fork.webp" style="width: 100%;" /&gt;
&lt;ol class="arabic simple" start="2"&gt;
&lt;li&gt;Add your fork as a remote.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;remote&lt;span class="w"&gt; &lt;/span&gt;add&lt;span class="w"&gt; &lt;/span&gt;mine&lt;span class="w"&gt; &lt;/span&gt;https://github.com/you/your_repo.git
&lt;/pre&gt;&lt;/div&gt;
&lt;ol class="arabic simple" start="3"&gt;
&lt;li&gt;Work on your fork.&lt;/li&gt;
&lt;li&gt;Send your commits to the owner(s) of the projects using a pull request.&lt;/li&gt;
&lt;/ol&gt;
&lt;img alt="GitHub pull request button" src="/images/blog/github_pull_request.webp" style="width: 100%;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="exercise-2"&gt;
&lt;h3&gt;Exercise&lt;/h3&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Fork &lt;a class="reference external" href="https://github.com/Nagasaki45/mat-trivia"&gt;this repository&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Clone your fork so you'll have a local git repository on your computer.&lt;/li&gt;
&lt;li&gt;Answer some questions in one of the files in &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;mat-trivia/trivia/&lt;/span&gt;&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Stage the changes, commit, and push to your remote repo.&lt;/li&gt;
&lt;li&gt;Submit a pull request&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="where-to-go-next"&gt;
&lt;h2&gt;Where to go next?&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;em&gt;Branches&lt;/em&gt; are an important concept in git.
&lt;a class="reference external" href="http://learngitbranching.js.org/"&gt;Learn them here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Ignore files in the repo with &lt;tt class="docutils literal"&gt;.gitignore&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://speakerdeck.com/alicebartlett/git-for-humans"&gt;Good intro to git in slides format&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://stackoverflow.com/"&gt;Stack overflow&lt;/a&gt; for questions, as usual :-)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://git-scm.com/book/en/v2"&gt;Pro Git book&lt;/a&gt;: lots of info, sometime too verbose.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="tutorials"></category><category term="tools"></category></entry><entry><title>Dead of Winter: The Long Night - A DIY box insert</title><link href="/blog/dow-tln-insert" rel="alternate"></link><published>2019-02-08T00:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2019-02-08:/blog/dow-tln-insert</id><summary type="html">&lt;p&gt;As if there were not enough different topics mashed together in the blog, here's another one.
I'm into board games, and recently got &lt;a class="reference external" href="https://boardgamegeek.com/boardgame/193037/dead-winter-long-night"&gt;Dead of Winter: The Long Night&lt;/a&gt;.
This blog post is about the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;As if there were not enough different topics mashed together in the blog, here's another one.
I'm into board games, and recently got &lt;a class="reference external" href="https://boardgamegeek.com/boardgame/193037/dead-winter-long-night"&gt;Dead of Winter: The Long Night&lt;/a&gt;.
This blog post is about the box the game came in, and what I did to make it usable.&lt;/p&gt;
&lt;p&gt;Below you can see the cards, standees, and tokens after a single play.
Yes, that's a complete mess!&lt;/p&gt;
&lt;img alt="DoW: TLN box after one play. A total mess." src="/images/blog/dow-mess.avif" style="width: 100%;" /&gt;
&lt;p&gt;Thankfully, I'm not the first to be frustrated about this. A quick google search found &lt;a class="reference external" href="https://www.reddit.com/r/foamcore/comments/51mvio/comfc_dead_of_winter_the_long_night/"&gt;nezbokaj's plans&lt;/a&gt; for a DIY foamboard insert to keep all of the components organized. I followed his plans and I'm super happy with the results.&lt;/p&gt;
&lt;img alt="The box with all of the components organized." src="/images/blog/dow-organized-1.avif" style="width: 100%;" /&gt;
&lt;p&gt;To contribute back to these plans, &lt;a class="reference external" href="/images/blog/dow_tln_insert.svg"&gt;here's the cutting pattern&lt;/a&gt; I followed to get the most out of a A2 piece of foamboard.
First, &lt;strong&gt;use it as a reference!&lt;/strong&gt; Don't try to print it out and cut on top of the lines or anything like that. The lines are too wide for that.
Second, when you cut the foamboard, start by cutting everything into stripes by the measurements on the left side of the cutting patter.
Then, cut the stripes into pieces.
Lastly, in the picture below you can see that the insert pushes the lid a bit up.
Maybe about 5-7mm.
I think that a few millimeters can be taken of the deepest measurement (the 6.3cm).
On the other hand, the result is good enough for me.&lt;/p&gt;
&lt;img alt="The lid is lifted by a few millimeters." src="/images/blog/dow-lid.avif" style="width: 100%;" /&gt;
&lt;p&gt;The entire thing costed £6. £2.5 for the foamboard and the rest for some glue and a knife.&lt;/p&gt;
&lt;p&gt;Here are some more pictures from the process, including pictures with some of the boards in the box.&lt;/p&gt;
&lt;img alt="The foamboard insert, before it got into the box." src="/images/blog/dow-insert.avif" style="width: 100%;" /&gt;
&lt;img alt="Small boards (locations and player aids) in the box." src="/images/blog/dow-organized-2.avif" style="width: 100%;" /&gt;
&lt;img alt="Larger boards in the box." src="/images/blog/dow-organized-3.avif" style="width: 100%;" /&gt;
&lt;p class="bold"&gt;TL;DR: Go build &lt;a class="reference external" href="https://www.reddit.com/r/foamcore/comments/51mvio/comfc_dead_of_winter_the_long_night/"&gt;nezbokaj's insert for Dead of Winter: The Long Night&lt;/a&gt;, possibly using my &lt;a class="reference external" href="/images/blog/dow_tln_insert.svg"&gt;cutting pattern&lt;/a&gt;.&lt;/p&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="games"></category></entry><entry><title>Getting started with Python for data analysis</title><link href="/blog/getting-started-with-python" rel="alternate"></link><published>2017-11-10T00:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2017-11-10:/blog/getting-started-with-python</id><summary type="html">&lt;img alt="Python books covers" src="/images/blog/python_books.webp" style="width: 100%;" /&gt;
&lt;p&gt;A few days ago another friend asked me to recommend reading materials to get started with python.
Yesterday, I saw this tweet.&lt;/p&gt;
&lt;img alt="&amp;quot;When you've written the same code 3 times, write a function. When you've given the same in-person advice 3 times, write a blog post&amp;quot; - David Robinson‏" src="/images/blog/write_a_blog_post_tweet.webp" style="width: 100%;" /&gt;
&lt;p&gt;So here I am, writing this blog post.&lt;/p&gt;
&lt;p&gt;A short disclaimer:
I like …&lt;/p&gt;</summary><content type="html">&lt;img alt="Python books covers" src="/images/blog/python_books.webp" style="width: 100%;" /&gt;
&lt;p&gt;A few days ago another friend asked me to recommend reading materials to get started with python.
Yesterday, I saw this tweet.&lt;/p&gt;
&lt;img alt="&amp;quot;When you've written the same code 3 times, write a function. When you've given the same in-person advice 3 times, write a blog post&amp;quot; - David Robinson‏" src="/images/blog/write_a_blog_post_tweet.webp" style="width: 100%;" /&gt;
&lt;p&gt;So here I am, writing this blog post.&lt;/p&gt;
&lt;p&gt;A short disclaimer:
I like learning from books, but I know that it doesn't work for everybody.
So my recommendations are, unsurprisingly, for books.
Don't follow them if you don't like learning by reading.&lt;/p&gt;
&lt;p&gt;If you have some coding experience and want to dive straight to doing data analysis with python you can skip this paragraph.
If you are not so confident with your programming skills, and want to take it slowly, &lt;a class="reference external" href="https://www.manning.com/books/the-quick-python-book-third-edition"&gt;the Quick Python Book&lt;/a&gt;, by Naomi Ceder, is highly recommended.
My first steps with python were with the 2nd edition of the same book, and &lt;a class="reference external" href="/blog/python-readings"&gt;here are my thoughts on it&lt;/a&gt;.
In general, it's a bit wordy but the explanations are very clear and to the point.
In fact, being a bit verbose is probably what you want anyway if coding is new to you.
Note that a new edition is about to come out, and an ebook version is already available.
If you are looking for a shorter and faster introduction to python take a look at &lt;a class="reference external" href="https://learnxinyminutes.com/docs/python3/"&gt;Learn X in Y minutes&lt;/a&gt;. It is especially good for those who are already familiar with coding but are new to python.&lt;/p&gt;
&lt;p&gt;To get familiar with the python scientific stack I can highly recommend going over the first section of the &lt;a class="reference external" href="https://lectures.scientific-python.org/"&gt;Scipy Lecture Notes&lt;/a&gt;.
Their short intro to the language (chapter 1.2) is also great.
With this resource one can learn &lt;a class="reference external" href="http://www.numpy.org/"&gt;numpy&lt;/a&gt; and &lt;a class="reference external" href="https://matplotlib.org/"&gt;matplotlib&lt;/a&gt; relatively fast.
The last crucial building block in the python scientific stack that you must learn is &lt;a class="reference external" href="http://pandas.pydata.org/"&gt;pandas&lt;/a&gt;.
The canonical book for pandas is &lt;a class="reference external" href="http://shop.oreilly.com/product/0636920023784.do"&gt;Python for Data Analysis&lt;/a&gt; by Wes McKinney, the creator of the package.
Personally, &lt;a class="reference external" href="/blog/python-readings"&gt;I didn't like this book so much&lt;/a&gt;.
On the other hand, I really like everything coming from Jake Vanderplas, and his book, the &lt;a class="reference external" href="http://shop.oreilly.com/product/0636920034919.do"&gt;Python Data Science Handbook&lt;/a&gt; contains a chapter about pandas.
I didn't read it, but from my familiarity with his writing and from online comments I saw I think that I can stand behind this recommendation.&lt;/p&gt;
&lt;p&gt;After that stop reading, and start to solve some real world problems!&lt;/p&gt;
</content><category term="Blog"></category><category term="thoughts"></category><category term="books"></category><category term="python"></category></entry><entry><title>Python vs. elixir for a web-app wrapper for a script</title><link href="/blog/web-script" rel="alternate"></link><published>2017-08-27T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2017-08-27:/blog/web-script</id><summary type="html">&lt;img alt="Python vs. elixir" src="/images/blog/python_vs_elixir.webp" style="width: 100%;" /&gt;
&lt;p&gt;I'm a facing a project with the following requirements:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;An existing script should be wrapped with a web server.&lt;/li&gt;
&lt;li&gt;The script takes 10-30 seconds to run, so just let the user wait for it to …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;img alt="Python vs. elixir" src="/images/blog/python_vs_elixir.webp" style="width: 100%;" /&gt;
&lt;p&gt;I'm a facing a project with the following requirements:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;An existing script should be wrapped with a web server.&lt;/li&gt;
&lt;li&gt;The script takes 10-30 seconds to run, so just let the user wait for it to complete.&lt;/li&gt;
&lt;li&gt;Multiple users should be able to call the script concurrently.&lt;/li&gt;
&lt;li&gt;Make sure to protect the server from overloading by limiting the number of concurrent active scripts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I created a repo with two projects, in python and elixir, to see how easy / hard the task will be with each technology.
You can find the repo &lt;a class="reference external" href="https://github.com/Nagasaki45/web-script/"&gt;here&lt;/a&gt;.
The frontend, and the demo script to run, are the same for both projects.
Getting and validating user input is not demonstrated, as it should be straightforward in both languages.
The idea was to compare the concurrency stuff.&lt;/p&gt;
&lt;div class="section" id="python"&gt;
&lt;h2&gt;Python&lt;/h2&gt;
&lt;p&gt;The implementation is based on &lt;a class="reference external" href="https://aiohttp.readthedocs.io/en/latest/index.html"&gt;aiohttp&lt;/a&gt;, with no much extras.
There is a global counter to track the number of active scripts.
A new POST request checks the counter.
If it reaches the maximal allowed active scripts a 503 error is returned, indicating that the service is unavailable.
Otherwise, first, the counter is incremented.
Then, &lt;tt class="docutils literal"&gt;asyncio.create_subprocess_exec&lt;/tt&gt; is used to call the script.
Lastly, the result is returned to the user, and the counter is decremented under &lt;tt class="docutils literal"&gt;finally&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="elixir"&gt;
&lt;h2&gt;Elixir&lt;/h2&gt;
&lt;p&gt;The general idea is very similar.
The server is based on &lt;a class="reference external" href="https://github.com/ninenines/cowboy"&gt;cowboy&lt;/a&gt; and &lt;a class="reference external" href="https://github.com/elixir-plug/plug"&gt;plug&lt;/a&gt;.
Instead of a global counter I'm using &lt;a class="reference external" href="https://github.com/devinus/poolboy"&gt;poolboy&lt;/a&gt; to create a pool of workers for calling the script.
On each POST request, if the pool if full, the 503 error is returned.
Otherwise, the script is called and the result is returned to the user.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusions"&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;I'm a complete asyncio newbie, and wasn't sure how complex the implementetion will be.
It always feel a bit restrictive for me.
For example, without the already implemented &lt;tt class="docutils literal"&gt;asyncio.subprocess&lt;/tt&gt; module, following the requirements would be much more difficult.
I'm also more confident with elixir, as I use it almost exclusively for everything web-based.
With elixir you can use whatever library you want and make use of all of the concurrency feature of the language without any special adapters.
Surprisingly, the python solution ended up much simpler than I thought, and it is much shorter than the elixir solution (mainly due to the way a project is structured in elixir).
So, I ended with two easy to use options, hence the decision between them will be even harder.
Or maybe it's time to properly learn asyncio.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="thoughts"></category><category term="python"></category><category term="elixir"></category><category term="asyncio"></category></entry><entry><title>DIY eurorack case</title><link href="/blog/eurorack-case" rel="alternate"></link><published>2017-07-16T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2017-07-16:/blog/eurorack-case</id><summary type="html">&lt;img alt="Final eurorack case." src="/images/blog/eurorack_case_header.avif" style="width: 100%;" /&gt;
&lt;p&gt;I recently drawn into the rabbit hole of modular synthesis.
This week I finished building my first eurorack case.
It's a 3U 84hp skiff.
Or in humans language, it is a relatively small, beginners sized …&lt;/p&gt;</summary><content type="html">&lt;img alt="Final eurorack case." src="/images/blog/eurorack_case_header.avif" style="width: 100%;" /&gt;
&lt;p&gt;I recently drawn into the rabbit hole of modular synthesis.
This week I finished building my first eurorack case.
It's a 3U 84hp skiff.
Or in humans language, it is a relatively small, beginners sized case, to accommodate my first modules.&lt;/p&gt;
&lt;div class="section" id="the-plan"&gt;
&lt;h2&gt;The plan&lt;/h2&gt;
&lt;p&gt;I have access to a laser cutter at uni, so I thought that it will be great to use it for the project.
Add to that some &lt;a class="reference external" href="https://www.thingiverse.com/thing:1206004"&gt;open source designs for laser cutting eurorack cases&lt;/a&gt;, and it looked like an easy path to follow.
But then I started to rethink it too much.
I already bought the &lt;a class="reference external" href="http://www.tiptopaudio.com/zrails.php"&gt;Tiptop audio Z-Rails&lt;/a&gt; to fit into the case, which is not exactly the same as the one in the design above,
In addition, our laser cutter can cut much thicker wood than the 6mm used in this design.
So maybe I will design my own case...&lt;/p&gt;
&lt;p&gt;I decided to do so, and with the help of &lt;a class="reference external" href="https://makeabox.io/"&gt;make a box&lt;/a&gt; produced my own design files, for a 9mm plywood.
And if I'm already using the laser cutter to cut the wood, why not add a stylistic engraved texture on top of it?
Inspired by &lt;a class="reference external" href="http://archive.eyebeam.org/projects/generative-laser-cuts"&gt;Aaron Meyers&lt;/a&gt;, I opened processing and started to code a generative texture to engrave over my case.
I was sure that engraving the texture will be the most complicated part in this DIY project, but I was wrong.
Very wrong.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="what-didn-t-work"&gt;
&lt;h2&gt;What didn't work&lt;/h2&gt;
&lt;p&gt;These are the mistakes I made.
All of them could be avoided easily.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Consider the position of the screws that connect the rails to the case. I didn't thought about it, and it ended to be very close to a cut, as you can see in the picture.&lt;/li&gt;
&lt;/ul&gt;
&lt;img alt="Problematic screw positioning." src="/images/blog/eurorack_case_screw.avif" style="width: 100%;" /&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Make sure that the laser cutter can actually cut the material you got! And if unsure, try on a small piece of material before starting. I checked with the workshop instruction, and was sure that 9mm will be fine. On the first attempt, when I configured the laser cutter to attempt to cut 9mm, it ran so slowly that the material caught fire (you can see the burned area in the upper left corner in the picture above)! Then, I speed it up, but with higher speed it took around 20 iterations until it was cut properly. Two consequences of the issues I gut with the cuttings are the burned cut, and...&lt;/li&gt;
&lt;li&gt;The cut ended up way wider than I expected. I thought that the laser will cut the material very precisely, and in minimal width, but the cut ended up to be pretty wide (I will say ~2 millimeters).&lt;/li&gt;
&lt;li&gt;Make sure you got the dimensions right! I checked online and saw that modules are 128.5mm high. I added the width of the top edge of the Z-Rails, which is 1.2mm, to each side, and ended up with 131mm as the internal height for the case. THIS IS WRONG! It seems that the correct height should be 133.35mm, but recheck for yourself. I had to use chisel to trim 1mm from the top and the bottom pieces to open some more room for the rails.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="the-went-well"&gt;
&lt;h2&gt;The went well&lt;/h2&gt;
&lt;p&gt;The engraving ended up much better than I expected.
I started with one PDF file for the entire engraving job, with an overall length of lines to engrave just over 100 meters.
When I tried to send this file to the printer the driver's preview window didn't show all of the lines in my PDF.
Maybe it's just a presentation issue, but I decided to separate the job into layers.
This was easy for my case, as the lines were generated by &lt;a class="reference external" href="https://processing.org/"&gt;processing&lt;/a&gt; one by one without any dependencies between them.
In the original PDF there were 30K lines, so I created 6 PDFs with 5K lines each, that when overlaid create the same result.
I really glad I did that for few reasons.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;I didn't know if the printer will move like a regular printer (with one axis moving forwards all the time and the other forwards and backwards repeatedly), or that it will do the lines one by one as they were &amp;quot;recorded&amp;quot; in the pdf (random order), or will optimize the movement. Apparently, it optimizes the movement, meaning that it starts from one corner and draws line by line from there towards the other side of the board. If I had send the whole plan, and the process was too slow, I would have been ended up with only half of the board engraved. Fortunately, each layer took &amp;quot;only&amp;quot; 53 minutes, so it wasn't a real problem.&lt;/li&gt;
&lt;li&gt;Second, with this layered approach I could see the state of the engraving after each layer and decide if I want to continue to the next layer or not. Eventually, I stopped after the 4th layer as the result was good enough for me.&lt;/li&gt;
&lt;/ul&gt;
&lt;img alt="The engraved texture before cutting." src="/images/blog/eurorack_case_engraving.avif" style="width: 100%;" /&gt;
&lt;p&gt;I also cut some blank panels on the way, from 3mm plywood.
An easy task for the laser printer.
In addition, the gluing and finishing (with danish oil) were successful and without any issues.
But there is nothing interesting I can tell you about these, so let's move on.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="files-and-disclaimer"&gt;
&lt;h2&gt;Files and disclaimer&lt;/h2&gt;
&lt;p&gt;The design files are &lt;a class="reference external" href="https://github.com/Nagasaki45/eurorack-case"&gt;here&lt;/a&gt;.
Feel free to use the engraving sketch in &lt;tt class="docutils literal"&gt;generative_waves/generative_waves.pde&lt;/tt&gt; for whatever you want.
As far as I can tell the blank panels files are also fine.
&lt;strong&gt;BUT PLEASE DON'T USE THE FILES IN THIS REPO TO CUT A EURORACK CASE!&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="to-summarize"&gt;
&lt;h2&gt;To summarize&lt;/h2&gt;
&lt;p&gt;It's not the most accurate build, but my new case does the job.
Despite the problems, IMHO the end result looks very good.
And finally I'm starting to play with it, and enjoy every moment!&lt;/p&gt;
&lt;img alt="Jamming with my new eurorack case." src="/images/blog/eurorack_case_jam.avif" style="width: 100%;" /&gt;
&lt;p&gt;If you want to see more &lt;a class="reference external" href="https://photos.app.goo.gl/dPukY2PL1LhajZlZ2"&gt;here is an album of the entire building process&lt;/a&gt;.
Some modular music will come soon.
Stay tuned!&lt;/p&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="music"></category><category term="modular"></category></entry><entry><title>git crash course</title><link href="/blog/git-crash-course" rel="alternate"></link><published>2017-01-31T17:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2017-01-31:/blog/git-crash-course</id><summary type="html">&lt;p&gt;A really short introduction to git for my PhD fellas.&lt;/p&gt;
&lt;div class="section" id="first-trygit"&gt;
&lt;h2&gt;First, &lt;a class="reference external" href="https://try.github.io/"&gt;TryGit&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;div class="section" id="clone-something"&gt;
&lt;h2&gt;Clone something&lt;/h2&gt;
&lt;p&gt;There are two ways to start to work in a git repository.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git clone &lt;span class="pre"&gt;https://github.com/some_user/some_repo.git&lt;/span&gt;&lt;/tt&gt; to …&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;A really short introduction to git for my PhD fellas.&lt;/p&gt;
&lt;div class="section" id="first-trygit"&gt;
&lt;h2&gt;First, &lt;a class="reference external" href="https://try.github.io/"&gt;TryGit&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;div class="section" id="clone-something"&gt;
&lt;h2&gt;Clone something&lt;/h2&gt;
&lt;p&gt;There are two ways to start to work in a git repository.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git clone &lt;span class="pre"&gt;https://github.com/some_user/some_repo.git&lt;/span&gt;&lt;/tt&gt; to download a project into a new directory &lt;cite&gt;some_repo&lt;/cite&gt;.&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git init&lt;/tt&gt; to make the current directory a git repository.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Go ahead and clone a project of interest.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="working-locally"&gt;
&lt;h2&gt;Working locally&lt;/h2&gt;
&lt;img alt="git local workflow" src="/images/blog/git_staging_commit.webp" style="width: 100%;" /&gt;
&lt;p&gt;&lt;strong&gt;Remember!&lt;/strong&gt; you can always see the current state and the staging / unstaging commands with &lt;tt class="docutils literal"&gt;git status&lt;/tt&gt;, so don't try to memorize them.&lt;/p&gt;
&lt;p&gt;When you are satisfied with the changes commit them:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;commit&lt;span class="w"&gt; &lt;/span&gt;-m&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;an informatice message describing your change&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="explore"&gt;
&lt;h2&gt;Explore&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;log&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;# see the history&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;diff&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;# see the unstaged changes&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;diff&lt;span class="w"&gt; &lt;/span&gt;--staged&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;# see the staged changes&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;show&lt;span class="w"&gt; &lt;/span&gt;&amp;lt;COMMIT_HASH&amp;gt;&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="c1"&gt;# see the changes in a commit&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="collaborating-through-github"&gt;
&lt;h2&gt;Collaborating through GitHub&lt;/h2&gt;
&lt;p&gt;GitHub is a place to share and collaborate on git repositories.&lt;/p&gt;
&lt;p&gt;Your local git repository can be &amp;quot;linked&amp;quot; to remote repositories.
To see them run &lt;tt class="docutils literal"&gt;git remote&lt;/tt&gt;.
If you cloned an existing repository you should see one remote, called &lt;tt class="docutils literal"&gt;origin&lt;/tt&gt;, in the list.
Otherwise, create a new GitHub repository and add it as a remote with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;remote&lt;span class="w"&gt; &lt;/span&gt;add&lt;span class="w"&gt; &lt;/span&gt;origin&lt;span class="w"&gt; &lt;/span&gt;https://github.com/you/your_repo.git
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="section" id="pull"&gt;
&lt;h3&gt;&lt;tt class="docutils literal"&gt;pull&lt;/tt&gt;&lt;/h3&gt;
&lt;p&gt;To get the latest changes (commits) from your remote run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;pull&lt;span class="w"&gt; &lt;/span&gt;origin&lt;span class="w"&gt; &lt;/span&gt;master
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="push"&gt;
&lt;h3&gt;&lt;tt class="docutils literal"&gt;push&lt;/tt&gt;&lt;/h3&gt;
&lt;p&gt;To update the remote with your changes (commits) run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;push&lt;span class="w"&gt; &lt;/span&gt;origin&lt;span class="w"&gt; &lt;/span&gt;master
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Remember!&lt;/strong&gt; Always &lt;tt class="docutils literal"&gt;pull&lt;/tt&gt; before you &lt;tt class="docutils literal"&gt;push&lt;/tt&gt; to avoid unnecessary conflicts.&lt;/p&gt;
&lt;img alt="git Austin Powers meme" src="/images/blog/git_meme.avif" style="width: 100%;" /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="a-simple-but-complete-workflow"&gt;
&lt;h2&gt;A simple but complete workflow&lt;/h2&gt;
&lt;p&gt;Assuming that you already have a local repository with a remote (called &lt;tt class="docutils literal"&gt;origin&lt;/tt&gt;) that you can push code to:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;pull&lt;span class="w"&gt; &lt;/span&gt;origin&lt;span class="w"&gt; &lt;/span&gt;master&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="c1"&gt;# to get the latest changes&lt;/span&gt;
&lt;span class="c1"&gt;# work work work...&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;status&lt;span class="w"&gt;                     &lt;/span&gt;&lt;span class="c1"&gt;# to see all of the changes you did&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;diff&lt;span class="w"&gt;                       &lt;/span&gt;&lt;span class="c1"&gt;# optional but handy&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;add&lt;span class="w"&gt; &lt;/span&gt;FILE_WITH_CHANGES&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="c1"&gt;# repeat as necessary&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;commit&lt;span class="w"&gt; &lt;/span&gt;-m&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;your message&amp;quot;&lt;/span&gt;&lt;span class="w"&gt;   &lt;/span&gt;&lt;span class="c1"&gt;# commit the changes to the repository&lt;/span&gt;
git&lt;span class="w"&gt; &lt;/span&gt;push&lt;span class="w"&gt; &lt;/span&gt;origin&lt;span class="w"&gt; &lt;/span&gt;master&lt;span class="w"&gt;         &lt;/span&gt;&lt;span class="c1"&gt;# to upload your changes&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="more-info-and-resources"&gt;
&lt;h2&gt;More info and resources&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;em&gt;Branches&lt;/em&gt; are an important concept in git. &lt;a class="reference external" href="http://learngitbranching.js.org/"&gt;Learn it&lt;/a&gt;!&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://git-scm.com/book/en/v2"&gt;Pro Git book&lt;/a&gt;: lots of info, sometime too verbose.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="tutorials"></category><category term="tools"></category></entry><entry><title>Media and arts projects - part 2</title><link href="/blog/media-and-arts-projects-part-2" rel="alternate"></link><published>2017-01-10T22:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2017-01-10:/blog/media-and-arts-projects-part-2</id><summary type="html">&lt;img alt="The tapeless cassettes" src="/images/blog/tapeless_cassettes_header.avif" style="width: 100%;" /&gt;
&lt;p&gt;In a &lt;a class="reference external" href="/blog/media-and-arts-projects-part-1"&gt;previous post&lt;/a&gt; I wrote about my assignments for the sound recording module I took as part of my PhD.
Here, I will present the projects of the Interactive Digital Multimedia Techniques module.&lt;/p&gt;
&lt;div class="section" id="the-tapeless-cassettes"&gt;
&lt;h2&gt;The …&lt;/h2&gt;&lt;/div&gt;</summary><content type="html">&lt;img alt="The tapeless cassettes" src="/images/blog/tapeless_cassettes_header.avif" style="width: 100%;" /&gt;
&lt;p&gt;In a &lt;a class="reference external" href="/blog/media-and-arts-projects-part-1"&gt;previous post&lt;/a&gt; I wrote about my assignments for the sound recording module I took as part of my PhD.
Here, I will present the projects of the Interactive Digital Multimedia Techniques module.&lt;/p&gt;
&lt;div class="section" id="the-tapeless-cassettes"&gt;
&lt;h2&gt;The tapeless cassettes&lt;/h2&gt;
&lt;p&gt;In the first major project of the module we were required to find some unused object and create an interactive digital &amp;quot;something&amp;quot; out of it.
The title for the projects, and the following event in which they were presented, was &amp;quot;CruftFest&amp;quot;.
My project, the tapeless cassettes, uses modified audio cassettes as controllers for an interactive and collaborative musical interface.
It invites users to manually turn the cassettes wheels, with their pinky or a BIC® pen, to control the speed of the music.
The interaction is simple and intuitive - the higher the speed of the wheel, the faster the music.
I assembled multiple cassettes to enable a group of users to play together, letting each one to control different track in the music.
The resulted sounds fluctuate in speed and in pitch, and therefore cannot be synchronized.
The lack of synchronization, which is unusual in familiar music, suggest different type of interactions with the musical materials and between players.&lt;/p&gt;
&lt;p&gt;More details can be found in the project page &lt;a class="reference external" href="https://github.com/Nagasaki45/TapelessCassettes"&gt;on github&lt;/a&gt;.&lt;/p&gt;
&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/JZ3Z4X_d1iQ" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;Here are a few pictures of the project from the CruftFest event.&lt;/p&gt;
&lt;img alt="Playing with the cassettes." src="https://lh3.googleusercontent.com/VssKhoacTmRKKIkZKfqmk_NNoiydcAHpXOgUiH0CVhe-s9riEPPs6MMuyAeuTTQd189YpEDEv9Xd0XeA4eJck6TQGre7ToGeLK3w0fDixOnk7BsGDgQYgjSehc7Enb5gDyyeUC-LsrYhybPM05ZbbFLbWJLeCvdZzMFnezp6se23xrp0AFt8PRynLILP7wq9TER2lOZ_727DYn-LvIrmAxV-ai_VUuyylA-PH0a3qudT0URXRcTUhU5RULUVG_RUX7eypD6eoUpmTUUdnNE4VLQ7JaUj2QUOOemyJQNvsGgy30g25GBXSV_aQM2ZVB0Kyw8_7omZmH51VYN273ijHEVCl3ll_VtaLmKJMORlUVNbYjYWRDkRj7wtiuvUMs4f_abSK2tkUV_FUcIoc9C9i_Q_c-GIzyRJZ4Z2mqkU7YNz1LAwFdJJV6XgxHGN4dh36UEv8QscGAjPDdmCOJpMhn4K76RNs1eVRwOJU09IV1TTtgVQU-qe5utXnMiLUKkLInPIzCSm7FlHUfuFg7mvQF6NMjgFUm4gIRYv6bBYdHs29cXrwn3VLAzpczuKUgnMS3xx_6PN4rPMxLTTRcEBCKJ_NS2v9t2Sk2vTdiRNYqAMS4sCa5f8Jg=w942-h628-no" style="width: 100%;" /&gt;
&lt;img alt="Playing with the cassettes." src="https://lh3.googleusercontent.com/VssKhoacTmRKKIkZKfqmk_NNoiydcAHpXOgUiH0CVhe-s9riEPPs6MMuyAeuTTQd189YpEDEv9Xd0XeA4eJck6TQGre7ToGeLK3w0fDixOnk7BsGDgQYgjSehc7Enb5gDyyeUC-LsrYhybPM05ZbbFLbWJLeCvdZzMFnezp6se23xrp0AFt8PRynLILP7wq9TER2lOZ_727DYn-LvIrmAxV-ai_VUuyylA-PH0a3qudT0URXRcTUhU5RULUVG_RUX7eypD6eoUpmTUUdnNE4VLQ7JaUj2QUOOemyJQNvsGgy30g25GBXSV_aQM2ZVB0Kyw8_7omZmH51VYN273ijHEVCl3ll_VtaLmKJMORlUVNbYjYWRDkRj7wtiuvUMs4f_abSK2tkUV_FUcIoc9C9i_Q_c-GIzyRJZ4Z2mqkU7YNz1LAwFdJJV6XgxHGN4dh36UEv8QscGAjPDdmCOJpMhn4K76RNs1eVRwOJU09IV1TTtgVQU-qe5utXnMiLUKkLInPIzCSm7FlHUfuFg7mvQF6NMjgFUm4gIRYv6bBYdHs29cXrwn3VLAzpczuKUgnMS3xx_6PN4rPMxLTTRcEBCKJ_NS2v9t2Sk2vTdiRNYqAMS4sCa5f8Jg=w942-h628-no" style="width: 100%;" /&gt;
&lt;img alt="Playing with two cassettes together." src="https://lh3.googleusercontent.com/wtO0fG91UFniA3yWIvGQRtIf_uv4T0IE0FJLFnzOHqjkUz77Be0usqalQE5DRXVj9dT40nyUI1aXg-S-7LLgbXBEngdCb8NWjxD2-9FTEZNf3Fm6FUXZwZFpb3qNdLlMVvNpXLdFVazkJGaBpnn0v47OgAQJpMEX9np6ZvBwXVQ7y96uV-4SoIMP6cTA62DgHBhW72vi9laqmfPZ6kdgX4M8M8sa4VirXi_7JyV1TrVI5DIIiojxENXBxHfvxHPo55wVuw6rCovQD2PdWrD_C4tEUxUrXin_iIiG-kIjhm43hmNoiQzvCNnHp8hyfGFyc6-QKrExdOFCIe0AQwy3HsQeUmJoCaGBeU9zNq5Bsr13eFceBw3Bq7_CaH24feqov1OHuAJPTCYS-MR8um3DZl8xc7qW0MkJMYEDg-BNrg7tmnGYg5eeVPPnjIu7vS9G2A2dFeSQmakk0CgSfBUm0Ne29nME6Iv4coEKZd_aemnstVzNXbaxIIbIQgNwpiAtNzEtZk-3xA8vQRMOOxJkBz2UXwa60k79nt5NfqUOpmNHD2N_IPBglV9W7W02TfJ-PErolVOSTIRTitLPUlLl7N1IkwE3bsRB1aAfqyjb7Bf5b3qZ5txBQA=w942-h628-no" style="width: 100%;" /&gt;
&lt;img alt="Presenting the project to Andrew McPherson." src="https://lh3.googleusercontent.com/SnxMdzevYmFSlyUD80fL62Dh_35OeYRJB9CmHgqPw7NzPsnPaGACpreHi4iGgeHVYGCn_4sUqrsLb1TJ-c5WLfE6qVSqJzXEpd4CasDvriRBe3JdU32ro9K02orkv68DOLFcp1c7acE44AU9TqO9nV4STDAMJhKp8-iWldjA2sq2f63Z__PjXw6aHZRXkOKVHej5Roj1dDSEdGgHs2R3HaJgyjgRrUlmRBn4vVlJo0sD2kNZR-ldJhkdrW1jhp-qBSNnnWG6a-6M1VtU6HaboEkgw7hCChpH1E02jZ1sIE2Yb9bml_pbbvRQKpwZhwDAjlplsfjr4vT55z7_p26vP-nHwAWWWibZ9jqFa0fhnsItbSaJ5kaBl4DmZUFPgQfG3EknJmt7hA9kreYAI7lY3Ugwf8oQ1gUkxnpo41Gj1fr7peh7R0xsLn09YNi8IQ1rscrtuw7RBhB7cVZagP7vyM2lU6uLys86EB8o-HvxHmvAlKqc4SN4wvYACrDim28UrR9kmfnESKeifecjD3AYV0yd6HneIe9lCsr48WoRYnQdctYidvriQWJlSEMtdaiKAjYAXvFj6W9n3NFPmYZbL5S8nCWIPdJDNELa1FugMlwrpJaxeQ4pZw=w471-h628-no" style="width: 100%;" /&gt;
&lt;img alt="Vanessa and Sebastian playing together." src="https://lh3.googleusercontent.com/Ztw4_E5dijN8uKB2F2EYO94dPO98EB8FhMWzGP-v4miJ_uJaelhWysRqn9Wca09u2C4BuWijIC7-AZEx-ZwvqOJqma4TNVNdqjhT5HjRuiS1lvANC8Uy7qwvwa0TJ_OsJl9yVTsJWwPwKWm2QCCDTdRALPUQjHcuus3rB9R9m45S1rEMtHFdBnx0TFH5Tw8sLQmz53UJP25_ebHQbtqi8RXmoSNE9zluR0D1OOOsAhTZkC-kofEUD8PraOj25FcDPXZWhCV8NLt68H22x2919iZi8JL1NDbw_BK7aSqnk5Q8gS1cpsqDMnuL0kYafsmTCiC9boNqfkirTWMc1K5j209Ktm5_0FWIJ9ysXWX3Sn1xEPJVr0rRn5AKteHr8Y8hlHzOv8C3ngRocog4lA3R0BhwudbdHF7G-xihxDqrbgwEn2l0ZiplItsyY1PGHCgz-N_asM3r3EKBQt4ebVrMjiU63sfc2mE1HHwAjto6gTJBpoG1POi5mUYOlEoMXQiYs2jPjwqtll4cuCsBDK-AFLihKecFWLEPi20RM_VL93rl753WIUffLYOfrJPiTmt1Zbxxnlh78BIyQKgdWNyscnFVEuL0SPxvUV5YeVcMOyGuKRCA6dVGUA=w838-h628-no" style="width: 100%;" /&gt;
&lt;/div&gt;
&lt;div class="section" id="schleikess-suspenders-in-yiddish"&gt;
&lt;h2&gt;Schleikess (&amp;quot;suspenders&amp;quot; in Yiddish)&lt;/h2&gt;
&lt;p&gt;As the final project for the module I created the Schleikess - a controller for full-body interactive performances.
It requires force and effort to play with, hopefully facilitating expressiveness.
The interface is composed of two elastic bands that are attached to the performers' belt loops on one side, and a main unit that measures the tension on each elastic band.
The performer holds the other side of each elastic band and stretches them to play.
In the current work, a generative drum machine is used to demonstrate the capabilities of this controller by mapping the tension on the bands to tempo the pitch properties of the drums.&lt;/p&gt;
&lt;p&gt;Again, all of the bits and bytes can be found &lt;a class="reference external" href="https://github.com/Nagasaki45/Schleikess"&gt;online&lt;/a&gt;.&lt;/p&gt;
&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/_BUf_VLCIWQ" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;And a few more pictures from the presentation event.&lt;/p&gt;
&lt;img alt="30 seconds presentation." src="https://lh3.googleusercontent.com/gEDGzxqM9c8ODxE8f3fZZGN9LPa3yW6TCk55tYz3PKmS5LxdagbjhL6Yxh8IqcDsAxUrrIsGCtW4z_gqjq2tZZjL3d92_87GIjrCYW8cfP4YYb31wsAUC9H1ZWh066trLB_EAolViafK0fQ6nCeS2Ol4kGFX7Yxhc6vAgnuksqCNzlqgufGp69Qf1m5hIYOpM9jLs48hAgEy2MJHogD0KeIYK8GR1h6Rz5Y0VNtMSMjjRLsieg2UUCiLE-r63BfD3krlUKU2Pjq-CMaScyw_Obr_y6qvZQIMX26Iq7eWh4SvWwSXxVydsaMGwPtuyhWzbDFR9WqGwnK-J3jZTOMbrkU9Ge8QuQmgtSe4ASi5jC7UgXOIlY7OTH_h-_7Nymx_ujWE3hKnv96cf8coZEMRMPeVdKM5d1X4VAk5iN1Gxbs9hM2QFWK4OwB2WfdOPDTXtVcdIjL77xXypW1n4hjmMzzbvoH438P_hG5CqynxNoLAn-uRbO4XBIbBecsDUgn69QbNJcV8XW9UWJpZttp7AZyuylYmf9GZnIRXshb9InPz6VK1BHu9MH4OKEXdXvMmcvQ9tcVRSqcOiUa5L9oVN9IFJUHWEiX-Pr4Ntux6ZTEjs9fKOxdZZQ=w948-h628-no" style="width: 100%;" /&gt;
&lt;img alt="The Schleikess are ready for demonstration." src="https://lh3.googleusercontent.com/9990Q8RappPQwljaT3UAYZDW8KUE9eCjYA41mgcEWFHkqSKyPS_rRRH0vkC_J41pdGEpYq8r9Fy9sfzu1l3UfQWFVPBB_05UnkEY0Eu6ES2i8uUV5yxluZC-0UzkO3gL3nW8N84IfOLUYHfDgFrrp-yFunrd06rWh-RABCvLI1tbzfUJ74b0DNTDpC6vrB5vy-xOI9_4wfxY9WR-_rYqfmdVBazsAaoQlaR4spIwaIFuejSNVcBvXRS3kbWm1ayeLr9JQQivy_Flpw4HCK5VG4VLJQxKCYoDv4zd_iwn4lU_qnosVY8bWqyoZ2gaSzJP4-Sws5RO6M4HyeniZ5ccmsOwkmL1_IQfT3gTErTqt-x_wLE5ezdlel6jFSODtDrsVdvo8qI6iZ5yaZIjKyaujWAezRDRQxkI5VrgNc1O_Nbwajrn9biJTf5rob7PhyTgU_IZ6gDwgc7g6ip04XPAwZoiwvH0R3hwMuPq_aRNcDJi7LqhgsCdzhBdRP5WbUKD5a0tOKBe-3ENVfpy3M5h_CwgC6akwhKNu21SoC0MHNpap4t60hwR9nHMES9761I_hkwwAZV_sfpRrXLeRYcZDafA_zLToSn1gcLY9SA7kKGSxAtJWmvjVQ=w838-h628-no" style="width: 100%;" /&gt;
&lt;img alt="Presenting to Andrew McPherson." src="https://lh3.googleusercontent.com/wO_aOOhvQbECirKp_OjTUEUMA9yrs6QsrIOx8f6JKocSuStAQlcnwx2qC2-BzMjA0j6Rb7FlxPLjYRfKXbl0y5HnKwoZ5PBMV6U-OsTxLiGJujSxcPFEP77YtvqYhJFfnUMcdckAMNer11Fdy_oBViPMH30vgzIXaOkNWeOUdpErli_N0Qu1P6pWS4uK65leOLOXBL6JzLY3Xbl3jk78aEr0jRazHQ6FaAnSIq5Mbsz84I9iKXkbJYZfUKiWZbiVAyWu7qmVu4hq6qC5dnqIaefNDQFvx4uDaQbDJrPF6ia2RqNwWaMmf6VXaESUtIw6ifQMHbcoEa8xOc0m4i1bTyqCCHypvP6ZtyuR7Rv2BiecJLBWgzKW69QttYUT-rTXvOF_Pe1qYqueLUW7IVlnijcEfdEKvLEt_vUiQFS4_Q7rbqAZWqxoYwFjDghfsF0Ogmb4XAWy51H-Pf8WOiUfI6wqbSHcu3CJQrxYK5Ve8oPWuK_T6U1kDUwocHH-iq1dTaDFhLimNPwQPVL1HIiGfdhBC4XBZjk8bWX3YTQbGF6yI_uz8W3J2WJHHetEe7UO24aliW8zCi-v006caaWWdD6FmG6xzP-djcG_RKMcLr3RCORQ7lYaFg=w471-h628-no" style="width: 100%;" /&gt;
&lt;img alt="Vivek and I." src="https://lh3.googleusercontent.com/IgUo4Wmzh8JZxjqD0F5e6CotqIVTNZl5Ie2hC_GCENueF2DANC1v5-JHC50DuPyzvehmeRM6rXUOz80lsWEiYYSE76-F2oDNFbzqGNQ1CnrdYEgaXdUmcmfK2SC5s-k9aWohYJPe_Biop5696oc2DrXrmTOHEy3_uy3n5EZAEknZFcx9hckLYPjc7OD0I7PVtoKUNVmWDjB_5LdjE-juK32KF0hgsxg-d-ZpWhNBD0V2CJMiK3G_I6BF8v5ws0koOzq-mDw7mYQ5O3B_wfsGyvgtGqAT6j9d5Eq3r0p5tlgu4ytqC21eqndVUTZWl6v0cadG5OSR2i3H29WaEljTzWVOwnjYGjQLj7aw6BGTB_kXcCkIO2AMWnjyuZNTdJ6B47_AEbdMvD_-g8buAr0JRllBC7bdhj1PcL0su6N-_W4ssEBZu_LHSMJalNp-Z0CnNtDIp9BoNkBb--QZupnVTue0Ia_vq_wG7VwQc6fBSVakhjUsOnnSKtJmRLjiC05AHHQ0tJdZu4Po5hTwkxFH4qG0b6et-4lBY0xAIb6LKMUTSsBU-Tv4qCxrU-idhSudkWHTpjN4DfOhwjzSeOIF96YmAJlB5CRqGxIKM_Oxfn9UMSFSco3ZKA=w471-h628-no" style="width: 100%;" /&gt;
&lt;img alt="Vivek and II." src="https://lh3.googleusercontent.com/hcTnB_CbGswBJ2nom4zTug8ZPsrWV38VRff6Mb41B8EcoAzvJPxQ2dqhuJUBi-_BDuewhY2k5d1arutsdSq5MuL8dzS8q01cPLg8u1l2aVjHRxxsnc-aKQWTfTzrl4z7W-A_IvU_MZOaor74xCG7vG-ARKT5IET_jrFhoKx4fKYneKreIa5efTOONlLu1oI92BSj-QaDyF3JMGXRzAFVd9Qwq_gkhJzhEO4jKcXj1HmJgsanB5wI435Zq0G4JLM1eRTnGyk9STX9uoM77tsVydEaq1ol9PkGW889RvZUk6yHhA-EAZnAXYUZkJOwcLE5es0EOgLRkRhqkBjJkWhSve5c3p4w8C7CZ7dRvzW8zV4bQm8jyH-CKyGhfNnNQZzMKBWfdD19n1PIE32mUmO3Yrdl9oqSkPY_clwhddrO12Nwmxp3jp9GF-7UJ_Aze-Ildw957kKlNB1iDC9fxEQ3y6Bpaqy0yrwIDuodB9jhnPGvhPa0FkiqGRvbGkNJ1aRQEm8f9ccXATGF8-5mbvENGTzEU3mFclfc36bEcAwnLhVKvQK3bZCLPH9PnFR7URoNx-ehkidwsNtENppWpvDQb51_w2TMbX8_5dYhNo0NpmbXwtTNpfNVfA=w471-h628-no" style="width: 100%;" /&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="arduino"></category><category term="demo"></category><category term="music programming"></category></entry><entry><title>Media and arts projects - part 1</title><link href="/blog/media-and-arts-projects-part-1" rel="alternate"></link><published>2016-12-29T22:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2016-12-29:/blog/media-and-arts-projects-part-1</id><summary type="html">&lt;img alt="Sunset Riders - Bury me with my money" src="/images/blog/bury_me_with_my_money.gif" style="width: 100%;" /&gt;
&lt;p&gt;I recently shared some of my &lt;a class="reference external" href="/blog/my-first-assignment-as-a-phd-student"&gt;first experiences as a PhD student&lt;/a&gt; in the &lt;a class="reference external" href="http://www.mat.qmul.ac.uk/"&gt;Media and Arts Technology program&lt;/a&gt;, Queen Mary University of London.
Now, when the first term is over and the second one …&lt;/p&gt;</summary><content type="html">&lt;img alt="Sunset Riders - Bury me with my money" src="/images/blog/bury_me_with_my_money.gif" style="width: 100%;" /&gt;
&lt;p&gt;I recently shared some of my &lt;a class="reference external" href="/blog/my-first-assignment-as-a-phd-student"&gt;first experiences as a PhD student&lt;/a&gt; in the &lt;a class="reference external" href="http://www.mat.qmul.ac.uk/"&gt;Media and Arts Technology program&lt;/a&gt;, Queen Mary University of London.
Now, when the first term is over and the second one is about to begin, it is a good time to show the projects I have been working on.
This post is therefore the first in a series of 3 posts.
Here I will present my assignments to the Sound Recording and Production Techniques module.&lt;/p&gt;
&lt;div class="section" id="bury-me-with-my-money"&gt;
&lt;h2&gt;&amp;quot;Bury me with my money!&amp;quot;&lt;/h2&gt;
&lt;iframe width="100%" height="300" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/300118139&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;visual=true"&gt;&lt;/iframe&gt;&lt;p&gt;The first significant project in the module was to produce a short soundscape.
Each student wrote a concept on a piece of paper and the concepts were picked by chance by other students.
Mine was &amp;quot;Bury me with my money!&amp;quot;. WTF!?!
After a short research I found the origin of the line, in the 90s arcade game Sunset Riders, and a long list of MEMEs surrounding it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="digital-privacy"&gt;
&lt;h2&gt;&amp;quot;Digital privacy&amp;quot;&lt;/h2&gt;
&lt;iframe width="100%" height="300" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/300119056&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;visual=true"&gt;&lt;/iframe&gt;&lt;p&gt;The instructions for the final project were similar to the previous one.
We were asked to compose another soundscape, but this time we got more freedom to choose the concept by ourselves, and it was required to be a bit longer.
I decided to seize the opportunity and play with deep neural networks on the way.
The idea was to use similar techniques to those presented by &lt;a class="reference external" href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/"&gt;google wavenet&lt;/a&gt; earlier this year (if you are not familiar with this research yet, go and take a look, it's fascinating!), to create a model that will be able to listen to audio and then generate new audio with similar characteristics.
I wanted to train the model on sounds of private conversations and sex of my partner and I, recorded in our apartment, and use the trained model to generate new audio material that will be used as the basis for the soundscape.&lt;/p&gt;
&lt;p&gt;As a serious PhD student I gave the soundscape the title &amp;quot;Digital privacy&amp;quot; and described it as &amp;quot;mirroring the existing conflicts between art, artificial intelligence, and privacy in the age of ubiquitous surveillance&amp;quot;.
The truth is, I really want to delve into deep learning and thought that it might be a good way to start :-).&lt;/p&gt;
&lt;p&gt;Although I played with machine learning in the past, I'm completely new to deep learning, and after several attempt this first ambitious idea turned out to be a complete failure.
In the end, I used audio samples that I found on the web that were generated in similar techniques.
However, I documented my attempts, so next time I (or someone else) will succeed. You can find all the information &lt;a class="reference external" href="https://github.com/Nagasaki45/digital-privacy-soundscape/blob/master/report/report.md"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="music"></category><category term="PhD"></category></entry><entry><title>Phoenix, templates, and active navbar items</title><link href="/blog/phoenix-templates-and-active-navbar-items" rel="alternate"></link><published>2016-12-22T15:30:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2016-12-22:/blog/phoenix-templates-and-active-navbar-items</id><summary type="html">&lt;p&gt;We build a web-app, and want the items on the navigation bar to be active when the user visits the corresponding page, like this:&lt;/p&gt;
&lt;img alt="An animated example of active navigation bar items." src="/images/blog/navbar_active_items.gif" style="width: 100%;" /&gt;
&lt;p&gt;I'm not saying that this is a complicated task in other …&lt;/p&gt;</summary><content type="html">&lt;p&gt;We build a web-app, and want the items on the navigation bar to be active when the user visits the corresponding page, like this:&lt;/p&gt;
&lt;img alt="An animated example of active navigation bar items." src="/images/blog/navbar_active_items.gif" style="width: 100%;" /&gt;
&lt;p&gt;I'm not saying that this is a complicated task in other frameworks, but it often feels &amp;quot;hacky&amp;quot;.
Here is a &lt;a class="reference external" href="http://www.phoenixframework.org/"&gt;phoenix&lt;/a&gt; solution that feels pretty elegant, and therefore worth sharing.&lt;/p&gt;
&lt;p&gt;So, let's start with a simple &lt;a class="reference external" href="https://getbootstrap.com/"&gt;twitter-bootstrap&lt;/a&gt; navbar example for our web-app, with links to our home, products, and about pages.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;nav&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;navbar navbar-default&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;ul&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;nav navbar-nav&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;li&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;#&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Home&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;li&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;li&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;#&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;Products&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;li&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;li&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;#&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;About&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;li&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;ul&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;nav&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Right now, none of the links are highlighted.
We need to add a &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;class=&amp;quot;active&amp;quot;&lt;/span&gt;&lt;/tt&gt; to the &lt;tt class="docutils literal"&gt;&amp;lt;li&amp;gt;&lt;/tt&gt; item that corresponds to the current page.
The question is, how can we do it dynamically, according to the current visited page?&lt;/p&gt;
&lt;p&gt;The &lt;a class="reference external" href="https://hexdocs.pm/plug/readme.html#the-plug-conn"&gt;&lt;tt class="docutils literal"&gt;Plug.Conn&lt;/tt&gt;&lt;/a&gt; contains all of the information for the current request/response cycle, and is available in our views and template.
Moreover, the &lt;tt class="docutils literal"&gt;&amp;amp;Phoenix.Controller.action_name/1&lt;/tt&gt; function expects a &lt;tt class="docutils literal"&gt;Plug.Conn&lt;/tt&gt; and returns the name of the controller function that was used to process the request.
With this information in mind, let's create a template to render navbar &lt;tt class="docutils literal"&gt;&amp;lt;li&amp;gt;&lt;/tt&gt; items.
First, we will have to make the &lt;tt class="docutils literal"&gt;action_name&lt;/tt&gt; function available in our views.
Edit &lt;tt class="docutils literal"&gt;web/web.ex&lt;/tt&gt; to import it to all of the views.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt; # Import convenience functions from controllers
&lt;span class="gd"&gt;- import Phoenix.Controller, only: [get_csrf_token: 0, get_flash: 2, view_module: 1]&lt;/span&gt;
&lt;span class="gi"&gt;+ import Phoenix.Controller, only: [get_csrf_token: 0, get_flash: 2, view_module: 1, action_name: 1]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we are ready to create the template for the navbar items:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cm"&gt;&amp;lt;!-- web/templates/layout/navbar_item.html.eex --&amp;gt;&lt;/span&gt;

&lt;span class="err"&gt;&amp;lt;&lt;/span&gt;%= if action_name(@conn) == @action do %&amp;gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;li&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;active&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="err"&gt;&amp;lt;&lt;/span&gt;%= else %&amp;gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;li&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="err"&gt;&amp;lt;&lt;/span&gt;%= end %&amp;gt;
  &lt;span class="err"&gt;&amp;lt;&lt;/span&gt;%= link @text, to: page_path(@conn, @action) %&amp;gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;li&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Notice that this template expects the &lt;tt class="docutils literal"&gt;conn&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;action&lt;/tt&gt; (as an atom), and &lt;tt class="docutils literal"&gt;text&lt;/tt&gt; (for the link) as assigns.
It also uses the &lt;tt class="docutils literal"&gt;link&lt;/tt&gt; function to create the &lt;tt class="docutils literal"&gt;&amp;lt;a&amp;gt;&lt;/tt&gt; tags automatically by finding the path in the routing table for us.
We can already use it by replacing our previous navbar with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;nav&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;navbar navbar-default&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;ul&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;nav navbar-nav&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;lt;&lt;/span&gt;%= render &amp;quot;navbar_item.html&amp;quot;, conn: @conn, action: :index, text: &amp;quot;Home&amp;quot; %&amp;gt;
    &lt;span class="err"&gt;&amp;lt;&lt;/span&gt;%= render &amp;quot;navbar_item.html&amp;quot;, conn: @conn, action: :products, text: &amp;quot;Products&amp;quot; %&amp;gt;
    &lt;span class="err"&gt;&amp;lt;&lt;/span&gt;%= render &amp;quot;navbar_item.html&amp;quot;, conn: @conn, action: :about, text: &amp;quot;About&amp;quot; %&amp;gt;
  &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;ul&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;nav&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;However, it is even more elegant and concise to add the following function to the layout view:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# web/views/layout_view.ex&lt;/span&gt;

&lt;span class="kd"&gt;def&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;navbar_item&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;assigns&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;do&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;render&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;navbar_item.html&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;assigns&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And improve the navbar:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;nav&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;navbar navbar-default&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;ul&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;nav navbar-nav&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="err"&gt;&amp;lt;&lt;/span&gt;%= navbar_item conn: @conn, action: :index, text: &amp;quot;Home&amp;quot; %&amp;gt;
    &lt;span class="err"&gt;&amp;lt;&lt;/span&gt;%= navbar_item conn: @conn, action: :products, text: &amp;quot;Products&amp;quot; %&amp;gt;
    &lt;span class="err"&gt;&amp;lt;&lt;/span&gt;%= navbar_item conn: @conn, action: :about, text: &amp;quot;About&amp;quot; %&amp;gt;
  &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;ul&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;nav&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In addition to &lt;tt class="docutils literal"&gt;action_name&lt;/tt&gt;, you might also be interested in &lt;tt class="docutils literal"&gt;Phoenix.Controller.controller_module&lt;/tt&gt;, as suggested &lt;a class="reference external" href="http://stackoverflow.com/a/36009443/1224456"&gt;here&lt;/a&gt;.
I hope that this short tutorial helped you.
Good luck with your navbar!&lt;/p&gt;
</content><category term="Blog"></category><category term="tutorials"></category><category term="elixir"></category><category term="phoenix"></category><category term="web"></category></entry><entry><title>An Even Better Pip Worflow™</title><link href="/blog/an-even-better-pip-workflow" rel="alternate"></link><published>2016-11-04T23:50:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2016-11-04:/blog/an-even-better-pip-workflow</id><summary type="html">&lt;p&gt;The 9th major version of &lt;a class="reference external" href="https://pypi.python.org/pypi/pip"&gt;&lt;tt class="docutils literal"&gt;pip&lt;/tt&gt;&lt;/a&gt;, the recommended tool for installing python packages, was released two days ago. I took a short look on &lt;a class="reference external" href="https://pip.pypa.io/en/stable/news/"&gt;the changelog&lt;/a&gt; to see what's new. At first, I couldn't notice …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The 9th major version of &lt;a class="reference external" href="https://pypi.python.org/pypi/pip"&gt;&lt;tt class="docutils literal"&gt;pip&lt;/tt&gt;&lt;/a&gt;, the recommended tool for installing python packages, was released two days ago. I took a short look on &lt;a class="reference external" href="https://pip.pypa.io/en/stable/news/"&gt;the changelog&lt;/a&gt; to see what's new. At first, I couldn't notice anything that will change my current workflows. Usually, the important changes are listed first, but there was nothing groundbreaking there. However, I kept reading, to find this:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Add &lt;em&gt;--not-required&lt;/em&gt; option to &lt;tt class="docutils literal"&gt;pip list&lt;/tt&gt; to list packages that are not dependencies of other packages.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In &amp;quot;&lt;a class="reference external" href="http://www.kennethreitz.org/essays/a-better-pip-workflow"&gt;A Better Pip Workflow™&lt;/a&gt;&amp;quot;, Kenneth Reitz describes a problematic aspect of dependencies management in python. Usually, we &amp;quot;freeze&amp;quot; the state of the dependencies of a project with &lt;tt class="docutils literal"&gt;pip freeze &amp;gt; requirements.txt&lt;/tt&gt; to reproduce the exact environment later with &lt;tt class="docutils literal"&gt;pip install &lt;span class="pre"&gt;-r&lt;/span&gt; requirements.txt&lt;/tt&gt;. The problem starts when you want to upgrade these dependencies. Take this &lt;a class="reference external" href="https://github.com/Nagasaki45/blog"&gt;blog dependencies&lt;/a&gt; for example.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$&lt;span class="w"&gt; &lt;/span&gt;pip&lt;span class="w"&gt; &lt;/span&gt;list
blinker&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;.4&lt;span class="o"&gt;)&lt;/span&gt;
docutils&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.12&lt;span class="o"&gt;)&lt;/span&gt;
feedgenerator&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;.8&lt;span class="o"&gt;)&lt;/span&gt;
Jinja2&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.8&lt;span class="o"&gt;)&lt;/span&gt;
MarkupSafe&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.23&lt;span class="o"&gt;)&lt;/span&gt;
pelican&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.6.0&lt;span class="o"&gt;)&lt;/span&gt;
pelican-readtime&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.1.2&lt;span class="o"&gt;)&lt;/span&gt;
pelican-youtube&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.2.0&lt;span class="o"&gt;)&lt;/span&gt;
pip&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;9&lt;/span&gt;.0.0&lt;span class="o"&gt;)&lt;/span&gt;
Pygments&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.1.3&lt;span class="o"&gt;)&lt;/span&gt;
python-dateutil&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.5.3&lt;span class="o"&gt;)&lt;/span&gt;
pytz&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;2016&lt;/span&gt;.4&lt;span class="o"&gt;)&lt;/span&gt;
setuptools&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;28&lt;/span&gt;.8.0&lt;span class="o"&gt;)&lt;/span&gt;
six&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;.10.0&lt;span class="o"&gt;)&lt;/span&gt;
Unidecode&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.4.19&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Ideally, I would like to manage only the packages I call directly from code / command line (let's call them the &amp;quot;top most dependencies&amp;quot; from now on), and let them manage their dependencies for me. Therefore, I would have to read this output carefully to decide what to upgrade: &amp;quot;did I install Pygments? and what about docutils? I know for sure that pelican-youtube was installed manually, so let's &lt;tt class="docutils literal"&gt;pip install &lt;span class="pre"&gt;--upgrade&lt;/span&gt; &lt;span class="pre"&gt;pelican-youtube&lt;/span&gt;&lt;/tt&gt;&amp;quot; and so forth...&lt;/p&gt;
&lt;p&gt;Kenneth's recommendation to simplify the upgrade process is to keep two requirements files, the 1st includes all of the dependencies with their versions (&lt;tt class="docutils literal"&gt;pip freeze &amp;gt; requirements.txt&lt;/tt&gt;), and the 2nd, &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;requirements-to-freeze.txt&lt;/span&gt;&lt;/tt&gt; should be &lt;strong&gt;managed manually&lt;/strong&gt; to contain the top most dependencies. When it's time for an upgrade, call &lt;tt class="docutils literal"&gt;pip install &lt;span class="pre"&gt;-r&lt;/span&gt; &lt;span class="pre"&gt;requirements-to-freeze.txt&lt;/span&gt; &lt;span class="pre"&gt;--upgrade&lt;/span&gt;&lt;/tt&gt;. Just don't forget to run &lt;tt class="docutils literal"&gt;pip freeze &amp;gt; requirements.txt&lt;/tt&gt; immediately afterwards!&lt;/p&gt;
&lt;p&gt;With the flag introduced in &lt;tt class="docutils literal"&gt;pip&lt;/tt&gt; 9.0.0, there is no more need for the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;requirements-to-freeze.txt&lt;/span&gt;&lt;/tt&gt; file. To find out which packages should be upgraded run &lt;tt class="docutils literal"&gt;pip list &lt;span class="pre"&gt;--not-required&lt;/span&gt;&lt;/tt&gt;. However, there are still some caveats to note:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;The &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;--not-required&lt;/span&gt;&lt;/tt&gt; flag is implemented for &lt;tt class="docutils literal"&gt;pip list&lt;/tt&gt; and not for &lt;tt class="docutils literal"&gt;pip freeze&lt;/tt&gt;. They have different format. When the later is suitable for requirement files the former is not. Here is a &lt;a class="reference external" href="https://github.com/pypa/pip/issues/4088"&gt;github issue&lt;/a&gt; to implement the same flag for &lt;tt class="docutils literal"&gt;pip freeze&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;Assuming that the previous issue will be solved, I couldn't find a &lt;strong&gt;nice&lt;/strong&gt; (read as &amp;quot;no bash scripting&amp;quot;) way to pipe the output of &lt;tt class="docutils literal"&gt;pip freeze &lt;span class="pre"&gt;--not-required&lt;/span&gt;&lt;/tt&gt; to &lt;tt class="docutils literal"&gt;pip install &lt;span class="pre"&gt;--upgrade&lt;/span&gt;&lt;/tt&gt;. There is still an intermediate phase of creating a temporary &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;requirements-to-freeze.txt&lt;/span&gt;&lt;/tt&gt; file.&lt;/li&gt;
&lt;li&gt;Until the first issue will be resolved, we will upgrade &lt;tt class="docutils literal"&gt;pip&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;setuptools&lt;/tt&gt; with our top most dependencies. The reason is that they are listed by &lt;tt class="docutils literal"&gt;pip list&lt;/tt&gt; but not by &lt;tt class="docutils literal"&gt;pip freeze&lt;/tt&gt;.&lt;/li&gt;
&lt;li&gt;We will probably want to strip the version numbers from the output of &lt;tt class="docutils literal"&gt;pip list &lt;span class="pre"&gt;--not-required&lt;/span&gt;&lt;/tt&gt;. It is meaningless to ask pip to upgrade but state the old versions in the same time.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="demo-time"&gt;
&lt;h2&gt;Demo time!&lt;/h2&gt;
&lt;p&gt;Let's try things out by updating this blog dependencies! First, let's see the top most dependencies:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$&lt;span class="w"&gt; &lt;/span&gt;pip&lt;span class="w"&gt; &lt;/span&gt;list&lt;span class="w"&gt; &lt;/span&gt;--not-required
pelican&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.6.0&lt;span class="o"&gt;)&lt;/span&gt;
pelican-readtime&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.1.2&lt;span class="o"&gt;)&lt;/span&gt;
pelican-youtube&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.2.0&lt;span class="o"&gt;)&lt;/span&gt;
pip&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;9&lt;/span&gt;.0.0&lt;span class="o"&gt;)&lt;/span&gt;
setuptools&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;28&lt;/span&gt;.8.0&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;OK. Considering the caveats above, we will need some bash scripting here. First, we want to remove the versions from the output. &lt;tt class="docutils literal"&gt;sed&lt;/tt&gt; might be our friend here. Let's try to use it to remove the versions completely by taking everything from the space to the end of the line and replacing it by an empty string:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$&lt;span class="w"&gt; &lt;/span&gt;pip&lt;span class="w"&gt; &lt;/span&gt;list&lt;span class="w"&gt; &lt;/span&gt;--not-required&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;sed&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;s/ .*//&amp;#39;&lt;/span&gt;
pelican
pelican-readtime
pelican-youtube
pip
setuptools
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Great! Let's pass this to &lt;tt class="docutils literal"&gt;pip install &lt;span class="pre"&gt;--upgrade&lt;/span&gt;&lt;/tt&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$&lt;span class="w"&gt; &lt;/span&gt;pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;--upgrade&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;pip&lt;span class="w"&gt; &lt;/span&gt;list&lt;span class="w"&gt; &lt;/span&gt;--not-required&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;sed&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;s/ .*//&amp;#39;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;
...
Successfully&lt;span class="w"&gt; &lt;/span&gt;installed&lt;span class="w"&gt; &lt;/span&gt;feedgenerator-1.9&lt;span class="w"&gt; &lt;/span&gt;pelican-3.6.3&lt;span class="w"&gt; &lt;/span&gt;pytz-2016.7
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That's all. The top most dependencies were upgraded.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="thoughts"></category><category term="python"></category><category term="tools"></category></entry><entry><title>My first assignment as a PhD student</title><link href="/blog/my-first-assignment-as-a-phd-student" rel="alternate"></link><published>2016-10-11T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2016-10-11:/blog/my-first-assignment-as-a-phd-student</id><summary type="html">&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/GCLCNuh4-Fs" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;So, what do you see here? Actually, nothing special. Yes, it is my first
assignment as a PhD student in the &lt;a class="reference external" href="http://www.mat.qmul.ac.uk/"&gt;Media and Arts Technology&lt;/a&gt; programme at
Queen Mary University of London. And yes, it …&lt;/p&gt;</summary><content type="html">&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/GCLCNuh4-Fs" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;So, what do you see here? Actually, nothing special. Yes, it is my first
assignment as a PhD student in the &lt;a class="reference external" href="http://www.mat.qmul.ac.uk/"&gt;Media and Arts Technology&lt;/a&gt; programme at
Queen Mary University of London. And yes, it is a simple &lt;a class="reference external" href="https://www.arduino.cc/"&gt;arduino&lt;/a&gt; exercise. So
why does it deserve a blog post?&lt;/p&gt;
&lt;p&gt;The thing that make this assignment interesting, for me, is the shift in mindset
that it proposes. In the last two years I've been working as a software
developer. As I see it, software engineering most of the time aims to &amp;quot;solve a
problem&amp;quot;. It can be a bug fix or a new feature, but the motivation is similar.
Here, on the other hand, the motivation is completely different - more like &amp;quot;try
something new that might be artistically interesting&amp;quot;. Personally, I can find
both approaches motivated, but it about time to start to explore the 2nd one a
bit more.&lt;/p&gt;
&lt;p&gt;In addition, I think that this assignment also demonstrate that:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Trying out new things should be fun.&lt;/li&gt;
&lt;li&gt;You don't need take yourself too seriously when doing science.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I really hope that all of these will continue to resonate throughout my PhD.&lt;/p&gt;
</content><category term="Blog"></category><category term="thoughts"></category><category term="PhD"></category><category term="arduino"></category></entry><entry><title>docker-compose in production - part 2</title><link href="/blog/docker-compose-in-production-part-2" rel="alternate"></link><published>2016-08-05T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2016-08-05:/blog/docker-compose-in-production-part-2</id><summary type="html">&lt;p&gt;Few months ago I shared my &lt;a class="reference external" href="/blog/docker-compose-in-production"&gt;experiences with docker-compose in production&lt;/a&gt;.
Recently I faced another deployment and decided to use the same technique. This
time I used it somewhat differently. In this blog post I …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Few months ago I shared my &lt;a class="reference external" href="/blog/docker-compose-in-production"&gt;experiences with docker-compose in production&lt;/a&gt;.
Recently I faced another deployment and decided to use the same technique. This
time I used it somewhat differently. In this blog post I would like to share the
new experiences.&lt;/p&gt;
&lt;p&gt;I started by following the process that went so well last time, which summarized
to:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Create a &lt;tt class="docutils literal"&gt;Dockerfile&lt;/tt&gt; for the app.&lt;/li&gt;
&lt;li&gt;Create a &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;docker-compose.yml&lt;/span&gt;&lt;/tt&gt; file with my app and its dependencies (official postgres and redis docker images).&lt;/li&gt;
&lt;li&gt;&lt;tt class="docutils literal"&gt;git clone&lt;/tt&gt; the project on the server.&lt;/li&gt;
&lt;li&gt;Build the project &lt;strong&gt;on the server&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Copy the &amp;quot;secrets&amp;quot; file to the server.&lt;/li&gt;
&lt;li&gt;Spin everything with &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;docker-compose&lt;/span&gt; up&lt;/tt&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But guess what? My digital ocean's droplet has only 512MB of RAM, which are not
enough for building the image. The beloved technique couldn't work with my
server!&lt;/p&gt;
&lt;div class="section" id="docker-hub-to-the-rescue"&gt;
&lt;h2&gt;&lt;a class="reference external" href="https://hub.docker.com/"&gt;Docker Hub&lt;/a&gt; to the rescue&lt;/h2&gt;
&lt;p&gt;OK. I can't build the image on the server, but I still want to use docker and
docker-compose for all of their advantages. The solution will be to build the
image somewhere else, upload it to &lt;a class="reference external" href="https://hub.docker.com/"&gt;Docker Hub&lt;/a&gt;- an open and free repository
for docker images - and fetch it from there directly to the server.&lt;/p&gt;
&lt;p&gt;There are two ways to upload a docker image to Docker Hub. The first is to link
it to your github account and instruct it to build an image whenever you push
code to the repository. The second is to build the image locally and push it to
the Hub using the docker command line tool. I wished I could choose the first
option, but due to memory restrictions the build failed on their build servers
similarly to the way it failed on my digital ocean droplet. Therefore, I choose
the 2nd option.&lt;/p&gt;
&lt;p&gt;With this revised deployment technique there are only two files on the server,
the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;docker-compose.yml&lt;/span&gt;&lt;/tt&gt; file and the &amp;quot;secrets&amp;quot; file. In my first blog post
about docker-compose the &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;docker-compose.yml&lt;/span&gt;&lt;/tt&gt; used the current directory as
the &lt;tt class="docutils literal"&gt;build&lt;/tt&gt; path for the image. Now, the full image name on Docker Hub is
referenced. Here is my &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;docker-compose.yml&lt;/span&gt;&lt;/tt&gt; file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;web&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;image&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;nagasaki45/krihelinator_web&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;ports&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;80:80&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;links&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;db&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p p-Indicator"&gt;-&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;stash&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;env_file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;./secrets&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;restart&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;always&lt;/span&gt;

&lt;span class="nt"&gt;db&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;image&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;postgres&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;restart&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;always&lt;/span&gt;

&lt;span class="nt"&gt;stash&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;image&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;redis&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;restart&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="l l-Scalar l-Scalar-Plain"&gt;always&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="summary"&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;Ideally, a server should only serve the application to the clients, and run the
necessary infrastructure to support it. Building or compiling a project on the
server is possible, but it doesn't have to be that way. With docker and
docker-compose based deployments the build can be done on one machine (be it
your local machine, Docker Hub's dedicated build servers, or some other
continuous integration / delivery server). But it's not only possible, it even
simplifies the process a bit as there is no source code involved, and less
operations run on the server. Give docker-compose a try, you won't regret it.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="thoughts"></category><category term="docker"></category><category term="web"></category><category term="tools"></category></entry><entry><title>Migrating to python3</title><link href="/blog/migrating-to-python3" rel="alternate"></link><published>2016-06-25T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2016-06-25:/blog/migrating-to-python3</id><summary type="html">&lt;p&gt;I was recently asked, by my boss, about the possible benefits of migrating our
code base at work from python 2.6 to python 3. Instead of sending an email back
to my boss with …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I was recently asked, by my boss, about the possible benefits of migrating our
code base at work from python 2.6 to python 3. Instead of sending an email back
to my boss with my answer, I decided that it worth a blog post. Why? because the
internet is full with comparisons between python 2 and python 3, but it is hard
to tell what are the real gains from doing the migration. Here, I will try to
explain, in a very subjective manner, the benefits I see from such move.&lt;/p&gt;
&lt;p&gt;So let's start with the obvious, &lt;strong&gt;python 3 is clearly a better language than
python 2.6&lt;/strong&gt;: &lt;tt class="docutils literal"&gt;print&lt;/tt&gt; is a function instead of a statement, now with sane
arguments; dict and set comprehensions reduce unnecessary, error prone,
verbosity; real division by default, because that's what you want 99% of the
time anyway; iterators by default (&lt;tt class="docutils literal"&gt;range&lt;/tt&gt; replaced &lt;tt class="docutils literal"&gt;xrange&lt;/tt&gt;,
&lt;tt class="docutils literal"&gt;dict.items()&lt;/tt&gt; replaced &lt;tt class="docutils literal"&gt;dict.iteritems()&lt;/tt&gt;, etc.); explicit relative
imports... Actually, the list goes on and on. However, I &lt;strong&gt;don't&lt;/strong&gt; think that
the features above are good reasons to migrate a large project. Modern python
code, written with python 3 in mind, will benefit from them, that's for sure. But
we do not want to rewrite our code base, we want the transition to be as smooth
as possible.&lt;/p&gt;
&lt;p&gt;So what &lt;strong&gt;is&lt;/strong&gt; valuable? Here is my list:&lt;/p&gt;
&lt;div class="section" id="we-must-leave-python-2-6"&gt;
&lt;h2&gt;We must leave python 2.6&lt;/h2&gt;
&lt;p&gt;Our server is based on &lt;a class="reference external" href="https://pypi.python.org/pypi/Twisted"&gt;twisted&lt;/a&gt;, which already dropped support for python 2.6.
Our other main dependency is &lt;a class="reference external" href="http://www.sqlalchemy.org/"&gt;SQLAlchemy&lt;/a&gt;. I don't think that they are going to
drop support for python 2.6 anytime soon but this day will surely come. In
general, staying with python 2.6 will soon mean that for each dependency upgrade
we will have to upgrade everything at once, which is kind of a nightmare.&lt;/p&gt;
&lt;p&gt;So, if we must leave python 2.6 behind and upgrade, I really don't think that
migrating to python 3.5, for example, will be way too complicated than to 2.7.
Moreover, moving to python 2.7 now will require another migration, with similar
effort, in the next 4 years.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="what-features-do-worth-the-upgrade"&gt;
&lt;h2&gt;What features do worth the upgrade&lt;/h2&gt;
&lt;div class="section" id="exception-chaining"&gt;
&lt;h3&gt;&lt;a class="reference external" href="https://www.python.org/dev/peps/pep-3134/"&gt;Exception chaining&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In python 3, when an exception is raised from within an &lt;tt class="docutils literal"&gt;except&lt;/tt&gt; block, it is
concatenated to the former exception, and the traceback of both is available to
whoever catch them. That way, we can always be sure that our top most logging
system will log the entire traceback, even if the latest exception &amp;quot;mask&amp;quot; the
original one.&lt;/p&gt;
&lt;p&gt;This feature could solve us several debugging hours. Even more, I'm sure that we
gave up on lots of bugs we couldn't investigate properly, as the original
exception was lost due to a bug in the &lt;tt class="docutils literal"&gt;except&lt;/tt&gt; block.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="unorderable-types"&gt;
&lt;h3&gt;&lt;a class="reference internal" href="#unorderable-types"&gt;Unorderable types&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;If something is broken, I prefer it to raise exception as soon as possible. In
python 2, the following won't fail!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="c1"&gt;# python2&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;hello&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;WTF?!? Why should anyone allow comparison between a string and an int!?!
Moreover, what is the result, &lt;tt class="docutils literal"&gt;True&lt;/tt&gt; or &lt;tt class="docutils literal"&gt;False&lt;/tt&gt;? In python 3 this issue was
solved for good:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="c1"&gt;# python3&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;hello&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;Traceback&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;most&lt;/span&gt; &lt;span class="n"&gt;recent&lt;/span&gt; &lt;span class="n"&gt;call&lt;/span&gt; &lt;span class="n"&gt;last&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;File&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;lt;stdin&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="ne"&gt;TypeError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;unorderable&lt;/span&gt; &lt;span class="n"&gt;types&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Again, we saw such bugs before in our system, and they are hard to spot. Having
the language solve this corner for us will be great.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="list-comprehensions-that-doesn-t-leak"&gt;
&lt;h3&gt;List comprehensions that doesn't leak&lt;/h3&gt;
&lt;p&gt;Again, another source for nasty bugs.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="c1"&gt;# python2&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;42&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;squares&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;xrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;9&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="c1"&gt;# python3&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;42&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;squares&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;xrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="mi"&gt;42&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="and-much-more"&gt;
&lt;h2&gt;And much more&lt;/h2&gt;
&lt;p&gt;Apart from new features there are the plethora of packages that we can't use
with python 2.6. External dependencies gradually drop support, while the
standard library continuously improves with new and shiny tools, such as
&lt;tt class="docutils literal"&gt;concurrent.futures&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;asyncio&lt;/tt&gt;.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="thoughts"></category><category term="python"></category></entry><entry><title>Continuous integration and delivery with travis-ci and codeship</title><link href="/blog/continuous-integration-and-delivery-with-travis-ci-and-codeship" rel="alternate"></link><published>2016-05-30T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2016-05-30:/blog/continuous-integration-and-delivery-with-travis-ci-and-codeship</id><summary type="html">&lt;img alt="Travis vs. Codeship" src="/images/blog/travis_codeship.webp" style="width: 100%;" /&gt;
&lt;p&gt;Generally speaking, continuous integration (CI) is the process of
running your test suite automatically when you push code to your repo.
Continuous delivery / deployment (CD) is the process of deploying the
new code to your …&lt;/p&gt;</summary><content type="html">&lt;img alt="Travis vs. Codeship" src="/images/blog/travis_codeship.webp" style="width: 100%;" /&gt;
&lt;p&gt;Generally speaking, continuous integration (CI) is the process of
running your test suite automatically when you push code to your repo.
Continuous delivery / deployment (CD) is the process of deploying the
new code to your server whenever you push to specific branches in your
repo. There is enough information about these on the web so I won't
cover it here. Instead, I would like to talk about travis-ci and
codeship, which are: online services that help you accomplish these
tasks easily; tightly integrated with github; free for open source
projects; very recommended. There are many similar services, of course,
but I won't mention them as I didn't use them enough to have an opinion.
So, let's start with travis.&lt;/p&gt;
&lt;div class="section" id="travis-ci"&gt;
&lt;h2&gt;&lt;a class="reference external" href="https://travis-ci.org/"&gt;Travis-CI&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;AFAIK, travis is the natural CI choice for python developers, and for
good reasons:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;It's the easiest to configure and use.&lt;/li&gt;
&lt;li&gt;Configuration is kept in the git repo, using a YAML file. Therefore,
it is version controlled, which is always a good thing.&lt;/li&gt;
&lt;li&gt;It will run your tests against a set of python versions, each one in
its own build (AKA a test matrix).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are situations, however, in which travis might not be enough for
you, especially when you want to set up continuous deployment. Enters
codeship.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="codeship"&gt;
&lt;h2&gt;&lt;a class="reference external" href="https://codeship.com/"&gt;Codeship&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Codeship is clearly inferior:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;It is configured using a web interface, using bash scripts to prepare
the environment, run the tests, and deploy (with different script per
branch, which is nice). Yep, you're expected to type bash scripts into
web forms!&lt;/li&gt;
&lt;li&gt;The environment setup is lacking. The &lt;a class="reference external" href="https://codeship.com/documentation/languages/python/"&gt;official recommendation for setting
the python version&lt;/a&gt;, for example, looks like a hack.&lt;/li&gt;
&lt;li&gt;You can't define a test matrix.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It sounds bad, I know, but on the other hand codeship has one feature
that is crucial to my workflow. Each project on codeship have an
ssh-key. Therefore, once you copied the public key to your server
&lt;tt class="docutils literal"&gt;authorized_keys&lt;/tt&gt; file, codeship can ssh / scp to it without
additional effort, exactly as you do from your development environment.&lt;/p&gt;
&lt;p&gt;For example, I have static sites that use a simple script to generate
the site and upload it to the server using &lt;tt class="docutils literal"&gt;rsync&lt;/tt&gt;. From my
development environment it looks like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;make&lt;span class="w"&gt; &lt;/span&gt;rsync_upload
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And guess what? The codeship deployment script do exactly the same when
I push code to the &lt;tt class="docutils literal"&gt;master&lt;/tt&gt; branch, and nothing more!&lt;/p&gt;
&lt;blockquote&gt;
It is important to note that travis do offer &lt;a class="reference external" href="https://docs.travis-ci.com/user/private-dependencies/#User-Key"&gt;this feature&lt;/a&gt; for
paid plans, and that &lt;a class="reference external" href="https://gist.github.com/lukewpatterson/4242707"&gt;hacky alternatives&lt;/a&gt; exist.&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="wrap-up"&gt;
&lt;h2&gt;Wrap up&lt;/h2&gt;
&lt;p&gt;Personally, for everything &amp;quot;deployable&amp;quot; I stay with codeship at the moment,
as this single feature is more important to me than travis's advantages.
To compensate, I document the different scripts (environment setup, test
running, and deployment) in the project &lt;tt class="docutils literal"&gt;README&lt;/tt&gt;. In addition, although the
test matrix is a crucial feature when you work on libraries and tools,
web sites and application are usually different. You control the environment
you deploy to, and can set the CI environment to be the same / very similar.&lt;/p&gt;
&lt;p&gt;Having said that, for everything else, just go with travis. You won't
regret it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="tl-dr"&gt;
&lt;h2&gt;TL;DR&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Prefer &lt;a class="reference external" href="https://travis-ci.org/"&gt;travis-ci&lt;/a&gt; when developing a library / command line
utility / non “deployable” software.&lt;/li&gt;
&lt;li&gt;Use &lt;a class="reference external" href="https://codeship.com/"&gt;codeship&lt;/a&gt; for continuous deployment of web sites and
applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="thoughts"></category><category term="web"></category><category term="tools"></category></entry><entry><title>Open your eyes</title><link href="/blog/open-your-eyes" rel="alternate"></link><published>2016-05-14T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2016-05-14:/blog/open-your-eyes</id><summary type="html">&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/SgISW_uyjjU" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;My band, Malinka, released a new video. It's the first release from our live session at Mooki's Raphsoda, so expect more to come... Meanwhile, you can come and here us live:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;This Monday&lt;/strong&gt; (16.5 …&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/SgISW_uyjjU" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;My band, Malinka, released a new video. It's the first release from our live session at Mooki's Raphsoda, so expect more to come... Meanwhile, you can come and here us live:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;This Monday&lt;/strong&gt; (16.5) in Hudna bar, Tel-Aviv.&lt;/li&gt;
&lt;li&gt;&lt;span class="strike"&gt;Next month (14.6) in Freddi Lemon bar, Jerusalem.&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="music"></category></entry><entry><title>Video demo of my Sign-language project</title><link href="/blog/video-demo-of-my-sign-language-project" rel="alternate"></link><published>2016-03-04T22:50:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2016-03-04:/blog/video-demo-of-my-sign-language-project</id><content type="html">&lt;p&gt;This project convert sign-language / gestures to speech. You can read
more about it on
&lt;a class="reference external" href="https://github.com/Nagasaki45/Sign-language"&gt;github&lt;/a&gt; or in &lt;a class="reference external" href="/projects/sign-language"&gt;my
site&lt;/a&gt;. I just uploaded a
video demo of the project. Feel free to comment.&lt;/p&gt;
&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/x6i9gXS5VEQ" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;</content><category term="Blog"></category><category term="projects"></category><category term="demo"></category><category term="machine learning"></category></entry><entry><title>docker-compose in production</title><link href="/blog/docker-compose-in-production" rel="alternate"></link><published>2016-02-29T00:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2016-02-29:/blog/docker-compose-in-production</id><summary type="html">&lt;p&gt;Deployment sucks! I'm not a dev ops / sys admin type of person, and
every time I'm into deploying a web project I start to rethink the whole
process and get confused. Recently, I decided to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Deployment sucks! I'm not a dev ops / sys admin type of person, and
every time I'm into deploying a web project I start to rethink the whole
process and get confused. Recently, I decided to restart the work on one
of my older django projects,
&lt;a class="reference external" href="https://github.com/Nagasaki45/Xteams"&gt;Xteams&lt;/a&gt;, and one of the first
tasks was to migrate it from &lt;a class="reference external" href="https://www.heroku.com/"&gt;heroku&lt;/a&gt; to my
VPS - a &lt;a class="reference external" href="http://digitalocean.com/"&gt;digital ocean&lt;/a&gt; droplet. Don't get
me wrong, heroku is great, but I'm already paying 5 bucks per month to
digital ocean, where I host all of my web projects, and the single web
dyno that heroku gives for free is a real limitation.
Before starting to migrate the project, I decided about the following
deployment requirements:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;I want a consistent production environment, with the fewest possible
system wide dependencies, mainly due to...&lt;/li&gt;
&lt;li&gt;I have several projects already deployed to this VPS, so I need a
production environment which will play nice with them both in term of
dependencies and in hostname routing (resolving foo.com and bar.com
to their respective ports / apps).&lt;/li&gt;
&lt;li&gt;Staging and production environments should be as similar as possible,
and I want to be able to run the staging environment on my local
machine.&lt;/li&gt;
&lt;li&gt;Moreover, if I can utilize parts of the production configurations for
development - like DB / job queue and workers - it's even better.&lt;/li&gt;
&lt;li&gt;Keep deployment scripts to the bare minimum.&lt;/li&gt;
&lt;li&gt;Not over-engineer the issue.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="dokku"&gt;
&lt;h2&gt;&lt;a class="reference external" href="https://dokku.com/"&gt;Dokku&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I liked heroku. Deploying is really easy, and if I can accomplish a
task using git alone I will probably do it that way :-) So I checked
dokku. It clearly solves the first requirement easily: apart from dokku
itself there is no system wide configuration and dependencies to worry
about. It also solves issues 5 and 6 really nicely: the deployment is
done by pushing to remote repository and production specific
configurations (or secrets) can be added with environment variables,
which I like. On the other hand, I'm not sure if dokku would play nicely
with my other projects, there is no way to run an environment similar to
production locally, and I can't reuse components for development.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="deployment-scripts-like-ansible-fabric"&gt;
&lt;h2&gt;Deployment scripts (like &lt;a class="reference external" href="https://www.ansible.com/"&gt;ansible&lt;/a&gt; / &lt;a class="reference external" href="http://www.fabfile.org/"&gt;fabric&lt;/a&gt;)&lt;/h2&gt;
&lt;p&gt;Almost a year ago I read Harry Percival's great book &lt;a class="reference external" href="http://chimera.labs.oreilly.com/books/1234000000754/"&gt;&amp;quot;TDD with
Python&amp;quot;&lt;/a&gt;. He
teaches how to automate deployment with ansible. I managed to deploy the
sample app for the book and later I used the same technique to deploy
one more django app of mine. However, I really don't like this approach.
It seems very fragile, touching too many configurations too often,
making me afraid about my other projects on the server. It's a lot of
work too, and work that I can't reuse for development. Overall, I feel
that it only answer requirement 3 and 6. The rest are not even close to
be answered.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="finally-docker-and-docker-compose-to-the-rescue"&gt;
&lt;h2&gt;Finally: docker and docker-compose to the rescue&lt;/h2&gt;
&lt;img alt="Docker compose in production" src="/images/blog/docker_compose_prod.avif" /&gt;
&lt;p&gt;You weren't expected this, didn't you?!?
Let's follow the diagram and I will try to convince you why using
docker-compose in production (and also partly in development) is a good
idea. With docker, you can create an image of an application, together
with all of its dependencies, and run it in an isolated environment,
which is called a docker container. docker-compose lets you take a set
of such images, define the links between containers (in means of network
and volume access) and orchestrate all of the containers together, from
building to running.
In the current example I had a DB container with an official postgres
image. Every time I need to configure postgres on my local machine I
find myself reading throughout half of stackoverflow and the official
docs for information. This time it was really easy: I grabbed the
official postgres image from docker hub and that's it - no more
configuration needed.
Second, there is the web container that runs the django app itself.
This is the main container in my project. I wrote a Dockerfile to
describe how the image should be built. It contains only a few lines:
starting from the official python 3.5 image, pip installing
dependencies, and collect static files. Secrets are written in a special
file which django-compose pass to the container as environment
variables. This file is not source controlled: I created one manually on
my local machine and another one, slightly different, on my server.
Here's the Dockerfile for this image:&lt;/p&gt;
&lt;script src="https://gist.github.com/Nagasaki45/58bd4d758c1408d2c4b7.js"&gt;&lt;/script&gt;&lt;p&gt;Above the web container there is the Nginx container, which have
access to a shared volume from the web container that contains all of
the static files, so static files are served by Nginx directly. Here is
the Nginx container configuration file:&lt;/p&gt;
&lt;script src="https://gist.github.com/Nagasaki45/1830411bc5e510c096ae.js"&gt;&lt;/script&gt;&lt;p&gt;Outside of the docker orchestration there is one more Nginx instance,
its job is to route each incoming request to the correct app on the
server. Every app is listening on a different port and Nginx only route
traffic based on the hostname in the http header. Here's the
configuration file:&lt;/p&gt;
&lt;script src="https://gist.github.com/Nagasaki45/4575b34641bc4e804c09.js"&gt;&lt;/script&gt;&lt;p&gt;Here's how my docker-compose configuration file looks like:&lt;/p&gt;
&lt;script src="https://gist.github.com/Nagasaki45/15f22aeb60e49d1c30d3.js"&gt;&lt;/script&gt;&lt;p&gt;Building and running these containers is really simple:&lt;/p&gt;
&lt;script src="https://gist.github.com/Nagasaki45/9aed10b837612f385bc7.js"&gt;&lt;/script&gt;&lt;p&gt;So now, let's try to tackle the requirements list again:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;The only system wide dependencies are docker and docker-compose.
Apart from that there is the system wide Nginx server, which is
already there for the other apps.&lt;/li&gt;
&lt;li&gt;Running the new project side by side with the other projects is just
a matter of adding one more server configuration file to the system
wide Nginx (more info is available in &lt;a class="reference external" href="https://github.com/Nagasaki45/Xteams#more-info"&gt;the project
README&lt;/a&gt;). This is
no different from any other app on the server, whether it's a django
app or a static website.&lt;/li&gt;
&lt;li&gt;There is no difference at all between staging and production.
Spinning a staging environment locally is just a matter of building
and running the docker-compose environment.&lt;/li&gt;
&lt;li&gt;I'm not using a system wide postgres instance in development.
Instead, I use the same postgress docker image I run in production.
Moreover, if I will need more building blocks, as a job queue and
workers, I will be able to add their respective images to both
development and production docker-compose configuration files.&lt;/li&gt;
&lt;li&gt;I do have a script for deployment, but it doesn't do much except
pulling the latest source from github, building and running. That's
all.&lt;/li&gt;
&lt;li&gt;One might argue that I did over-engineered the issue. Compared to
using dokku this solution is definitely more complex. However, I'm
not sure if maintaining this deployment mechanism is harder than
maintaining ansible deployment scripts, especially when there are
several different apps on the same server.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="cons"&gt;
&lt;h2&gt;Cons&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Provisioning, although very simple, is done manually: I create a
folder on the server, clone the project, and add the django &amp;quot;secrets&amp;quot;
file. It can be automated too, of course, but I'm not sure I see a
reason for that now.&lt;/li&gt;
&lt;li&gt;I wished I could run functional tests from a special
&lt;a class="reference external" href="http://www.seleniumhq.org/"&gt;selenium&lt;/a&gt; container against the
staging environment. This is not trivial as it requires a
bidirectional network access between the selenium driver and the web
app. I gave up the idea, because of its complexity, and I'm running
selenium tests only against the development environment, outside of
any docker container.&lt;/li&gt;
&lt;li&gt;Sharing a volume between the web container and the Nginx container is
a neat trick. However, I most force-remove the old web container
after any build and before running the new container to &amp;quot;refresh&amp;quot; the
volume with the latest collected static files. It's a hack I don't
like, but I live with it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="summary"&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;I really like docker-compose. At first, it looks like a tool with a
steep learning curve. But don't be too intimidated. Give it a try and
you might find an elegant solution for deployments, which will hopefully
scale well with your requirements.
I'm sure that there are lots of approaches I'm not covering here, and
all of the above only reflects my limited experience in the field.
Therefor, feel free to criticize and share your experience about the
subject!&lt;/p&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="thoughts"></category><category term="django"></category><category term="docker"></category><category term="web"></category><category term="tools"></category></entry><entry><title>My new portfolio site</title><link href="/blog/my-new-portfolio-site" rel="alternate"></link><published>2016-02-04T17:06:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2016-02-04:/blog/my-new-portfolio-site</id><summary type="html">&lt;p&gt;I have a new site!&lt;/p&gt;
&lt;img alt="My portfolio header" src="/images/blog/portfolio_header.avif" style="width: 100%;" /&gt;
&lt;p&gt;The site was created to present the different projects I'm working on
as a portfolio. I will keep posting ideas and explorations here. But I
feel that a site with …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have a new site!&lt;/p&gt;
&lt;img alt="My portfolio header" src="/images/blog/portfolio_header.avif" style="width: 100%;" /&gt;
&lt;p&gt;The site was created to present the different projects I'm working on
as a portfolio. I will keep posting ideas and explorations here. But I
feel that a site with a proper home page and unique design (compared to
this blog, at least) will present the projects and my skillset in a
better light.
And for the technical part. This is a static, pelican based site. The
theme was adapted from the &lt;a class="reference external" href="http://themes.gohugo.io/creative/"&gt;Hugo Creative
theme&lt;/a&gt;, with several
modifications. Feel free to
&lt;a class="reference external" href="https://github.com/Nagasaki45/leverstone.me"&gt;fork&lt;/a&gt; and change for
your own needs.
As usual, comments are more than welcome!&lt;/p&gt;
</content><category term="Blog"></category><category term="other"></category><category term="web"></category></entry><entry><title>Poor man's trick to add and remove conda from $PATH</title><link href="/blog/poor-mans-trick-to-add-and-remove-conda-from-path" rel="alternate"></link><published>2015-10-24T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2015-10-24:/blog/poor-mans-trick-to-add-and-remove-conda-from-path</id><summary type="html">&lt;p&gt;&lt;a class="reference external" href="http://conda.pydata.org/docs/"&gt;Conda&lt;/a&gt; is great for managing
dependencies as matplotlib and scipy: try to install these with pip, in
a virtualenv, and you will be convinced that conda is better in that
regard.
But!
Somehow, the folks …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a class="reference external" href="http://conda.pydata.org/docs/"&gt;Conda&lt;/a&gt; is great for managing
dependencies as matplotlib and scipy: try to install these with pip, in
a virtualenv, and you will be convinced that conda is better in that
regard.
But!
Somehow, the folks at continuum analytics decided that using conda
should override the default python environment (the system-wide python
installation). There are some
&lt;a class="reference external" href="https://groups.google.com/a/continuum.io/forum/#!topic/anaconda/opMLiGnjymE"&gt;recommendations&lt;/a&gt;,
but AFAIK there is no official solution for the problem.
Here is my solution to keep the system-wide python installation as my
default environment and start to use conda only when I want to:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$&lt;span class="w"&gt; &lt;/span&gt;cat&lt;span class="w"&gt; &lt;/span&gt;~/bin/unconda
&lt;span class="nb"&gt;export&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;:&lt;/span&gt;&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;:&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;|&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;sed&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;s:\:&lt;/span&gt;&lt;span class="nv"&gt;$HOME&lt;/span&gt;&lt;span class="s2"&gt;/miniconda3/bin\::\::g&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;s/^://&amp;quot;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;-e&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;s/:&lt;/span&gt;$&lt;span class="s2"&gt;//&amp;quot;&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Got the trick from
&lt;a class="reference external" href="https://ntk.me/2013/05/04/path-environment-variable/"&gt;here&lt;/a&gt;. Thanks
Natsuki!&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$&lt;span class="w"&gt; &lt;/span&gt;cat&lt;span class="w"&gt; &lt;/span&gt;~/bin/reconda
&lt;span class="nb"&gt;export&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="nv"&gt;$HOME&lt;/span&gt;&lt;span class="s2"&gt;/miniconda3/bin:&lt;/span&gt;&lt;span class="nv"&gt;$PATH&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now just add &lt;tt class="docutils literal"&gt;$HOME/bin&lt;/tt&gt; to your path if it's not already there and you
are ready to go.
Don't forget to remove the line in your &lt;tt class="docutils literal"&gt;.bashrc&lt;/tt&gt; that add miniconda to
the path in the first place.&lt;/p&gt;
&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/UdQgJdnrEDw" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;</content><category term="Blog"></category><category term="thoughts"></category><category term="python"></category><category term="tools"></category></entry><entry><title>Back to music with Malinka</title><link href="/blog/back-to-music-with-malinka" rel="alternate"></link><published>2015-08-27T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2015-08-27:/blog/back-to-music-with-malinka</id><summary type="html">&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/fzQoYdzAFz0" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;It's been a while, but recently I started playing bass guitar in a
band again. The band,
&amp;quot;&lt;a class="reference external" href="https://www.youtube.com/channel/UCXGJ2u2sw8sB6Jwa-63ATNw"&gt;Malinka&lt;/a&gt;&amp;quot;,
is lead by &lt;a class="reference external" href="https://www.stavocaldesign.com/"&gt;Stav German&lt;/a&gt;, and we have our
&lt;a class="reference external" href="https://www.facebook.com/events/1019498851418082/"&gt;first live show next
week&lt;/a&gt; in Tel-Aviv.
Feel …&lt;/p&gt;</summary><content type="html">&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/fzQoYdzAFz0" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;It's been a while, but recently I started playing bass guitar in a
band again. The band,
&amp;quot;&lt;a class="reference external" href="https://www.youtube.com/channel/UCXGJ2u2sw8sB6Jwa-63ATNw"&gt;Malinka&lt;/a&gt;&amp;quot;,
is lead by &lt;a class="reference external" href="https://www.stavocaldesign.com/"&gt;Stav German&lt;/a&gt;, and we have our
&lt;a class="reference external" href="https://www.facebook.com/events/1019498851418082/"&gt;first live show next
week&lt;/a&gt; in Tel-Aviv.
Feel free to hear, comment, and come to the show, it's free.&lt;/p&gt;
</content><category term="Blog"></category><category term="other"></category><category term="music"></category></entry><entry><title>My Jupyter (tmpnb) server and Thebe</title><link href="/blog/my-jupyter-tmpnb-server-and-thebe" rel="alternate"></link><published>2015-08-04T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2015-08-04:/blog/my-jupyter-tmpnb-server-and-thebe</id><summary type="html">&lt;p&gt;&lt;strong&gt;Notice: code execution in the browser is currently broken&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;IPython.html.widgets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;interact&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;plot_sine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;frequency&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;plt …&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Notice: code execution in the browser is currently broken&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;matplotlib&lt;/span&gt; &lt;span class="n"&gt;inline&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;IPython.html.widgets&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;interact&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;plot_sine&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;frequency&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylim&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;frequency&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;interact&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plot_sine&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;frequency&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;10.0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;amplitude&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;));&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Isn't that amazing?!?
I've recently installed an
&lt;a class="reference external" href="https://github.com/jupyter/tmpnb"&gt;tmpnb&lt;/a&gt; sever on my digitalocean
server, you can access it at &lt;tt class="docutils literal"&gt;nagasaki45.com:8000&lt;/tt&gt;.
So, what's the big deal?
This configuration allow anyone to use python (or one of the other
supported / installed kernels) on the web, using my server. You don't
have to ask for permission; you can just go to the provided address and
start to code without any local installation.
And it goes way beyond:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;You can open new terminal, 'git clone' your project, and demonstrate
it to someone else. And you can do it on mobile devices too. Again,
no installation required, everything is running on the server.&lt;/li&gt;
&lt;li&gt;You can use &lt;a class="reference external" href="https://github.com/oreillymedia/thebe"&gt;thebe&lt;/a&gt; to add
code snippets as the one above to any static html page (your blog, as
example). Even interactive widgets will run the computation back and
fourth from the server to the web frontend for presentation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So go ahead, write some code, let me execute it for you ;-)&lt;/p&gt;
&lt;div class="section" id="edit-6-5-16"&gt;
&lt;h2&gt;Edit 6.5.16:&lt;/h2&gt;
&lt;p&gt;Oreilly shut down their tmpnb server too :-(
So this blog post won't execute python code anytime soon.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="edit-20-9-15"&gt;
&lt;h2&gt;Edit 20.9.15:&lt;/h2&gt;
&lt;p&gt;I'm stopping the service on my server due to some number crunching tasks
I'm running on it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="edit-1-9-15"&gt;
&lt;h2&gt;Edit 1.9.15:&lt;/h2&gt;
&lt;p&gt;My digitalocean VM has &amp;quot;only&amp;quot; 512MB of RAM. I decided to span tmpnb
with 4 docker containers, 50MB RAM each, to keep the server load on
minimum. Apparently, it possessed some issues as 50MB are probably not
enough.
Right now the example above uses the same tmpnb server has the one in
thebe example
(&lt;a class="reference external" href="https://oreillymedia.github.io/thebe/examples/matplotlib.html"&gt;here&lt;/a&gt;),
namely &lt;a class="reference external" href="https://oreillyorchard.com:8000/"&gt;https://oreillyorchard.com:8000/&lt;/a&gt;. It works much better now as
there are no kernal failures when running the examples.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="thoughts"></category><category term="python"></category><category term="web"></category><category term="docker"></category></entry><entry><title>Writing a programming book? Don't compose an utility library!</title><link href="/blog/writing-a-programming-book-dont-compose-an-utility-library" rel="alternate"></link><published>2015-05-23T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2015-05-23:/blog/writing-a-programming-book-dont-compose-an-utility-library</id><summary type="html">&lt;p&gt;I came across two books recently, in which the authors decided to
write an utility library. The first book was &lt;a class="reference external" href="http://www.amazon.com/Python-Practice-Concurrency-Libraries-Developers/dp/0321905636/"&gt;Python in Practice, by
Mark
Summerfield&lt;/a&gt;
(my opinion about the book can be found
&lt;a class="reference external" href="/blog/python-readings"&gt;here …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;I came across two books recently, in which the authors decided to
write an utility library. The first book was &lt;a class="reference external" href="http://www.amazon.com/Python-Practice-Concurrency-Libraries-Developers/dp/0321905636/"&gt;Python in Practice, by
Mark
Summerfield&lt;/a&gt;
(my opinion about the book can be found
&lt;a class="reference external" href="/blog/python-readings"&gt;here&lt;/a&gt;),
and the second, which I'm still reading, is &lt;a class="reference external" href="http://www.amazon.com/Doing-Bayesian-Data-Analysis-Second/dp/0124058884"&gt;Doing Bayesian Data Analysis,
Second Edition, by John Kruschke&lt;/a&gt;.
A separate review will be added when I will finish reading it.
The books are different in their nature: One is about python
programming, while the other is about statistical methods, and uses the
R programming language for hands-on examples and exercises; the first
book is average quality overall (IMHO) and the second is absolutely
amazing! However, I believe that I may be able criticize the utility
libraries that came with the books in the same manner: Don't do this!
And why?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Installation process breaks conventions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When I need an external tool in a python project I know I have
&lt;a class="reference external" href="https://pypi.python.org/pypi"&gt;pypi&lt;/a&gt; to rely on for finding packages.
I have &lt;a class="reference external" href="https://pip.pypa.io/en/stable/"&gt;pip&lt;/a&gt; to easily install the
package and prefer to work with
&lt;a class="reference external" href="https://virtualenv.pypa.io/en/latest/"&gt;virtualenv&lt;/a&gt; whenever
possible. This set of tools help me in maintaining a sane codebase, and
reduce the effort of managing the dependencies by my own.
There is no chance that I will copy an external module into my project
and source control it unless I'll have to, so why to use this module in
an educational project in the first place?
I really don't know what is the convention in installing R external
packages, but I believe that Kruschke suggestion of sourcing his
supplied scripts is not the proper way to do this (enlighten me if I'm
wrong).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Package maintenance / code quality&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Before&amp;nbsp;I'm installing an external package I tend to search
about the package quality. First thing is checking how many stars the
package have on github and how many times it was downloaded from pypi.
And there is a reason behind it: I can rely on packages that are used
often to have better code quality; through gihub I can browse the
package issues / latest commits and make sure that it is still
maintained.
I'm sure that books authors invest a large amount of time in writing
their utility libraries. But code free of bugs doesn't exists, and I
prefer to know that the codebase is maintained before I use it (again,
without distinction between educational and &amp;quot;real&amp;quot; projects).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Not specific enough&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If your utility library is a mix of different solutions for different
problems, it might not worth keeping in our toolbox. The above is
probably more relevant to Python in practice than to Doing Bayesian Data
Analysis, but I think it's still worth mentioning.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;When I choose a tool to work with I want it's documentation
to be top notch! Take
&lt;a class="reference external" href="https://docs.djangoproject.com/en/1.8/"&gt;django&lt;/a&gt; for example. The
project's documentation is not less than perfect, including a great
tutorial for beginners. I really don't want to look for the book when
I'm interesting in put in use some less obvious function from an utility
library.&lt;/p&gt;
&lt;img alt="Doing Bayesian Data Analysis, Second Edition, by John Kruschke" src="https://lh6.googleusercontent.com/R563ddoYp_JArt338PZqp_qqISnv0k4kTGKtp8rrls6K-K8h3maMRccSFgaMOFkMft59Lhu3SzFq_1M64agOFQozaL7eQQTLnvgR6p7Uiy2M0oLW=w1280" style="width: 100%;" /&gt;
&lt;div class="section" id="what-i-m-expecting-from-authors-instead"&gt;
&lt;h2&gt;What I'm expecting from authors instead&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;If you think that your utility functions worth it pack it and publish
it as any other package.&lt;/li&gt;
&lt;li&gt;I really don't mind reading one or two additional pages of code&amp;nbsp;in
your book, if there's something interesting in it. Again, if the code
deserved to be mentioned in your book, it may be also deserved to be
talked about explicitly.&lt;/li&gt;
&lt;li&gt;If this functionality exists elsewhere you should reference it, and
advise the user to use it. I've never wrote code in R, but was ready
to learn how to work with its ecosystem. I expected Kruschke to teach
me that, instead of showing me how to source his supplied scripts.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="late-disclaimer"&gt;
&lt;h2&gt;Late disclaimer&lt;/h2&gt;
&lt;p&gt;Don't get me wrong, supplying code as part of your book is great! But
there are different ways to do it: David Beazley's Python Cookbook is
full of code snippets, fully commented and explained; In Test-Driven
Development with Python, Harry Percival guides the reader in developing
an webapp with reference code available at github.
Don't get me wrong 2: The above doesn't mean that the books are bad.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="edit"&gt;
&lt;h2&gt;Edit:&lt;/h2&gt;
&lt;p&gt;Don't miss Kruschke's comment below! He lights the above topics from
different angle and supplies great arguments for his decisions.
Maybe, as a programmer, I tend to rely on the language ecosystem mechamisms instead of being satisfied with the easier, and more beginners friendly solution Kruschke proposes.
I definitely agree with him that an easier-to-use software for data science, and bayesian data analysis in particular, is always welcomed.
I would like to seize the opportunity to thank Kruschke again for his great book! I really enjoy reading it and I'm sure that I will continue to use the insights gained from it in the future.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="thoughts"></category><category term="books"></category></entry><entry><title>Python readings</title><link href="/blog/python-readings" rel="alternate"></link><published>2014-11-17T00:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2014-11-17:/blog/python-readings</id><summary type="html">&lt;p&gt;I usually learn anything new by reading books. In fact, I got almost
all of my python knowledge (which is not a lot, I'm just an apprentice
programmer) by reading python books.
A year ago …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I usually learn anything new by reading books. In fact, I got almost
all of my python knowledge (which is not a lot, I'm just an apprentice
programmer) by reading python books.
A year ago I've started to learn web development from &lt;a class="reference external" href="http://www.10x.org.il/"&gt;Udi
Oron&lt;/a&gt; in
&lt;a class="reference external" href="https://hackita.hasadna.org.il/"&gt;Hackita&lt;/a&gt; (my impressions
&lt;a class="reference external" href="/blog/hackita"&gt;here&lt;/a&gt;), and
shortly after started to work with him as a python teaching assistant in
his courses. Few months ago I've got a permanent position in one of
those companies we've taught in and the stigma of someone that can
answer everybody's python questions still sticks to me in the company.
Between those questions are how to get started with python and where to
find information regarding specific topics.
Hence, here is my thoughts about the books that helped, and still
helping me learning python.&lt;/p&gt;
&lt;div class="section" id="disclaimers"&gt;
&lt;h2&gt;Disclaimers&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;I'm new to python and the world of programming.&lt;/li&gt;
&lt;li&gt;Books won't do the work for everybody.&lt;/li&gt;
&lt;li&gt;When I first started to learn python I never thought I will end up
making my leaving out of it, so I've learned python 3 (which is
preferable language IMHO). However, most of the industry still uses
python 2. All of the books below are for python 3. It doesn't mean that
they won't help you learn python 2 also, but you will have to find the
differences by yourself.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="beginners-books"&gt;
&lt;h2&gt;Beginners books&lt;/h2&gt;
&lt;div class="section" id="the-quick-python-book-second-edition-naomi-r-ceder"&gt;
&lt;h3&gt;&lt;a class="reference external" href="http://www.amazon.com/Quick-Python-Book-Second-Edition/dp/193518220X"&gt;The Quick Python Book, Second Edition (Naomi R. Ceder)&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img alt="image0" src="http://ecx.images-amazon.com/images/I/51afqHmFrML._SX258_BO1,204,203,200_.jpg" style="width: 180px;" /&gt;&lt;/p&gt;
&lt;p&gt;After trying different books for python (Think Python, Dive
into Python 3 and Head First Python) I've found this one to be the
preferable as a learning book for someone that already saw some code,
but is definitely not an experienced programmer.
Part 1 is a short introduction that may also be used as a quick
reference. Part 2 is very organized tutorial for the language. It
contains most of the essentials and will give you the feeling that you
can continue learning by your own (or with more specialized books /
tutorials). Part 3 is much less cohesive then part 2. It seems that the
chapter about regular expressions could get into part 2 but the rest of
the section is too much esoteric and there are some mistakes through all
of it (for example, it refers you to the appendix for more information
that is not there).
I didn't read part 4 completely. I've only read the information about
working with databases in chapter 24 and it is very well written.
Summary: For part 2 I will give 5 start without hesitations. But part
3, although less significant, doesn't deserve it. After all the book is
very recommended.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="more-advance-intermediate-books"&gt;
&lt;h2&gt;More advance / intermediate books&lt;/h2&gt;
&lt;div class="section" id="python-in-practice-mark-summerfield"&gt;
&lt;h3&gt;&lt;a class="reference external" href="http://www.amazon.com/Python-Practice-Concurrency-Libraries-Developers/dp/0321905636/ref=sr_1_1?s=books&amp;amp;ie=UTF8&amp;amp;qid=1416060956&amp;amp;sr=1-1&amp;amp;keywords=python+in+practice"&gt;Python in Practice (Mark Summerfield)&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img alt="image1" src="https://mark-summerfield.github.io/images/pipbookm.png" style="width: 180px;" /&gt;&lt;/p&gt;
&lt;p&gt;I bought this book primary for its chapters about design
patterns as well as the concurrency and the networking chapters (1 to 3,
4 and 6 accordingly). The book doesn't meant to be read from start to
finish, but as a reference and guide to each topic separately. I think
that from the above chapters I've already read most of the content, as
well as the chapter about GUI with tkinter. I have nothing to say though
about the two remaining chapters (extending python and 3d graphics).
The best chapter of this book is the one about high-level concurrency.
In this chapter Summerfield explain with details the difference between
CPU-bound and I/O-bound concurrency and have a strong suggestions
regarding the tools to use for concurrency with python 3. Namely, the
suggestion is to use the threading, multiprocessing and
concurrent.futures modules and never use locks or other lower level
synchronization primitives explicitly, use queues and futures instead.
The examples are good, although I found the code unnecessarily complex
sometimes.
On the other hand, I found the chapters about design patterns to be
much less fruitful. The author attitude is too object oriented for me
where things could be done much easier using a decorator or two instead.
The code examples too, are complex and non pythonic.
I'm sure that there are much better and approaches to high-level
networking then those described in this book. The author implement
&lt;a class="reference external" href="http://en.wikipedia.org/wiki/Remote_procedure_call"&gt;remote procedure
call&lt;/a&gt; server and
client. Simple examples can be done in a simpler manner then the
suggested code and advance use cases may prefer higher level 3rd party
libraries and frameworks that removes much of the boilerplate (e.g.
&lt;a class="reference external" href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; +
&lt;a class="reference external" href="http://www.django-rest-framework.org/"&gt;DRF&lt;/a&gt; for REST server +
&lt;a class="reference external" href="http://docs.python-requests.org/en/latest/"&gt;requests&lt;/a&gt; based client).
Summary:The high-level concurrency chapter is really great and deserve
5 stars, but the rest of the book is ranging between 2 and 3.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-python-cookbook-3rd-edition-david-beasley"&gt;
&lt;h3&gt;&lt;a class="reference external" href="http://www.amazon.com/Python-Cookbook-David-Beazley/dp/1449340377/ref=sr_1_1?s=books&amp;amp;ie=UTF8&amp;amp;qid=1416061017&amp;amp;sr=1-1&amp;amp;keywords=the+python+cookbook"&gt;The Python Cookbook, 3rd edition (David Beasley)&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img alt="image2" src="http://ecx.images-amazon.com/images/I/51zDEWm5kcL._SX258_BO1,204,203,200_.jpg" style="width: 180px;" /&gt;&lt;/p&gt;
&lt;p&gt;After disappointing from &amp;quot;Python in Practice&amp;quot; I've came across this
book as one with similar scope, namely, a design patterns book,
organized into chapters by topic that you can read in any order. In
addition, this one is also great reference book by the fact that most of
the suggested patterns are described in a short, self-contained manner.
This is a really great book! Beasley's attitude is so pythonic. AKA:
readable, simple,
&lt;a class="reference external" href="http://en.wikipedia.org/wiki/Don%27t_repeat_yourself"&gt;DRY&lt;/a&gt;, less OO
and more functional whenever possible, smart usage of the standard
library / 3rd party high level libraries.
Most of the chapters of the book are really fluent and easy to read.
I've found the meta-programming and the object oriented chapters a bit
more complex, but still great after the 2nd or the 3rd read as the ideas
demonstrated there are a bit too advanced for my background.
Summary: Assuming you already know python (don't read it if you don't)
I think that this book is a must have. 5 stars are barely enough.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="scientific-computing-with-python"&gt;
&lt;h2&gt;Scientific computing with python&lt;/h2&gt;
&lt;p&gt;As already noted, I've never thought that I will find myslef
programming python in a full time job. Essentially, I've decided to
learn python as a data analysis tool for my &lt;a class="reference external" href="/projects/an-audio-only-augmented-reality-system-for-social-interaction"&gt;MA
research&lt;/a&gt;. These
are the main sources I've used to get the necessary knowledge.&lt;/p&gt;
&lt;div class="section" id="python-for-data-analysis-wes-mckinney"&gt;
&lt;h3&gt;&lt;a class="reference external" href="http://www.amazon.com/Python-Data-Analysis-Wrangling-IPython/dp/1449319793"&gt;Python for Data Analysis (Wes McKinney)&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img alt="image3" src="https://d.gr-assets.com/books/1356132971l/14744694.jpg" style="width: 180px;" /&gt;&lt;/p&gt;
&lt;p&gt;It's not a bad book but if you are looking for a good book for
scientific computing with python you will probably be disappointed.
The book covers mostly the pandas library. It doesn't give much
information about numpy and matplotlib, and say completely nothing about
scipy, which are all more essential for scientific computing than pandas
as far as I understand that topic.
On the other hand, pandas is your tool to go if you need to work with
spreadsheet oriented data (the &lt;a class="reference external" href="http://pandas.pydata.org/index.html#library-highlights"&gt;library highlights
page&lt;/a&gt; summarize
its strengths pretty good).
This book was one of the first python books I've read, together with
the quick python book above. It explains pandas in a very introductory
way (pretty slow), which make recommending this book even harder: If you
are a beginner, this book is written in the right level, but on the
wrong content; If you are a more advanced programmer looking to learn a
bit of pandas you may find the tutorials
&lt;a class="reference external" href="http://pandas.pydata.org/pandas-docs/dev/tutorials.html"&gt;here&lt;/a&gt;
comprehensive enough.
Summary: Pandas is a great tool, use it! But I don't think that this
book is a good your way to learn data analysis with python, whether you
are a beginner or not.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="python-scientific-lecture-notes"&gt;
&lt;h3&gt;&lt;a class="reference external" href="https://lectures.scientific-python.org/"&gt;Python Scientific Lecture Notes&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I have to admit, I've read only the first section of the &amp;quot;lecture
notes&amp;quot;, but if you are looking for an introduction to scientific
computing with python this &amp;quot;book&amp;quot; is definitely worth reading. It covers
the basics of numpy, matplotlib and scipy very concisely, with lots of
short but working code examples.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="web-development-with-python"&gt;
&lt;h2&gt;Web development with python&lt;/h2&gt;
&lt;div class="section" id="two-scoops-of-django-best-practices-for-django-1-6-daniel-greenfeld-aka-pydanny-and-his-wife-audrey-roy"&gt;
&lt;h3&gt;&lt;a class="reference external" href="http://www.amazon.com/Two-Scoops-Django-Best-Practices/dp/098146730X"&gt;Two Scoops of Django: Best Practices for Django 1.6 (Daniel Greenfeld - AKA pydanny, and his wife Audrey Roy)&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img alt="image4" src="https://images-na.ssl-images-amazon.com/images/S/compressed.photo.goodreads.com/books/1391889816i/20754237.jpg" style="width: 180px;" /&gt;&lt;/p&gt;
&lt;p&gt;Can't say I've finish reading this book. It more like a
reference you open anytime you need for some extra help on each topic,
with emphasis on best practices.
Be aware that this book is not for beginners! But if you want to
progress with python + django you're going to appreciate the suggestions
found there. For django starters, go through the really good
&lt;a class="reference external" href="https://docs.djangoproject.com/en/dev/intro/tutorial01/"&gt;tutorial&lt;/a&gt;
and write another django app before reading any of the suggestions in
this book. It won't help you if you don't.
There are two editions for this book, for django versions 1.5 and 1.6.
According to the authors &lt;a class="reference external" href="http://twoscoopspress.com/pages/two-scoops-of-django-1-6-faq#what-if-1.7"&gt;there will be no more version of this
book&lt;/a&gt;,
so don't attempt to wait to one. Take the latest as it has much more
content.
Behind the general recommendation and the versions stuff I will add
that I don't like the &amp;quot;theme&amp;quot; of the book. The code examples themselves
are great but there are lots of illustrations that doesn't really
helping in explaining the concepts nor in remembering them.
Summary: If you take django development seriously just get yourself a
copy, you won't regret it!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="tdd-with-python-harry-j-w-percival"&gt;
&lt;h3&gt;&lt;a class="reference external" href="http://www.amazon.com/Test-Driven-Development-Python-Harry-Percival/dp/1449364829"&gt;TDD with python (Harry J. W. Percival)&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img alt="image5" src="http://orm-other.s3.amazonaws.com/tddwithpython/final_cover.jpg" style="width: 180px;" /&gt;&lt;/p&gt;
&lt;p&gt;I've started to read this book only recently, so I'm still in the
middle of it (somewhere around chapter 17). So my very warm
recommendations are for those I've read.
Percival does a great job in explaining and demonstrating the TDD
discipline, introducing web development with django on the way. Although
I am already familiar with django I found the introductory attitude of
the author more then appropriate, and it let me concentrate more on the
TDD side rather on understanding the framework. On the other hand, there
are lots of developers that prefer a more strait forward attitude, with
less text and more working code snippets, so bear in mind that this is
not the case with this one. Here, lots of code examples are written
iteratively throughout the test cycles and upon several pages. I like
it!
Behind introducing TDD, its the first time I manage to deploy an app
to a real server (I've deployed some apps to
&lt;a class="reference external" href="https://www.heroku.com/"&gt;heroku&lt;/a&gt; before, but it is different). I
will surely recommend those chapters as stand alone tutorial for
deployment (chapters 8 &amp;amp; 9 + appendix C).
The only downside I can think of is if you are not interested in web
development at all. It will be too much work to translate the concepts
in this book into completely different subject.
Summary: Great introduction to the discipline of TDD for web
development. Very recommended. And you can even read it online for free
&lt;a class="reference external" href="http://chimera.labs.oreilly.com/books/1234000000754/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="ending-words"&gt;
&lt;h2&gt;Ending words&lt;/h2&gt;
&lt;p&gt;I would really like to hear your thoughts about the recommendations,
whether you agree with me and even more if not :-).
You are also welcome to contact me on any question about these books /
other python resources and I will do my best to answer.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="thoughts"></category><category term="books"></category><category term="python"></category></entry><entry><title>Participants movement tracking animations from my MA experiment #2</title><link href="/blog/participants-movement-tracking-animations-from-my-ma-experiment-2" rel="alternate"></link><published>2014-10-27T19:22:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2014-10-27:/blog/participants-movement-tracking-animations-from-my-ma-experiment-2</id><summary type="html">&lt;p&gt;The following animated renditions are a byproduct of the video
tracking an analysis of my MA thesis second experiment.&lt;/p&gt;
&lt;img alt="Experiment design" src="/images/blog/experiment_design.webp" style="width: 100%;" /&gt;
&lt;p&gt;The figure above shows a schematic diagram of the experiment design.
The videos are of session …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The following animated renditions are a byproduct of the video
tracking an analysis of my MA thesis second experiment.&lt;/p&gt;
&lt;img alt="Experiment design" src="/images/blog/experiment_design.webp" style="width: 100%;" /&gt;
&lt;p&gt;The figure above shows a schematic diagram of the experiment design.
The videos are of session 1 to 3 of each of the groups (the last session
wasn't analyzed). They have been for great help in gaining insights
about the social interactions between the participants themselves and
between the participants and the system components.&lt;/p&gt;
&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/eMvRYz-3hrk" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/ViCy3Q0gQlQ" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/y2_1mssBn30" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/Ck_CcrJ0CsE" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/0u8Mcv3FMmE" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/TkRZFkfdY8c" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;The analysis repository can be found &lt;a class="reference external" href="https://github.com/Nagasaki45/MA-experiment-analysis"&gt;at
github&lt;/a&gt;.
Additional information about the research can be found
&lt;a class="reference external" href="/projects/an-audio-only-augmented-reality-system-for-social-interaction"&gt;here&lt;/a&gt;.&lt;/p&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="MA thesis"></category></entry><entry><title>Create teams easily with Xteams!</title><link href="/blog/create-teams-easily-with-xteams" rel="alternate"></link><published>2014-09-19T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2014-09-19:/blog/create-teams-easily-with-xteams</id><summary type="html">&lt;img alt="Playing volleyball" src="/images/blog/xteams.avif" style="width: 100%;" /&gt;
&lt;p&gt;I've been playing volleyball recently with a group of
amateur players. In the last two months the size of our group has
increased so much that it became very hard to create teams. And if …&lt;/p&gt;</summary><content type="html">&lt;img alt="Playing volleyball" src="/images/blog/xteams.avif" style="width: 100%;" /&gt;
&lt;p&gt;I've been playing volleyball recently with a group of
amateur players. In the last two months the size of our group has
increased so much that it became very hard to create teams. And if you
think that size is the only issue I can assure you that there are many
more:
- How can one create teams when Dana doesn't want to play with Haim,
who must play with Jacob but not with Yossi... You've got the idea.
- No one will ever want to help in creating teams as he may end up
insulting a not-so-good player by choosing him last.
- Maybe you have too many players around for one game, but just enough
for a tournament of 4 teams.
In order to solve these inconveniences I've created
&lt;a class="reference external" href="https://xteams.leverstone.me/"&gt;Xteams!&lt;/a&gt; a web-app with one goal in
mind:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Create teams automatically based on discrete scores of the players&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Using Xteams, group managers can give scores to players in the
management panel. Players of the group can't access this panel but can
see the list of players, mark which of them arrived to the game and
create teams easily.
At the time of writing, the algorithm behind the teams' allocation was
pretty simple. It takes all of the available players, and the number of
teams to create, and tries to find teams with equal or close to equal
strength (sum of the players scores) by generating several random
allocations and choosing the best of them.&lt;/p&gt;
&lt;div class="section" id="for-devs"&gt;
&lt;h2&gt;For devs&lt;/h2&gt;
&lt;p&gt;The app is still under development (aren't they all?), and many more
modifications, improvements and features are considered. Any help in the
development process is more than welcome (&lt;a class="reference external" href="https://github.com/Nagasaki45/Xteams"&gt;github
repo&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="thanks"&gt;
&lt;h2&gt;Thanks&lt;/h2&gt;
&lt;p&gt;To the players of Nahlaot Veshut volleyball team, who consistently help
with new ideas for features and additional improvements.&lt;/p&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="django"></category><category term="python"></category><category term="web"></category></entry><entry><title>My research proposal</title><link href="/blog/my-research-proposal" rel="alternate"></link><published>2014-04-09T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2014-04-09:/blog/my-research-proposal</id><summary type="html">&lt;img alt="Baloon bundles on the dance floor" src="/images/portfolio/ma_thesis.avif" style="width: 100%;" /&gt;
&lt;p&gt;I've recently submitted my &lt;a class="reference external" href="https://db.tt/4h5u179a"&gt;MA research proposal&lt;/a&gt;, titled:
&amp;quot;Audio-Only Augmented Reality System for Social Interaction&amp;quot;.
Usually, research proposals aims to present the subject and describe
the intents of the current research. This one is a …&lt;/p&gt;</summary><content type="html">&lt;img alt="Baloon bundles on the dance floor" src="/images/portfolio/ma_thesis.avif" style="width: 100%;" /&gt;
&lt;p&gt;I've recently submitted my &lt;a class="reference external" href="https://db.tt/4h5u179a"&gt;MA research proposal&lt;/a&gt;, titled:
&amp;quot;Audio-Only Augmented Reality System for Social Interaction&amp;quot;.
Usually, research proposals aims to present the subject and describe
the intents of the current research. This one is a bit more
comprehensive, presenting a fully operated system I've developed,
preliminary results of the system evaluation, and the exact design for a
future experiment.
Feedback is always welcome. LaTeX source can be found&amp;nbsp;&amp;#64;
&lt;a class="reference external" href="https://github.com/Nagasaki45/MA"&gt;github&lt;/a&gt;.&lt;/p&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="MA thesis"></category></entry><entry><title>Some experiments with SimpleCV - object detection by color</title><link href="/blog/some-experiments-with-simplecv-object-detection-by-color" rel="alternate"></link><published>2014-04-06T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2014-04-06:/blog/some-experiments-with-simplecv-object-detection-by-color</id><summary type="html">&lt;p&gt;Computer vision is way far from my daily interest. But last weekend I
participated in a semi-hackathon, developing code that aims to detect
and track cards by their color.&lt;/p&gt;
&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/wDAFhOv0tKU" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;Credits deserve to this
&lt;a class="reference external" href="https://www.youtube.com/watch?v=jihxqg3kr-g"&gt;guy&lt;/a&gt;. I've …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Computer vision is way far from my daily interest. But last weekend I
participated in a semi-hackathon, developing code that aims to detect
and track cards by their color.&lt;/p&gt;
&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/wDAFhOv0tKU" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;Credits deserve to this
&lt;a class="reference external" href="https://www.youtube.com/watch?v=jihxqg3kr-g"&gt;guy&lt;/a&gt;. I've used his
code as a reference and a starting point.&lt;/p&gt;
&lt;p&gt;It is my first experience with&amp;nbsp;SimpleCV. After all the code works pretty
well, I think, despite the awful documentation of SimpleCV and some hard
time working with the library.&lt;/p&gt;
&lt;p&gt;As always, the code is written in python and is available
at &lt;a class="reference external" href="https://github.com/Nagasaki45/cards-tracker"&gt;github&lt;/a&gt;. Any
thoughts about the mini-project, the code and computer vision
alternative libraries are always welcome.&lt;/p&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="python"></category><category term="demo"></category></entry><entry><title>Web Audio API - some thoughts and experiments</title><link href="/blog/web-audio-api-some-thoughts-and-experiments" rel="alternate"></link><published>2014-02-14T00:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2014-02-14:/blog/web-audio-api-some-thoughts-and-experiments</id><summary type="html">&lt;p&gt;For me, being able to use advance audio programming on the web looks
like a dream just a couple of weeks ago, and I'm not the only one for
sure.
Doing audio programming, I've mainly …&lt;/p&gt;</summary><content type="html">&lt;p&gt;For me, being able to use advance audio programming on the web looks
like a dream just a couple of weeks ago, and I'm not the only one for
sure.
Doing audio programming, I've mainly experienced with Max/MSP and Pd
but my interest in shared music creation / consumption and interactive
systems have long seems to demand the extension of this skill set; as
Udi Oron rightly argued in
&amp;quot;&lt;a class="reference external" href="/blog/hackita"&gt;Hackita&lt;/a&gt;&amp;quot;
two months ago: you have no chance to convince someone to download your
desktop app (Max or Pd patches for example), give them a web app
instead!
I'm not sure if I've heard of the &lt;a class="reference external" href="http://www.w3.org/TR/webaudio/"&gt;Web Audio
API&lt;/a&gt;&amp;nbsp;before last week, but even if I
did I probably wouldn't had a clue of how to use it back then (before
learning web development and JavaScript&amp;nbsp;at Hackita). Today I can say
that it looks like a great solution for audio programming, and a good
way to look for if you interesting in designing systems for public wide
usage because of the next reasons:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;As claimed before, no one downloads and install desktop application
anymore unless it came from known source and the one that download it
knows for sure that he wants to use it (as opposed to just trying
things out).&lt;/li&gt;
&lt;li&gt;It's probably the easiest way to go if you want shared behavior and
interaction between users of the system.&lt;/li&gt;
&lt;li&gt;Web standards are here to stay. You can be sure that organizations
like Google, Mozilla, and Microsoft will compete to provide the best
implementation possible.&lt;/li&gt;
&lt;li&gt;The API itself looks very promising. I hope that I will be able to
summarize pros and cons soon.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a class="reference external image-reference" href="https://web-audio.leverstone.me/"&gt;
&lt;img alt="Web-audio experiment screenshot" src="/images/blog/web_audio_screenshot.webp" /&gt;
&lt;/a&gt;
&lt;/div&gt;&lt;p&gt;That's being said, &lt;a class="reference external" href="https://web-audio.leverstone.me/"&gt;here&lt;/a&gt; are my
experiment with the API. If you are interesting in more information and
tutorials be sure to take a look at the &amp;quot;Useful links&amp;quot; menu (top
navigation bar). And as always, source code can be found at
&lt;a class="reference external" href="https://github.com/Nagasaki45/Web-Audio"&gt;github&lt;/a&gt;.&lt;/p&gt;
</content><category term="Blog"></category><category term="thoughts"></category><category term="web"></category><category term="music programming"></category></entry><entry><title>"Hackita"</title><link href="/blog/hackita" rel="alternate"></link><published>2013-12-07T00:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2013-12-07:/blog/hackita</id><summary type="html">&lt;p&gt;In the last few weeks I was participating in the first session of
&amp;quot;&lt;a class="reference external" href="https://hackita.hasadna.org.il/"&gt;Hackita&lt;/a&gt;&amp;quot;, which means &amp;quot;The
classroom&amp;quot; in Hebrew. This project aims to bring people from different
backgrounds to learn and develop open source …&lt;/p&gt;</summary><content type="html">&lt;p&gt;In the last few weeks I was participating in the first session of
&amp;quot;&lt;a class="reference external" href="https://hackita.hasadna.org.il/"&gt;Hackita&lt;/a&gt;&amp;quot;, which means &amp;quot;The
classroom&amp;quot; in Hebrew. This project aims to bring people from different
backgrounds to learn and develop open source web applications together.
Furthermore, the project is part of &lt;a class="reference external" href="http://www.hasadna.org.il/en/"&gt;The Public Knowledge
Workshop&lt;/a&gt;,&amp;nbsp;and as such one of its main
goals is to guide its participants to complete a project that expose
public knowledge to the public by the end of the 2 month session,
somewhere around late January.
Until now we've learned few technologies that will help us accomplish
this goal and from the next week we will start to work on the final
project.
Meanwhile, here are two of my &amp;quot;homework&amp;quot; exercises:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://simplecrypt.appspot.com/"&gt;SimpleCrypt&lt;/a&gt; - Online
cryptographic tool, based on
&lt;a class="reference external" href="http://en.wikipedia.org/wiki/Data_Encryption_Standard"&gt;DES&lt;/a&gt;.
Source&amp;nbsp;&amp;#64; &lt;a class="reference external" href="https://github.com/Nagasaki45/SimpleCrypt"&gt;github&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://friends-mapper.herokuapp.com/"&gt;Friends-Mapper&lt;/a&gt; - Creates a
dynamic map of your friends. Source&amp;nbsp;&amp;#64;
&lt;a class="reference external" href="https://github.com/Nagasaki45/Friends-Mapper"&gt;github&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Information regarding my final project will come soon...&lt;/p&gt;
</content><category term="Blog"></category><category term="other"></category><category term="django"></category><category term="python"></category><category term="web"></category></entry><entry><title>Compare food prices in Jerusalem - a new mini-web-project</title><link href="/blog/compare-food-prices-in-jerusalem-a-new-mini-web-project" rel="alternate"></link><published>2013-11-16T00:00:00+00:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2013-11-16:/blog/compare-food-prices-in-jerusalem-a-new-mini-web-project</id><summary type="html">&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a class="reference external image-reference" href="http://nagasaki45.pythonanywhere.com/"&gt;
&lt;img alt="Project screenshot" src="/images/blog/jerusalem_marketprices.webp" /&gt;
&lt;/a&gt;
&lt;/div&gt;&lt;p&gt;Two things happened recently, I've moved to the holly city and started
to learn Python. Here are the consequences: a mini web app to compare
food prices, written in Django and deployed to pythonanywhere, for …&lt;/p&gt;</summary><content type="html">&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a class="reference external image-reference" href="http://nagasaki45.pythonanywhere.com/"&gt;
&lt;img alt="Project screenshot" src="/images/blog/jerusalem_marketprices.webp" /&gt;
&lt;/a&gt;
&lt;/div&gt;&lt;p&gt;Two things happened recently, I've moved to the holly city and started
to learn Python. Here are the consequences: a mini web app to compare
food prices, written in Django and deployed to pythonanywhere, for my
own&amp;nbsp;purpose&amp;nbsp;and for my students friends.&lt;/p&gt;
&lt;div style="text-align: center;"&gt;&lt;p&gt;&lt;a class="reference external" href="http://nagasaki45.pythonanywhere.com/"&gt;Jerusalem MarketPrices&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;p&gt;More features will be added soon and on demand :-). If you want to be
able to update markets, products and prices, drop a comment and I will
create an account for you.
And as always, source code can be found at
&lt;a class="reference external" href="https://github.com/Nagasaki45/MarketPrices"&gt;github&lt;/a&gt;.&lt;/p&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="django"></category><category term="python"></category><category term="web"></category></entry><entry><title>MusiGali video demonstration</title><link href="/blog/musigali-video-demonstration" rel="alternate"></link><published>2013-10-19T19:35:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2013-10-19:/blog/musigali-video-demonstration</id><content type="html">&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/aXbvVGCQ5wY" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;A screen capture of MusiGali &lt;a class="reference external" href="https://www.ableton.com/"&gt;Ableton Live&lt;/a&gt;
set. All the details are
&lt;a class="reference external" href="/blog/musigali-eeg-controlled-music-for-brain-tech-israel-2013"&gt;here&lt;/a&gt;.&lt;/p&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="demo"></category><category term="music programming"></category></entry><entry><title>MusiGali - EEG controlled music for Brain Tech Israel 2013</title><link href="/blog/musigali-eeg-controlled-music-for-brain-tech-israel-2013" rel="alternate"></link><published>2013-10-14T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2013-10-14:/blog/musigali-eeg-controlled-music-for-brain-tech-israel-2013</id><summary type="html">&lt;p&gt;A project by Giori Politi, Sharon Duek, Jonathan Abramson and myself
which developed / composed especially for the Brain Tech Israel 2013
conference this week.
In this project we created a musical soundtrack based on mind …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A project by Giori Politi, Sharon Duek, Jonathan Abramson and myself
which developed / composed especially for the Brain Tech Israel 2013
conference this week.
In this project we created a musical soundtrack based on mind waves
transmitted from an EEG headset. The generated musical line is
parameterized according to levels of attention and meditation of the
headset wearer, leading the listener to unexpected musical realms which
somewhat correspond to his or her neuro-electric activity. One may try
to attain control over the musical line and advance within it through
deliberate control over levels of relaxation and concentration.
The EEG headset that was used for the project is &lt;a class="reference external" href="http://www.neurosky.com/Products/MindWaveMobile.aspx"&gt;NueroSky MindWave
mobile&lt;/a&gt;. Music
was composed in&amp;nbsp;&lt;a class="reference external" href="https://www.ableton.com/en/live/"&gt;Ableton
Live&lt;/a&gt;&amp;nbsp;using Max for Live to read
the data from the headset.
Many thanks to Zvika Markfeld and Saron Paz from &lt;a class="reference external" href="http://forrealteam.com/"&gt;ForReal
Team&lt;/a&gt;, the&amp;nbsp;exhibition curators.&lt;/p&gt;
&lt;img alt="MusiGali project presentation at Brain Tech Israel 2013" src="/images/blog/musigali_presentation1.avif" style="width: 100%;" /&gt;
&lt;img alt="MusiGali project presentation at Brain Tech Israel 2013" src="/images/blog/musigali_presentation2.avif" style="width: 100%;" /&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="conference"></category><category term="music programming"></category></entry><entry><title>Find nearby Bluetooth devices with BT-logger</title><link href="/blog/find-nearby-bluetooth-devices-with-bt-logger" rel="alternate"></link><published>2013-08-21T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2013-08-21:/blog/find-nearby-bluetooth-devices-with-bt-logger</id><summary type="html">&lt;p&gt;With this new Android app you can get information about nearby
Bluetooth devices. The application collect the name, address, RSSI value
and time of discovery of nearby Bluetooth devices and write them to file
in …&lt;/p&gt;</summary><content type="html">&lt;p&gt;With this new Android app you can get information about nearby
Bluetooth devices. The application collect the name, address, RSSI value
and time of discovery of nearby Bluetooth devices and write them to file
in \BluetoothData directory on the main device storage.
The application primary use is to evaluate my Bluetooth based relative
indoor positioning system that you should&amp;nbsp;already&amp;nbsp;be familiar with.
Otherwise you can find all the necessary information regarding my master
thesis &lt;a class="reference external" href="/projects/an-audio-only-augmented-reality-system-for-social-interaction"&gt;here&lt;/a&gt;.
As always, everything is
&lt;a class="reference external" href="https://github.com/Nagasaki45/BT-logger"&gt;opensource&lt;/a&gt;.&lt;/p&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="android"></category><category term="MA thesis"></category></entry><entry><title>Poster presentation for HCI International 2013</title><link href="/blog/poster-presentation-for-hci-international-2013" rel="alternate"></link><published>2013-07-17T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2013-07-17:/blog/poster-presentation-for-hci-international-2013</id><summary type="html">&lt;p&gt;Next week I'm going to present my master thesis in &lt;a class="reference external" href="http://hcii2013.org/"&gt;HCI International
2013&lt;/a&gt; conference in Las Vegas.
The poster is already in printing: 42&amp;quot; x 60&amp;quot; with glossy finish. But
for the most of you …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Next week I'm going to present my master thesis in &lt;a class="reference external" href="http://hcii2013.org/"&gt;HCI International
2013&lt;/a&gt; conference in Las Vegas.
The poster is already in printing: 42&amp;quot; x 60&amp;quot; with glossy finish. But
for the most of you &lt;a class="reference external" href="http://db.tt/Rx7FnAxn"&gt;here is the original pdf&lt;/a&gt;.
Comments are more than welcome.&lt;/p&gt;
&lt;img alt="Poster for HCI International 2013" src="/images/blog/hci_poster.avif" style="width: 100%;" /&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="conference"></category><category term="MA thesis"></category></entry><entry><title>Some pictures from ISTAS'13</title><link href="/blog/some-pictures-from-istas13" rel="alternate"></link><published>2013-07-01T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2013-07-01:/blog/some-pictures-from-istas13</id><summary type="html">&lt;p&gt;Here are some pictures from the conference, which was great by the way.&lt;/p&gt;
&lt;img alt="Presenting the project" src="/images/blog/istas1.avif" style="width: 100%;" /&gt;
&lt;p&gt;Thanks for Alexander Hayes for the picture&lt;/p&gt;
&lt;img alt="My desc in the exhibition hall" src="/images/blog/istas2.avif" style="width: 100%;" /&gt;
&lt;p&gt;Me presenting the system in the exhibition hall&lt;/p&gt;
&lt;img alt="Amber case thumbsup!" src="/images/blog/istas3.avif" style="width: 100%;" /&gt;
&lt;p&gt;Looks like &lt;a class="reference external" href="http://caseorganic.com/"&gt;Amber Case&lt;/a&gt; likes interactive music …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Here are some pictures from the conference, which was great by the way.&lt;/p&gt;
&lt;img alt="Presenting the project" src="/images/blog/istas1.avif" style="width: 100%;" /&gt;
&lt;p&gt;Thanks for Alexander Hayes for the picture&lt;/p&gt;
&lt;img alt="My desc in the exhibition hall" src="/images/blog/istas2.avif" style="width: 100%;" /&gt;
&lt;p&gt;Me presenting the system in the exhibition hall&lt;/p&gt;
&lt;img alt="Amber case thumbsup!" src="/images/blog/istas3.avif" style="width: 100%;" /&gt;
&lt;p&gt;Looks like &lt;a class="reference external" href="http://caseorganic.com/"&gt;Amber Case&lt;/a&gt; likes interactive music :-)&lt;/p&gt;
</content><category term="Blog"></category><category term="other"></category><category term="conference"></category><category term="MA thesis"></category></entry><entry><title>Slideshow of my thesis presentation</title><link href="/blog/slideshow-of-my-thesis-presentation" rel="alternate"></link><published>2013-06-28T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2013-06-28:/blog/slideshow-of-my-thesis-presentation</id><summary type="html">&lt;div style="text-align: center;"&gt;
&lt;iframe src="//www.slideshare.net/slideshow/embed_code/key/4fp4TiFyoBEsrf" width="100%" height="440" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px;" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;&lt;p&gt;In this slideshow you can taste a little bit of how the system and the
experiment looks like. This slideshow originally made for my
presentation at &lt;a class="reference external" href="http://istas13.org/"&gt;ISTAS'13&lt;/a&gt;&amp;nbsp;(and it contains much
better animations then what …&lt;/p&gt;</summary><content type="html">&lt;div style="text-align: center;"&gt;
&lt;iframe src="//www.slideshare.net/slideshow/embed_code/key/4fp4TiFyoBEsrf" width="100%" height="440" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px;" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;&lt;p&gt;In this slideshow you can taste a little bit of how the system and the
experiment looks like. This slideshow originally made for my
presentation at &lt;a class="reference external" href="http://istas13.org/"&gt;ISTAS'13&lt;/a&gt;&amp;nbsp;(and it contains much
better animations then what you can see here on the slideshare version
:-) ), but&amp;nbsp;I would be happy to present it again, just contact
me.&lt;/p&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="conference"></category><category term="MA thesis"></category></entry><entry><title>ARpArty, the first ScenePlayer Plus Bluetooth aware scene, is here for you</title><link href="/blog/arparty-the-first-sceneplayer-plus-bluetooth-aware-scene-is-here-for-you" rel="alternate"></link><published>2013-06-27T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2013-06-27:/blog/arparty-the-first-sceneplayer-plus-bluetooth-aware-scene-is-here-for-you</id><summary type="html">&lt;p&gt;You are welcome to download and install ARpArty scene for
&lt;a class="reference external" href="https://play.google.com/store/apps/details?id=com.nagasaki45.sceneplayerplus"&gt;ScenePlayer Plus&lt;/a&gt;
from &lt;a class="reference external" href="http://db.tt/Y6cn2APx"&gt;here&lt;/a&gt;. ARpArty was developed as an
implementation of audio-based augmented reality system for interactive
music consumption in a silent disco context and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;You are welcome to download and install ARpArty scene for
&lt;a class="reference external" href="https://play.google.com/store/apps/details?id=com.nagasaki45.sceneplayerplus"&gt;ScenePlayer Plus&lt;/a&gt;
from &lt;a class="reference external" href="http://db.tt/Y6cn2APx"&gt;here&lt;/a&gt;. ARpArty was developed as an
implementation of audio-based augmented reality system for interactive
music consumption in a silent disco context and is the main scene that I
use in my research.
In order to install the scene, just copy the extracted directory from
the zip file to the SD card of your device, then launch the the app and
add the new scene.
If you are an artist that want to develop Bluetooth aware scenes for
ScenePlayer Plus taking a look at this scene could be a good starting
point.&lt;/p&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="MA thesis"></category><category term="android"></category><category term="music programming"></category></entry><entry><title>ScenePlayer Plus</title><link href="/blog/sceneplayer-plus" rel="alternate"></link><published>2013-06-24T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2013-06-24:/blog/sceneplayer-plus</id><summary type="html">&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;img alt="ScenePlayer Plus logo" src="/images/blog/sceneplayerplus_logo.webp" /&gt;
&lt;/div&gt;&lt;p&gt;ScenePlayer Plus is an enhanced version of
&lt;a class="reference external" href="https://github.com/libpd/pd-for-android/tree/master/ScenePlayer"&gt;ScenePlayer&lt;/a&gt;
by Peter Brinkmann.
It uses additional capabilities of the Android device that are not
used by RjDj or ScenePlayer apps (Bluetooth is an example) but it is …&lt;/p&gt;</summary><content type="html">&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;img alt="ScenePlayer Plus logo" src="/images/blog/sceneplayerplus_logo.webp" /&gt;
&lt;/div&gt;&lt;p&gt;ScenePlayer Plus is an enhanced version of
&lt;a class="reference external" href="https://github.com/libpd/pd-for-android/tree/master/ScenePlayer"&gt;ScenePlayer&lt;/a&gt;
by Peter Brinkmann.
It uses additional capabilities of the Android device that are not
used by RjDj or ScenePlayer apps (Bluetooth is an example) but it is
still fully compatible with standard RjDj scenes.
ScenePlayer Plus can be downloaded from &lt;a class="reference external" href="https://play.google.com/store/apps/details?id=com.nagasaki45.sceneplayerplus"&gt;Google
Play&lt;/a&gt;.
Source code can be found at
&lt;a class="reference external" href="https://github.com/Nagasaki45/ScenePlayer-Plus"&gt;Github&lt;/a&gt;&amp;nbsp;and
instruction for creating scenes for ScenePlayer Plus can be found at the
&lt;a class="reference external" href="https://github.com/Nagasaki45/ScenePlayer-Plus/wiki"&gt;project wiki&lt;/a&gt;.
ScenePlayer Plus has been developed as part of my master thesis as an
implementation of the &lt;a class="reference external" href="/projects/an-audio-only-augmented-reality-system-for-social-interaction"&gt;proposed
system&lt;/a&gt;.
With the abilities of &lt;a class="reference external" href="http://libpd.cc/"&gt;libpd&lt;/a&gt; and the ease of use
of ScenePlayer I've found that the only component that is necessary for
me to develop is the Bluetooth discovery routine for the relative indoor
positioning.
Developers that interested in improving the Bluetooth awareness
capabilities of the app or in adding more features (GPS / compass /
social media APIs etc.) are welcome to contact me.&lt;/p&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="android"></category><category term="MA thesis"></category></entry><entry><title>Abstract: Audio­-only augmented reality system for social interaction</title><link href="/blog/abstract-audio-only-augmented-reality-system-for-social-interaction" rel="alternate"></link><published>2013-06-23T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2013-06-23:/blog/abstract-audio-only-augmented-reality-system-for-social-interaction</id><summary type="html">&lt;div class="section" id="tom-gurion"&gt;
&lt;h2&gt;Tom Gurion&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Bar-Ilan University, Ramat-Gan&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="nori-jacoby"&gt;
&lt;h2&gt;Nori Jacoby&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Hebrew University, Jeruslam; Bar-Ilan University, Ramat-Gan&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We explore new possibilities for interactive music consumption by proposing an audio-only augmented reality system for social interaction.
We designed and built …&lt;/p&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="section" id="tom-gurion"&gt;
&lt;h2&gt;Tom Gurion&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Bar-Ilan University, Ramat-Gan&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="nori-jacoby"&gt;
&lt;h2&gt;Nori Jacoby&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Hebrew University, Jeruslam; Bar-Ilan University, Ramat-Gan&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We explore new possibilities for interactive music consumption by proposing an audio-only augmented reality system for social interaction.
We designed and built an Android application that measures the relative position of the device from specially designed Bluetooth beacons.
Participants can freely move the beacons that are installed on physical objects, thereby dynamically changing the structure of the music in the virtual space.
In a controlled experiment, we assessed the interactive component of the system in the context of a silent rave party by comparing the system positioning readings in interactive and non-interactive control segments.
We also directly assessed the user experience using self-reported pre/post surveys.
Our preliminary results show that in the post-party survey, participants self-reported significantly higher levels of movement using the system, compared with their behavior on other parties as reported in the pre-party survey.
We used the relative positioning system in the application to objectively validate that the interactive components of the system facilitate greater participant movement in space, thereby offering more frequent opportunities for social interaction.
Indeed, in the post-party survey participants reported that they danced significantly less with people that they knew ahead of time, compared with their pre-party survey reporting of usual behavior.
Our results displaying the potential of using audio-only augmented reality in future mobile applications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; Augmented reality, Music technology, Social interaction, Relative indoor positioning system&lt;/p&gt;
&lt;/div&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="MA thesis"></category></entry><entry><title>Publication in the proceedings of HCI International 2013</title><link href="/blog/publication-in-the-proceedings-of-hci-international-2013" rel="alternate"></link><published>2013-06-23T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2013-06-23:/blog/publication-in-the-proceedings-of-hci-international-2013</id><content type="html">&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;img alt="HCI International 2013 logo" src="http://www.ainci.com/hci-international-2013/HCI%20Lab%20%202013%20-%20HCI%20International%20-%20Las%20Vegas%20-%20USA.jpg" /&gt;
&lt;/div&gt;&lt;p&gt;&lt;a class="reference external" href="http://db.tt/zpgwMFKJ"&gt;Gurion, Tom, and Nori Jacoby. &amp;quot;Audio-Only Augmented Reality System
for Social Interaction.&amp;quot; HCI International 2013-Posters' Extended
Abstracts. Springer Berlin Heidelberg, 2013.
322-326.&lt;/a&gt;
Here's the &lt;a class="reference external" href="http://link.springer.com/content/pdf/10.1007%2F978-3-642-39473-7_65.pdf"&gt;paper page at
SpringerLink&lt;/a&gt;&lt;/p&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="conference"></category><category term="MA thesis"></category><category term="publication"></category></entry><entry><title>Thesis project Pure Data patch video demonstration</title><link href="/blog/thesis-project-pure-data-patch-video-demonstration" rel="alternate"></link><published>2013-06-23T00:00:00+01:00</published><updated>2025-04-21T18:28:54+01:00</updated><author><name>Tom Gurion</name></author><id>tag:None,2013-06-23:/blog/thesis-project-pure-data-patch-video-demonstration</id><summary type="html">&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/2kJoeD2iWBA" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;This demo shows how movement of participants in space affects the music
they hear through their own Android device and headphones using the
system in a silent disco party. In addition it demonstrate the influence …&lt;/p&gt;</summary><content type="html">&lt;div class="youtube youtube-16x9"&gt;&lt;iframe src="https://www.youtube.com/embed/2kJoeD2iWBA" allowfullscreen seamless frameBorder="0"&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;This demo shows how movement of participants in space affects the music
they hear through their own Android device and headphones using the
system in a silent disco party. In addition it demonstrate the influence
of different participants on one another when one virtual participant
takes diverse sound zones with him during this simulation. The music is
the same as in the original system.&lt;/p&gt;
</content><category term="Blog"></category><category term="projects"></category><category term="MA thesis"></category><category term="demo"></category><category term="music programming"></category></entry></feed>